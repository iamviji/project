{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasOneHotCNN_10_20_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/Final/tmp/KerasOneHotCNN_10_20_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dLvr1Rr1K8"
      },
      "source": [
        "import numpy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense,  Reshape, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "input_message_length = 10\n",
        "encoder_output_length = 30\n",
        "channel_size = 10\n",
        "\n",
        "input_block_length = 5\n",
        "num_of_input_block = 2\n",
        "\n",
        "\n",
        "NUM_OF_INPUT_MESSAGE = 1000\n",
        "SNR_STEP_SIZE = .5\n",
        "\n",
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "\n",
        "bler_per_iter_uncoded_commpy_psk_2 = [0.521, 0.473, 0.436, 0.37,  0.304, 0.259, 0.187, 0.138, 0.098, 0.098, 0.052, 0.028, 0.012, 0.011, 0.009, 0.002, 0.0,  0.001, 0.,    0.0]\n",
        "bler_per_iter_uncoded_itpp_psk_2 = [0.518, 0.478, 0.415, 0.355, 0.305, 0.227, 0.177, 0.149, 0.11,  0.075, 0.055, 0.023, 0.014, 0.014, 0.015, 0.001, 0.003, 0.001, 0.,    0. ]\n",
        "bler_per_iter_uncoded_commpy_psk_4 = [0.815, 0.793, 0.75,  0.714, 0.64,  0.639, 0.526, 0.49,  0.433, 0.371, 0.335, 0.236, 0.204, 0.154, 0.129, 0.08,  0.063, 0.046, 0.023, 0.018]\n",
        "bler_per_iter_uncoded_itpp_psk_4 = [0.814, 0.767, 0.729, 0.702, 0.66,  0.616, 0.563, 0.511, 0.442, 0.4,   0.294, 0.277, 0.228, 0.17,  0.114, 0.087, 0.05,  0.037, 0.022, 0.017]\n",
        "bler_per_iter_ldpc_itpp_psk_4 = [0.584, 0.488, 0.404, 0.332, 0.218, 0.151, 0.097, 0.058, 0.041, 0.024, 0.007, 0.004, 0.002, 0.001, 0.001, 0.,    0.,    0.,    0.,    0.,   ]\n",
        "bler_per_iter_ham_itpp_psk_4 = [0.51, 0.479, 0.419, 0.333, 0.313, 0.247, 0.212, 0.132, 0.114, 0.093, 0.042, 0.027, 0.024, 0.016, 0.006, 0.005, 0.003, 0.002, 0.,    0.  ]\n",
        "bler_per_iter_uncoded_itpp_psk_8 = [0.921, 0.917, 0.912, 0.867, 0.86,  0.857, 0.826, 0.808, 0.77,  0.737, 0.704, 0.657, 0.608, 0.6,   0.547, 0.487, 0.426, 0.361, 0.323, 0.293]\n",
        "bler_per_iter_uncoded_commpy_psk_8 = [0.923, 0.912, 0.891, 0.888, 0.874, 0.851, 0.804, 0.779, 0.758, 0.736, 0.715, 0.643, 0.614, 0.557, 0.542, 0.503, 0.431, 0.386, 0.331, 0.289]\n",
        "\n",
        "ber_per_iter_uncoded_itpp_psk_2 = [0.07933333, 0.067, 0.058, 0.04811111, 0.039, 0.02911111, 0.02211111, 0.01833333, 0.01266667, 0.00866667, 0.00622222, 0.00255556, 0.00166667, 0.00155556, 0.00166667, 0.00011111, 0.00033333, 0.00011111, 0., 0.]\n",
        "ber_per_iter_uncoded_commpy_psk_2 = [0.07955556, 0.07055556, 0.05344444, 0.04477778, 0.03644444, 0.02888889, 0.02055556, 0.01955556, 0.01033333, 0.00855556, 0.00522222, 0.004, 0.00188889, 0.00155556, 0.00055556, 0.00066667, 0.00022222, 0.00011111, 0., 0.]\n",
        "ber_per_iter_uncoded_itpp_psk_4 = [0.1559, 0.1421, 0.1248, 0.1137, 0.1031, 0.0924, 0.0802, 0.0684, 0.055,  0.0499, 0.0348, 0.0336, 0.0257, 0.0185, 0.0121, 0.0092, 0.0054, 0.0037, 0.0022, 0.0017]\n",
        "ber_per_iter_uncoded_commpy_psk_4 = [0.2137, 0.1943, 0.1773, 0.1624, 0.1473, 0.1355, 0.1105, 0.0984, 0.0873, 0.0686, 0.0573, 0.0454, 0.0356, 0.024,  0.0214, 0.0142, 0.0111, 0.0055, 0.0038, 0.002]\n",
        "ber_per_iter_uncoded_itpp_psk_8 = [0.24566667, 0.23411111, 0.21455556, 0.19888889, 0.188, 0.184, 0.16355556, 0.15655556, 0.13777778, 0.12966667, 0.115, 0.10622222, 0.09211111, 0.088, 0.07622222, 0.06855556, 0.05677778, 0.04755556, 0.04188889, 0.03577778]\n",
        "ber_per_iter_uncoded_commpy_psk_8 = [0.32577778, 0.31533333, 0.30455556, 0.29644444, 0.27955556, 0.266, 0.24677778, 0.23411111, 0.22088889, 0.209,      0.19577778, 0.17544444, 0.15844444, 0.13966667, 0.13533333, 0.12077778, 0.10211111, 0.09066667, 0.07544444, 0.06355556]\n",
        "ber_per_iter_ldpc_itpp_psk_4 = [1.25444444e-01, 1.19111111e-01, 9.48888889e-02, 7.54444444e-02, 5.50000000e-02, 3.86666667e-02, 2.51111111e-02, 1.53333333e-02, 1.04444444e-02, 1.22222222e-03, 2.88888889e-03, 0.00000000e+00, 1.11111111e-04, 3.33333333e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]\n",
        "\n",
        "\n",
        "import numpy as np #for numerical computing\n",
        "import matplotlib.pyplot as plt #for plotting functions\n",
        "from scipy.special import erfc\n",
        "import math\n",
        "#ref : https://core.ac.uk/download/pdf/235049678.pdf\n",
        "EbN0dBs = np.arange(start=0,stop = 10.5, step = .5)\n",
        "PSK_2_BER_theory = 0.5*erfc(np.sqrt(10**(EbN0dBs/10)))\n",
        "M=4\n",
        "#QAM_BER_theory = 2*(1-np.sqrt(1/M))*erfc(np.sqrt(10**(EbN0dBs/10)))\n",
        "QAM_BER_theory = erfc(np.sqrt(math.log2(M)*3/(2*(M-1)))*np.sqrt(10**(EbN0dBs/10)))\n",
        "PSK_4_BER_theory = erfc(math.sin(math.pi/M)*np.sqrt(10**(EbN0dBs/10)))\n",
        "M=8\n",
        "PSK_8_BER_theory = erfc(math.sin(math.pi/M)*np.sqrt(10**(EbN0dBs/10)))\n",
        "QAM_8_BER_theory = 2*erfc(np.sqrt(math.log2(M)*3/(2*(M-1)))*np.sqrt(10**(EbN0dBs/10)))\n",
        "M=16\n",
        "PSK_16_BER_theory = erfc(math.sin(math.pi/M)*np.sqrt(10**(EbN0dBs/10)))\n",
        "#QAM_16_BER_theory = 2*erfc(np.sqrt(math.log2(M)*3/(2*(M-1)))*np.sqrt(10**(EbN0dBs/10)))\n",
        "QAM_16_BER_theory = (3.0/2)*erfc(np.sqrt((4.0/10))*np.sqrt(10**(EbN0dBs/10)))\n",
        "                     #(3.0/2)*special.erfc(np.sqrt((4.0/10)*10.**(ebno/10)))\n",
        "M=32\n",
        "PSK_32_BER_theory = erfc(math.sin(math.pi/M)*np.sqrt(10**(EbN0dBs/10)))\n",
        "\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = (10 ** (- snr / 20))  #*(numpy.sqrt(2))\n",
        "  return sigma\n",
        "\n",
        "\n",
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DiN6PgYvjEI"
      },
      "source": [
        "def conv_to_binary_from_decimal (decimal,input_message_size, input_message_length):\r\n",
        "  binary = numpy.random.randint(1, size=(input_message_size,input_message_length))\r\n",
        "  for i in range (input_message_size):\r\n",
        "    bin = [int(x) for x in list('{0:0b}'.format(decimal[0][i]))]\r\n",
        "    #print(bin)\r\n",
        "    for j in range (len(bin)):\r\n",
        "      offset = input_message_length - len(bin)\r\n",
        "      #print (\"x\",offset)\r\n",
        "      binary [i][j+offset] = bin [j]\r\n",
        "  return binary\r\n",
        "\r\n",
        "def GetBerBler (input_message_binary1, input_message_binary2):\r\n",
        "  diff = abs(input_message_binary1 - input_message_binary2)\r\n",
        "  field_sum = numpy.sum (diff, axis=1)\r\n",
        "  field_sum = numpy.reshape (field_sum, (-1,1))\r\n",
        "  ber = numpy.sum(field_sum)/(input_message_binary1.shape[0]*input_message_binary1.shape[1])\r\n",
        "  field_non_zero_count = numpy.count_nonzero(field_sum != 0, axis=1)\r\n",
        "  bler = numpy.sum(field_non_zero_count)/field_non_zero_count.shape[0]\r\n",
        "  return ber, bler\r\n",
        "\r\n",
        "def get_onehot_ber_bler_of_model (snr_list, encoder, decoder, input_onehot, input_binary, num_of_input_msg, input_message_length, channel_size, verbose=1):\r\n",
        "  bler_per_iter_dl_tensor  = numpy.array(())\r\n",
        "  ber_per_iter_dl_tensor  = numpy.array(())\r\n",
        "  channel_out = []\r\n",
        "  encoded_message = encoder.predict(input_onehot)\r\n",
        "  for snr in snr_list:\r\n",
        "    total_bit_error = 0\r\n",
        "    total_msg_error = 0    \r\n",
        "    sigma = Snr2Sigma (snr)\r\n",
        "    noised_message = encoded_message + numpy.random.normal(0, sigma, encoded_message.shape)\r\n",
        "    for i in range (num_of_input_msg):\r\n",
        "      noised_message[i] = encoded_message[i] + numpy.random.normal(0, sigma, [1,2*channel_size])\r\n",
        "      channel_out.append(noised_message[i])\r\n",
        "    decoded_message = decoder.predict(noised_message)\r\n",
        "    decoded_message_decimal = []\r\n",
        "    decoded_message_decimal.append(numpy.argmax(decoded_message, axis=1))\r\n",
        "    decoded_message_binary = conv_to_binary_from_decimal (decoded_message_decimal, num_of_input_msg,  input_message_length)\r\n",
        "    ber,bler = GetBerBler (input_binary, decoded_message_binary)\r\n",
        "    print('SNR: {:04.3f}:-> BLER: {:03.3f} BER: {:03.3f}'.format(snr,bler,ber))\r\n",
        "    bler_per_iter_dl_tensor = numpy.append(bler_per_iter_dl_tensor, bler)\r\n",
        "    ber_per_iter_dl_tensor = numpy.append(ber_per_iter_dl_tensor, ber)\r\n",
        "  return ber_per_iter_dl_tensor, bler_per_iter_dl_tensor, channel_out\r\n",
        "\r\n",
        "def get_block_onehot_ber_bler_of_model (snr_list, encoder, decoder, input_onehot, input_binary, num_of_input_msg, input_message_length, channel_size, verbose=1):\r\n",
        "  bler_per_iter_dl_tensor  = numpy.array(())\r\n",
        "  ber_per_iter_dl_tensor  = numpy.array(())\r\n",
        "  channel_out = []\r\n",
        "  encoded_message = encoder.predict(input_onehot)\r\n",
        "  for snr in snr_list:\r\n",
        "    total_bit_error = 0\r\n",
        "    total_msg_error = 0    \r\n",
        "    sigma = Snr2Sigma (snr)\r\n",
        "    noised_message = encoded_message + numpy.random.normal(0, sigma, encoded_message.shape)\r\n",
        "    for i in range (num_of_input_msg):\r\n",
        "      noised_message[i] = encoded_message[i] + numpy.random.normal(0, sigma, [1,2*channel_size])\r\n",
        "      channel_out.append(noised_message[i])\r\n",
        "    decoded_message = decoder.predict(noised_message)\r\n",
        "    decoded_message_decimal = []\r\n",
        "    decoded_message_decimal.append(numpy.argmax(decoded_message, axis=1))\r\n",
        "    decoded_message_binary = conv_to_binary_from_decimal (decoded_message_decimal, num_of_input_msg,  input_message_length)\r\n",
        "    ber,bler = GetBerBler (input_binary, decoded_message_binary)\r\n",
        "    print('SNR: {:04.3f}:-> BLER: {:03.3f} BER: {:03.3f}'.format(snr,bler,ber))\r\n",
        "    bler_per_iter_dl_tensor = numpy.append(bler_per_iter_dl_tensor, bler)\r\n",
        "    ber_per_iter_dl_tensor = numpy.append(ber_per_iter_dl_tensor, ber)\r\n",
        "  return ber_per_iter_dl_tensor, bler_per_iter_dl_tensor, channel_out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIqZA3RCrJgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470b7b7b-feb5-419e-c8e5-ac8be0bb0fe9"
      },
      "source": [
        "snr_std = Snr2Sigma(7.0)\n",
        "\n",
        "print (\"num_of_input_block\", num_of_input_block)\n",
        "print (\"input_block_length\", input_block_length)\n",
        "train_batch_size = 500\n",
        "input_message_x = Input(shape=(num_of_input_block, 2**input_block_length), name=\"inputs\")\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "#reshaped_input = tf.reshape (input_message_x, (tf.shape(input_message_x)[0],tf.shape(input_message_x)[1]*tf.shape(input_message_x)[2]))\n",
        "reshaped_input = tf.reshape (input_message_x, (train_batch_size,num_of_input_block*2**input_block_length))\n",
        "enc_layer1 = Dense(encoder_output_length, activation='tanh', name=\"enc_layer1\")(reshaped_input)\n",
        "enc_layer2 = Dense(2*channel_size, activation='tanh', name=\"enc_layer2\")(enc_layer1)\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(2*channel_size,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(2*channel_size,))\n",
        "dec_layer1 = Dense(num_of_input_block*2**input_block_length, activation='sigmoid', name=\"dec_layer1\")(encoded_input)\n",
        "#dec_layer2 = Dense(num_of_input_block*2**input_block_length, activation=\"sigmoid\")(dec_layer1)\n",
        "reshaped_output = tf.reshape (dec_layer1, (train_batch_size,num_of_input_block,2**input_block_length))\n",
        "dec_layer2 = Dense((2**input_block_length), activation=\"softmax\", name=\"dec_layer2\")(reshaped_output)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "\n",
        "\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_of_input_block 2\n",
            "input_block_length 5\n",
            "Model: \"model_42\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, 2, 32)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.reshape_24 (TFOpLambda)      (500, 64)            0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "enc_layer1 (Dense)              (500, 30)            1950        tf.reshape_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "enc_layer2 (Dense)              (500, 20)            620         enc_layer1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.square_16 (TFOpLambda)  (500, 20)            0           enc_layer2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_mean_16 (TFOpLam ()                   0           tf.math.square_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.sqrt_16 (TFOpLambda)    ()                   0           tf.math.reduce_mean_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv_16 (TFOpLambda) (500, 20)            0           enc_layer2[0][0]                 \n",
            "                                                                 tf.math.sqrt_16[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,570\n",
            "Trainable params: 2,570\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "dec_layer1 (Dense)           (None, 64)                1344      \n",
            "_________________________________________________________________\n",
            "tf.reshape_25 (TFOpLambda)   (500, 2, 32)              0         \n",
            "_________________________________________________________________\n",
            "dec_layer2 (Dense)           (500, 2, 32)              1056      \n",
            "=================================================================\n",
            "Total params: 2,400\n",
            "Trainable params: 2,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_44\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 2, 32)]           0         \n",
            "_________________________________________________________________\n",
            "model_42 (Functional)        (500, 20)                 2570      \n",
            "_________________________________________________________________\n",
            "gaussian_noise_16 (GaussianN (500, 20)                 0         \n",
            "_________________________________________________________________\n",
            "model_43 (Functional)        (500, 2, 32)              2400      \n",
            "=================================================================\n",
            "Total params: 4,970\n",
            "Trainable params: 4,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcVN1ktie4dh",
        "outputId": "dbb3fa3b-1207-4559-f4d1-a4e795fab69e"
      },
      "source": [
        "snr_std = Snr2Sigma(7.0)\r\n",
        "\r\n",
        "print (\"num_of_input_block\", num_of_input_block)\r\n",
        "print (\"input_block_length\", input_block_length)\r\n",
        "train_batch_size = 500\r\n",
        "input_message_x = Input(shape=(num_of_input_block, 2**input_block_length), name=\"inputs\")\r\n",
        "# \"encoded\" is the encoded representation of the input\r\n",
        "#reshaped_input = tf.reshape (input_message_x, (tf.shape(input_message_x)[0],tf.shape(input_message_x)[1]*tf.shape(input_message_x)[2]))\r\n",
        "reshaped_input = tf.reshape (input_message_x, (-1,num_of_input_block*2**input_block_length))\r\n",
        "#reshaped_input =  Reshape((1,num_of_input_block*2**input_block_length))\r\n",
        "\r\n",
        "enc_layer1 = Dense(encoder_output_length, activation='tanh', name=\"enc_layer1\")(reshaped_input)\r\n",
        "enc_layer2 = Dense(2*channel_size, activation='tanh', name=\"enc_layer2\")(enc_layer1)\r\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\r\n",
        "encoder = Model(input_message_x, enc_layer3)\r\n",
        "\r\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(2*channel_size,))\r\n",
        "\r\n",
        "# create a placeholder for an encoded (32-dimensional) input\r\n",
        "encoded_input = Input(shape=(2*channel_size,))\r\n",
        "dec_layer1 = Dense(num_of_input_block*2**input_block_length, activation='sigmoid', name=\"dec_layer1\")(encoded_input)\r\n",
        "#dec_layer2 = Dense(num_of_input_block*2**input_block_length, activation=\"sigmoid\")(dec_layer1)\r\n",
        "reshaped_output = tf.reshape (dec_layer1, (-1,num_of_input_block,2**input_block_length))\r\n",
        "dec_layer2 = Dense((2**input_block_length), activation=\"softmax\", name=\"dec_layer2\")(reshaped_output)\r\n",
        "# this model maps an encoded input to its decoder representation\r\n",
        "decoder = Model(encoded_input, dec_layer2)\r\n",
        "\r\n",
        "# this model maps an input to its reconstruction\r\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\r\n",
        "\r\n",
        "\r\n",
        "print(encoder.summary())\r\n",
        "print(decoder.summary())\r\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_of_input_block 2\n",
            "input_block_length 5\n",
            "Model: \"model_54\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, 2, 32)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.reshape_32 (TFOpLambda)      (None, 64)           0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "enc_layer1 (Dense)              (None, 30)           1950        tf.reshape_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "enc_layer2 (Dense)              (None, 20)           620         enc_layer1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.square_20 (TFOpLambda)  (None, 20)           0           enc_layer2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_mean_20 (TFOpLam ()                   0           tf.math.square_20[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.sqrt_20 (TFOpLambda)    ()                   0           tf.math.reduce_mean_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.truediv_20 (TFOpLambda) (None, 20)           0           enc_layer2[0][0]                 \n",
            "                                                                 tf.math.sqrt_20[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,570\n",
            "Trainable params: 2,570\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_55\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 20)]              0         \n",
            "_________________________________________________________________\n",
            "dec_layer1 (Dense)           (None, 64)                1344      \n",
            "_________________________________________________________________\n",
            "tf.reshape_33 (TFOpLambda)   (None, 2, 32)             0         \n",
            "_________________________________________________________________\n",
            "dec_layer2 (Dense)           (None, 2, 32)             1056      \n",
            "=================================================================\n",
            "Total params: 2,400\n",
            "Trainable params: 2,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_56\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 2, 32)]           0         \n",
            "_________________________________________________________________\n",
            "model_54 (Functional)        (None, 20)                2570      \n",
            "_________________________________________________________________\n",
            "gaussian_noise_20 (GaussianN (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "model_55 (Functional)        (None, 2, 32)             2400      \n",
            "=================================================================\n",
            "Total params: 4,970\n",
            "Trainable params: 4,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IidQMKlts65l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb72494-7bb1-4f3f-b109-bc6a3cf9d37c"
      },
      "source": [
        "NUM_OF_INPUT_MESSAGE = train_batch_size * 10\n",
        "training_input_message = numpy.random.randint(2**input_block_length, size=(NUM_OF_INPUT_MESSAGE,num_of_input_block,1))\n",
        "print(training_input_message)\n",
        "training_input_message_one_hot = to_categorical(y=training_input_message, num_classes=2**input_block_length)\n",
        "print(training_input_message_one_hot)\n",
        "\n",
        "test_input_message = numpy.random.randint(2**input_block_length, size=(NUM_OF_INPUT_MESSAGE,num_of_input_block,1))\n",
        "print(test_input_message)\n",
        "test_input_message_one_hot = to_categorical(y=test_input_message, num_classes=2**input_block_length)\n",
        "print(test_input_message_one_hot)\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[10]\n",
            "  [24]]\n",
            "\n",
            " [[25]\n",
            "  [19]]\n",
            "\n",
            " [[ 2]\n",
            "  [13]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 4]\n",
            "  [ 0]]\n",
            "\n",
            " [[11]\n",
            "  [15]]\n",
            "\n",
            " [[ 5]\n",
            "  [15]]]\n",
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]]\n",
            "[[[ 9]\n",
            "  [ 8]]\n",
            "\n",
            " [[ 2]\n",
            "  [15]]\n",
            "\n",
            " [[ 9]\n",
            "  [24]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[10]\n",
            "  [24]]\n",
            "\n",
            " [[14]\n",
            "  [23]]\n",
            "\n",
            " [[28]\n",
            "  [18]]]\n",
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbiBvRFNtUly",
        "outputId": "fcb10452-8e5a-4d47-bed9-b466f75fa1d1"
      },
      "source": [
        "import keras\n",
        "autoencoder.compile(optimizer=keras.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  snr_std = sigma\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  autoencoder.fit(training_input_message_one_hot, training_input_message,\n",
        "                epochs=50,\n",
        "                batch_size=train_batch_size,\n",
        "                shuffle=False,\n",
        "                validation_data=(test_input_message_one_hot, test_input_message))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for SNR= 0.0  sigma= 1.0\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 26ms/step - loss: 3.5664 - sparse_categorical_accuracy: 0.0409 - val_loss: 3.4789 - val_sparse_categorical_accuracy: 0.0475\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4660 - sparse_categorical_accuracy: 0.0564 - val_loss: 3.3877 - val_sparse_categorical_accuracy: 0.0696\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3849 - sparse_categorical_accuracy: 0.0770 - val_loss: 3.3087 - val_sparse_categorical_accuracy: 0.1227\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3076 - sparse_categorical_accuracy: 0.1204 - val_loss: 3.2346 - val_sparse_categorical_accuracy: 0.1993\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2395 - sparse_categorical_accuracy: 0.1769 - val_loss: 3.1636 - val_sparse_categorical_accuracy: 0.2980\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1772 - sparse_categorical_accuracy: 0.2321 - val_loss: 3.0945 - val_sparse_categorical_accuracy: 0.3918\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1157 - sparse_categorical_accuracy: 0.2759 - val_loss: 3.0268 - val_sparse_categorical_accuracy: 0.4738\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.0481 - sparse_categorical_accuracy: 0.3390 - val_loss: 2.9601 - val_sparse_categorical_accuracy: 0.5370\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.9929 - sparse_categorical_accuracy: 0.3783 - val_loss: 2.8943 - val_sparse_categorical_accuracy: 0.5810\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.9348 - sparse_categorical_accuracy: 0.4034 - val_loss: 2.8289 - val_sparse_categorical_accuracy: 0.6249\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8795 - sparse_categorical_accuracy: 0.4366 - val_loss: 2.7638 - val_sparse_categorical_accuracy: 0.6608\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.8232 - sparse_categorical_accuracy: 0.4561 - val_loss: 2.6987 - val_sparse_categorical_accuracy: 0.6918\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.7684 - sparse_categorical_accuracy: 0.4758 - val_loss: 2.6333 - val_sparse_categorical_accuracy: 0.7188\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.7159 - sparse_categorical_accuracy: 0.4884 - val_loss: 2.5677 - val_sparse_categorical_accuracy: 0.7463\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6654 - sparse_categorical_accuracy: 0.5044 - val_loss: 2.5021 - val_sparse_categorical_accuracy: 0.7639\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.6153 - sparse_categorical_accuracy: 0.5122 - val_loss: 2.4362 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5537 - sparse_categorical_accuracy: 0.5389 - val_loss: 2.3703 - val_sparse_categorical_accuracy: 0.8097\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4983 - sparse_categorical_accuracy: 0.5475 - val_loss: 2.3039 - val_sparse_categorical_accuracy: 0.8241\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4535 - sparse_categorical_accuracy: 0.5538 - val_loss: 2.2378 - val_sparse_categorical_accuracy: 0.8389\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3993 - sparse_categorical_accuracy: 0.5699 - val_loss: 2.1719 - val_sparse_categorical_accuracy: 0.8490\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3471 - sparse_categorical_accuracy: 0.5752 - val_loss: 2.1064 - val_sparse_categorical_accuracy: 0.8669\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.2992 - sparse_categorical_accuracy: 0.5874 - val_loss: 2.0413 - val_sparse_categorical_accuracy: 0.8790\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.2510 - sparse_categorical_accuracy: 0.5977 - val_loss: 1.9773 - val_sparse_categorical_accuracy: 0.8926\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2129 - sparse_categorical_accuracy: 0.5984 - val_loss: 1.9147 - val_sparse_categorical_accuracy: 0.9003\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1479 - sparse_categorical_accuracy: 0.6214 - val_loss: 1.8528 - val_sparse_categorical_accuracy: 0.9100\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 2.1014 - sparse_categorical_accuracy: 0.6234 - val_loss: 1.7909 - val_sparse_categorical_accuracy: 0.9169\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.0642 - sparse_categorical_accuracy: 0.6277 - val_loss: 1.7314 - val_sparse_categorical_accuracy: 0.9226\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0227 - sparse_categorical_accuracy: 0.6437 - val_loss: 1.6732 - val_sparse_categorical_accuracy: 0.9284\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9770 - sparse_categorical_accuracy: 0.6411 - val_loss: 1.6161 - val_sparse_categorical_accuracy: 0.9403\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.9314 - sparse_categorical_accuracy: 0.6551 - val_loss: 1.5599 - val_sparse_categorical_accuracy: 0.9459\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8998 - sparse_categorical_accuracy: 0.6561 - val_loss: 1.5059 - val_sparse_categorical_accuracy: 0.9514\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8624 - sparse_categorical_accuracy: 0.6627 - val_loss: 1.4530 - val_sparse_categorical_accuracy: 0.9610\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8289 - sparse_categorical_accuracy: 0.6655 - val_loss: 1.4022 - val_sparse_categorical_accuracy: 0.9612\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.7764 - sparse_categorical_accuracy: 0.6752 - val_loss: 1.3511 - val_sparse_categorical_accuracy: 0.9665\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7459 - sparse_categorical_accuracy: 0.6870 - val_loss: 1.3016 - val_sparse_categorical_accuracy: 0.9711\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7167 - sparse_categorical_accuracy: 0.6860 - val_loss: 1.2544 - val_sparse_categorical_accuracy: 0.9735\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6753 - sparse_categorical_accuracy: 0.6945 - val_loss: 1.2072 - val_sparse_categorical_accuracy: 0.9772\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.6582 - sparse_categorical_accuracy: 0.6948 - val_loss: 1.1622 - val_sparse_categorical_accuracy: 0.9809\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6199 - sparse_categorical_accuracy: 0.6950 - val_loss: 1.1179 - val_sparse_categorical_accuracy: 0.9793\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5924 - sparse_categorical_accuracy: 0.7149 - val_loss: 1.0756 - val_sparse_categorical_accuracy: 0.9819\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.5533 - sparse_categorical_accuracy: 0.7116 - val_loss: 1.0337 - val_sparse_categorical_accuracy: 0.9886\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5256 - sparse_categorical_accuracy: 0.7224 - val_loss: 0.9930 - val_sparse_categorical_accuracy: 0.9895\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.5011 - sparse_categorical_accuracy: 0.7158 - val_loss: 0.9548 - val_sparse_categorical_accuracy: 0.9920\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4846 - sparse_categorical_accuracy: 0.7142 - val_loss: 0.9173 - val_sparse_categorical_accuracy: 0.9922\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4537 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.8808 - val_sparse_categorical_accuracy: 0.9939\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.4278 - sparse_categorical_accuracy: 0.7202 - val_loss: 0.8455 - val_sparse_categorical_accuracy: 0.9968\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.4045 - sparse_categorical_accuracy: 0.7323 - val_loss: 0.8115 - val_sparse_categorical_accuracy: 0.9981\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3790 - sparse_categorical_accuracy: 0.7259 - val_loss: 0.7787 - val_sparse_categorical_accuracy: 0.9987\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.3555 - sparse_categorical_accuracy: 0.7392 - val_loss: 0.7475 - val_sparse_categorical_accuracy: 0.9987\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.3359 - sparse_categorical_accuracy: 0.7382 - val_loss: 0.7167 - val_sparse_categorical_accuracy: 0.9996\n",
            "Training for SNR= 0.5  sigma= 0.9440608762859234\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3054 - sparse_categorical_accuracy: 0.7489 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2993 - sparse_categorical_accuracy: 0.7398 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2711 - sparse_categorical_accuracy: 0.7446 - val_loss: 0.6315 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2433 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.6046 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2382 - sparse_categorical_accuracy: 0.7473 - val_loss: 0.5798 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2216 - sparse_categorical_accuracy: 0.7439 - val_loss: 0.5554 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.2061 - sparse_categorical_accuracy: 0.7556 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1793 - sparse_categorical_accuracy: 0.7557 - val_loss: 0.5103 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1552 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.4885 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1579 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.4682 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1325 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.4499 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1182 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0979 - sparse_categorical_accuracy: 0.7591 - val_loss: 0.4128 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.1024 - sparse_categorical_accuracy: 0.7630 - val_loss: 0.3952 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0723 - sparse_categorical_accuracy: 0.7662 - val_loss: 0.3795 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0680 - sparse_categorical_accuracy: 0.7615 - val_loss: 0.3636 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0544 - sparse_categorical_accuracy: 0.7664 - val_loss: 0.3490 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0356 - sparse_categorical_accuracy: 0.7752 - val_loss: 0.3348 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0246 - sparse_categorical_accuracy: 0.7719 - val_loss: 0.3217 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0042 - sparse_categorical_accuracy: 0.7754 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.0128 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.2953 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9910 - sparse_categorical_accuracy: 0.7759 - val_loss: 0.2844 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9889 - sparse_categorical_accuracy: 0.7769 - val_loss: 0.2730 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9656 - sparse_categorical_accuracy: 0.7812 - val_loss: 0.2623 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.9778 - sparse_categorical_accuracy: 0.7692 - val_loss: 0.2517 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9564 - sparse_categorical_accuracy: 0.7747 - val_loss: 0.2420 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9529 - sparse_categorical_accuracy: 0.7783 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 0.9429 - sparse_categorical_accuracy: 0.7803 - val_loss: 0.2237 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9264 - sparse_categorical_accuracy: 0.7862 - val_loss: 0.2154 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9221 - sparse_categorical_accuracy: 0.7780 - val_loss: 0.2072 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9176 - sparse_categorical_accuracy: 0.7794 - val_loss: 0.1997 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8952 - sparse_categorical_accuracy: 0.7831 - val_loss: 0.1917 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.9044 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.1847 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8916 - sparse_categorical_accuracy: 0.7823 - val_loss: 0.1780 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8853 - sparse_categorical_accuracy: 0.7813 - val_loss: 0.1715 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8775 - sparse_categorical_accuracy: 0.7848 - val_loss: 0.1653 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8772 - sparse_categorical_accuracy: 0.7840 - val_loss: 0.1592 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8503 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.1539 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8497 - sparse_categorical_accuracy: 0.7886 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8537 - sparse_categorical_accuracy: 0.7854 - val_loss: 0.1433 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8443 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.1388 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8282 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.1339 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8445 - sparse_categorical_accuracy: 0.7834 - val_loss: 0.1293 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8369 - sparse_categorical_accuracy: 0.7819 - val_loss: 0.1249 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8348 - sparse_categorical_accuracy: 0.7839 - val_loss: 0.1207 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8162 - sparse_categorical_accuracy: 0.7937 - val_loss: 0.1166 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8192 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.1131 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8155 - sparse_categorical_accuracy: 0.7923 - val_loss: 0.1094 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8117 - sparse_categorical_accuracy: 0.7905 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7978 - sparse_categorical_accuracy: 0.7921 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 1.0  sigma= 0.8912509381337456\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.8214 - sparse_categorical_accuracy: 0.7818 - val_loss: 0.0997 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7951 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7863 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.0938 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7717 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.0907 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7863 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.0878 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7840 - sparse_categorical_accuracy: 0.7922 - val_loss: 0.0852 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7777 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.0829 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7584 - sparse_categorical_accuracy: 0.8009 - val_loss: 0.0806 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7805 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.0781 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7752 - sparse_categorical_accuracy: 0.7909 - val_loss: 0.0760 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7570 - sparse_categorical_accuracy: 0.7953 - val_loss: 0.0738 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7562 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.0718 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7628 - sparse_categorical_accuracy: 0.7865 - val_loss: 0.0698 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7523 - sparse_categorical_accuracy: 0.7956 - val_loss: 0.0677 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7358 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.0658 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7594 - sparse_categorical_accuracy: 0.7860 - val_loss: 0.0641 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7426 - sparse_categorical_accuracy: 0.7976 - val_loss: 0.0623 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7248 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.0607 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.7347 - sparse_categorical_accuracy: 0.7938 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7400 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.0578 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7301 - sparse_categorical_accuracy: 0.7972 - val_loss: 0.0564 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7352 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.0551 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7360 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.0536 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7403 - sparse_categorical_accuracy: 0.7888 - val_loss: 0.0522 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7212 - sparse_categorical_accuracy: 0.7988 - val_loss: 0.0508 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7142 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.0495 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7265 - sparse_categorical_accuracy: 0.7930 - val_loss: 0.0484 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7151 - sparse_categorical_accuracy: 0.7942 - val_loss: 0.0473 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7121 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.0462 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7165 - sparse_categorical_accuracy: 0.7953 - val_loss: 0.0450 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7018 - sparse_categorical_accuracy: 0.8029 - val_loss: 0.0440 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7057 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.0429 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7097 - sparse_categorical_accuracy: 0.7941 - val_loss: 0.0419 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7125 - sparse_categorical_accuracy: 0.7979 - val_loss: 0.0410 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7062 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.0401 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7046 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.0392 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.8029 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7099 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.0375 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6854 - sparse_categorical_accuracy: 0.8012 - val_loss: 0.0367 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6827 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.0360 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7055 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.0351 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.0344 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.7943 - val_loss: 0.0337 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.0331 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6857 - sparse_categorical_accuracy: 0.8010 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6643 - sparse_categorical_accuracy: 0.8066 - val_loss: 0.0317 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6811 - sparse_categorical_accuracy: 0.8009 - val_loss: 0.0310 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6763 - sparse_categorical_accuracy: 0.8018 - val_loss: 0.0303 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6790 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.0297 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.0292 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 1.5  sigma= 0.8413951416451951\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6832 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.0286 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6694 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.0281 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6773 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.0276 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6722 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.0272 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6570 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6680 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.0261 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6724 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6728 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.0252 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6725 - sparse_categorical_accuracy: 0.7995 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6604 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6639 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.0239 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6592 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6597 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.0231 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6859 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.0227 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6700 - sparse_categorical_accuracy: 0.7981 - val_loss: 0.0223 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6534 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.0219 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6616 - sparse_categorical_accuracy: 0.8002 - val_loss: 0.0216 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6640 - sparse_categorical_accuracy: 0.7980 - val_loss: 0.0213 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.6787 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.0205 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6491 - sparse_categorical_accuracy: 0.8042 - val_loss: 0.0201 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6419 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.0198 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6631 - sparse_categorical_accuracy: 0.7970 - val_loss: 0.0195 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.0193 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6525 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6556 - sparse_categorical_accuracy: 0.8032 - val_loss: 0.0186 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6500 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.0184 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6593 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.0181 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6471 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.0178 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6449 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.0176 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6436 - sparse_categorical_accuracy: 0.8039 - val_loss: 0.0173 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6384 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.0170 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6441 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.0167 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.0165 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6469 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.0162 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6488 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.0160 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6445 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.0158 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6369 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.0156 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6557 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.0153 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6282 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.0152 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6628 - sparse_categorical_accuracy: 0.7969 - val_loss: 0.0150 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6393 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.0147 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6434 - sparse_categorical_accuracy: 0.8029 - val_loss: 0.0146 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6447 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.0144 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6349 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.0142 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6451 - sparse_categorical_accuracy: 0.8029 - val_loss: 0.0140 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6446 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.0139 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6395 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6282 - sparse_categorical_accuracy: 0.8079 - val_loss: 0.0135 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6129 - sparse_categorical_accuracy: 0.8119 - val_loss: 0.0134 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 2.0  sigma= 0.7943282347242815\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6500 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.0132 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6477 - sparse_categorical_accuracy: 0.8059 - val_loss: 0.0130 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6210 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.0128 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6398 - sparse_categorical_accuracy: 0.8024 - val_loss: 0.0126 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6332 - sparse_categorical_accuracy: 0.8058 - val_loss: 0.0125 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6370 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.0123 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.0122 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6422 - sparse_categorical_accuracy: 0.8018 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6322 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.0119 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6409 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.0117 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6182 - sparse_categorical_accuracy: 0.8127 - val_loss: 0.0116 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6380 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.0115 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6387 - sparse_categorical_accuracy: 0.8027 - val_loss: 0.0114 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6226 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.0112 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6267 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.0111 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6319 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.0110 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6290 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.0109 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6312 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.0108 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6137 - sparse_categorical_accuracy: 0.8150 - val_loss: 0.0106 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6109 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.0105 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6231 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.0104 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6124 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.0103 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6208 - sparse_categorical_accuracy: 0.8100 - val_loss: 0.0102 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6232 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.0100 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6063 - sparse_categorical_accuracy: 0.8141 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6183 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.0098 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.8055 - val_loss: 0.0097 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6240 - sparse_categorical_accuracy: 0.8073 - val_loss: 0.0096 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6251 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.0095 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6275 - sparse_categorical_accuracy: 0.8045 - val_loss: 0.0094 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6189 - sparse_categorical_accuracy: 0.8076 - val_loss: 0.0094 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5971 - sparse_categorical_accuracy: 0.8140 - val_loss: 0.0093 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6173 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6325 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6260 - sparse_categorical_accuracy: 0.8075 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6037 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.0089 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6261 - sparse_categorical_accuracy: 0.8067 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6332 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.0087 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6124 - sparse_categorical_accuracy: 0.8154 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6182 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.0086 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6388 - sparse_categorical_accuracy: 0.8022 - val_loss: 0.0085 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6189 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6012 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.0083 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6173 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.0082 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6097 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6115 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.0081 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6069 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.0080 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6142 - sparse_categorical_accuracy: 0.8097 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6214 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6241 - sparse_categorical_accuracy: 0.8061 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 2.5  sigma= 0.7498942093324559\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6186 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6027 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.0077 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6057 - sparse_categorical_accuracy: 0.8139 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6148 - sparse_categorical_accuracy: 0.8080 - val_loss: 0.0076 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5855 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6120 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6348 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5925 - sparse_categorical_accuracy: 0.8154 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6118 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6041 - sparse_categorical_accuracy: 0.8137 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6137 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.0071 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.6308 - sparse_categorical_accuracy: 0.8062 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6092 - sparse_categorical_accuracy: 0.8102 - val_loss: 0.0070 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6168 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6119 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6088 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6135 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.0068 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6216 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6010 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6055 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.0066 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6155 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.0065 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6048 - sparse_categorical_accuracy: 0.8098 - val_loss: 0.0065 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5898 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.0064 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6007 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.0064 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6033 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6021 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6122 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5942 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6013 - sparse_categorical_accuracy: 0.8128 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6135 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5906 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6073 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.0060 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6034 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6093 - sparse_categorical_accuracy: 0.8082 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5927 - sparse_categorical_accuracy: 0.8179 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6102 - sparse_categorical_accuracy: 0.8105 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5935 - sparse_categorical_accuracy: 0.8116 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6075 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6378 - sparse_categorical_accuracy: 0.8000 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6043 - sparse_categorical_accuracy: 0.8136 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6009 - sparse_categorical_accuracy: 0.8144 - val_loss: 0.0056 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.0056 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6108 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.0055 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5929 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.0055 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6164 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.0054 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5956 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.0054 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6120 - sparse_categorical_accuracy: 0.8055 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6233 - sparse_categorical_accuracy: 0.8036 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5902 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 3.0  sigma= 0.7079457843841379\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6014 - sparse_categorical_accuracy: 0.8138 - val_loss: 0.0053 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5996 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.0052 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5954 - sparse_categorical_accuracy: 0.8154 - val_loss: 0.0052 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5989 - sparse_categorical_accuracy: 0.8131 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6048 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.8133 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5957 - sparse_categorical_accuracy: 0.8123 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5998 - sparse_categorical_accuracy: 0.8144 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6064 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6073 - sparse_categorical_accuracy: 0.8046 - val_loss: 0.0050 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5951 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6006 - sparse_categorical_accuracy: 0.8139 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6022 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.0049 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6015 - sparse_categorical_accuracy: 0.8137 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6001 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5955 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6007 - sparse_categorical_accuracy: 0.8108 - val_loss: 0.0048 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5838 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5817 - sparse_categorical_accuracy: 0.8139 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5791 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5998 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5863 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6013 - sparse_categorical_accuracy: 0.8117 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5954 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6131 - sparse_categorical_accuracy: 0.8064 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6150 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6021 - sparse_categorical_accuracy: 0.8086 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6162 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5956 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6018 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5914 - sparse_categorical_accuracy: 0.8160 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5834 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.0044 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5963 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5961 - sparse_categorical_accuracy: 0.8137 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6013 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6132 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6007 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5797 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5872 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5897 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.0042 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6044 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6153 - sparse_categorical_accuracy: 0.8014 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5900 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5843 - sparse_categorical_accuracy: 0.8167 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5987 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.0041 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6059 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5881 - sparse_categorical_accuracy: 0.8129 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5864 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 3.5  sigma= 0.6683439175686147\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6004 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5947 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5939 - sparse_categorical_accuracy: 0.8140 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6140 - sparse_categorical_accuracy: 0.8107 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6012 - sparse_categorical_accuracy: 0.8137 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5815 - sparse_categorical_accuracy: 0.8167 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5934 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5869 - sparse_categorical_accuracy: 0.8197 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5850 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5899 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5983 - sparse_categorical_accuracy: 0.8138 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5724 - sparse_categorical_accuracy: 0.8233 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5996 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6117 - sparse_categorical_accuracy: 0.8042 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5942 - sparse_categorical_accuracy: 0.8129 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5770 - sparse_categorical_accuracy: 0.8158 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5943 - sparse_categorical_accuracy: 0.8157 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6066 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5905 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5724 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5907 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5760 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.0037 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6007 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5924 - sparse_categorical_accuracy: 0.8138 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5798 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5659 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5901 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.0036 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5824 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5849 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5844 - sparse_categorical_accuracy: 0.8173 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5885 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5979 - sparse_categorical_accuracy: 0.8160 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5857 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5898 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5985 - sparse_categorical_accuracy: 0.8150 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5788 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5928 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5895 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5770 - sparse_categorical_accuracy: 0.8190 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5908 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5795 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5833 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5855 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5695 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5962 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5732 - sparse_categorical_accuracy: 0.8204 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5965 - sparse_categorical_accuracy: 0.8132 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5965 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 4.0  sigma= 0.6309573444801932\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5956 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5904 - sparse_categorical_accuracy: 0.8154 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5775 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5913 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5827 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5597 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5909 - sparse_categorical_accuracy: 0.8147 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5854 - sparse_categorical_accuracy: 0.8150 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5753 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5739 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5829 - sparse_categorical_accuracy: 0.8161 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5782 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5745 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5757 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6026 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5661 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5829 - sparse_categorical_accuracy: 0.8160 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5752 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5875 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5981 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5834 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5897 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5870 - sparse_categorical_accuracy: 0.8149 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5841 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5875 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5702 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5822 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5787 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5770 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5874 - sparse_categorical_accuracy: 0.8182 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5800 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5717 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6133 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5844 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5904 - sparse_categorical_accuracy: 0.8122 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5727 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5929 - sparse_categorical_accuracy: 0.8158 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5902 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5810 - sparse_categorical_accuracy: 0.8176 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5932 - sparse_categorical_accuracy: 0.8158 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5737 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5684 - sparse_categorical_accuracy: 0.8232 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.8261 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5885 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5892 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 4.5  sigma= 0.5956621435290105\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5887 - sparse_categorical_accuracy: 0.8169 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.8210 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5752 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5610 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5803 - sparse_categorical_accuracy: 0.8152 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5793 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5947 - sparse_categorical_accuracy: 0.8112 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5757 - sparse_categorical_accuracy: 0.8172 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5951 - sparse_categorical_accuracy: 0.8147 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5836 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5820 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5594 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5600 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.8228 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5825 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5798 - sparse_categorical_accuracy: 0.8182 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5775 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5848 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.8196 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5554 - sparse_categorical_accuracy: 0.8251 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5895 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5770 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5847 - sparse_categorical_accuracy: 0.8160 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.8131 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5523 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5722 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.8197 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5628 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5577 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5679 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5759 - sparse_categorical_accuracy: 0.8159 - val_loss: 0.0026 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5583 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5609 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5773 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 0.5932 - sparse_categorical_accuracy: 0.8163 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5795 - sparse_categorical_accuracy: 0.8171 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5624 - sparse_categorical_accuracy: 0.8242 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5703 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 5.0  sigma= 0.5623413251903491\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5682 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5722 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5591 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.8136 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5576 - sparse_categorical_accuracy: 0.8269 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5976 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5473 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5864 - sparse_categorical_accuracy: 0.8149 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5538 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5838 - sparse_categorical_accuracy: 0.8135 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5801 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5772 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5762 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5590 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5660 - sparse_categorical_accuracy: 0.8239 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5882 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5668 - sparse_categorical_accuracy: 0.8182 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5600 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5553 - sparse_categorical_accuracy: 0.8244 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5755 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5665 - sparse_categorical_accuracy: 0.8209 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5673 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5672 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5575 - sparse_categorical_accuracy: 0.8232 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5804 - sparse_categorical_accuracy: 0.8149 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5565 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5534 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5490 - sparse_categorical_accuracy: 0.8242 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5577 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5583 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.0024 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.8241 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5496 - sparse_categorical_accuracy: 0.8274 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.8261 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5666 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5565 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5620 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5730 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5555 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5695 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5767 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5662 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5730 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5692 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 5.5  sigma= 0.5308844442309884\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5654 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5725 - sparse_categorical_accuracy: 0.8199 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5694 - sparse_categorical_accuracy: 0.8228 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5556 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5666 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5615 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5685 - sparse_categorical_accuracy: 0.8262 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5584 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5775 - sparse_categorical_accuracy: 0.8210 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5814 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5487 - sparse_categorical_accuracy: 0.8316 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5648 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5862 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5711 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5554 - sparse_categorical_accuracy: 0.8241 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5861 - sparse_categorical_accuracy: 0.8168 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5625 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5884 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5518 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5618 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5674 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5785 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5514 - sparse_categorical_accuracy: 0.8263 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5712 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5533 - sparse_categorical_accuracy: 0.8279 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5548 - sparse_categorical_accuracy: 0.8282 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5701 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5595 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5700 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5468 - sparse_categorical_accuracy: 0.8279 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5818 - sparse_categorical_accuracy: 0.8147 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5805 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5584 - sparse_categorical_accuracy: 0.8204 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5498 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5586 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.8271 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5709 - sparse_categorical_accuracy: 0.8180 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5610 - sparse_categorical_accuracy: 0.8248 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5641 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5790 - sparse_categorical_accuracy: 0.8173 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 6.0  sigma= 0.5011872336272722\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5700 - sparse_categorical_accuracy: 0.8200 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5702 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5808 - sparse_categorical_accuracy: 0.8183 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5714 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5713 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5523 - sparse_categorical_accuracy: 0.8217 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5673 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5657 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5548 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5854 - sparse_categorical_accuracy: 0.8185 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5544 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5589 - sparse_categorical_accuracy: 0.8207 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5606 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5640 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.8193 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5493 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5500 - sparse_categorical_accuracy: 0.8304 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5598 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.8233 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5656 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.8185 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5512 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5637 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5630 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5756 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5728 - sparse_categorical_accuracy: 0.8228 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5597 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5729 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.8251 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5590 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5826 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5541 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5546 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5650 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5732 - sparse_categorical_accuracy: 0.8232 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5574 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5397 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5583 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5701 - sparse_categorical_accuracy: 0.8173 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5710 - sparse_categorical_accuracy: 0.8207 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5653 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5534 - sparse_categorical_accuracy: 0.8269 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5680 - sparse_categorical_accuracy: 0.8209 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 6.5  sigma= 0.47315125896148047\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5462 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5419 - sparse_categorical_accuracy: 0.8309 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5615 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5360 - sparse_categorical_accuracy: 0.8308 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5682 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5566 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5669 - sparse_categorical_accuracy: 0.8242 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5609 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5561 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5615 - sparse_categorical_accuracy: 0.8263 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.8272 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5650 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.8204 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5592 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5622 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5589 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5611 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5363 - sparse_categorical_accuracy: 0.8335 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5640 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5561 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5500 - sparse_categorical_accuracy: 0.8262 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5519 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5534 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5771 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5645 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5619 - sparse_categorical_accuracy: 0.8244 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5381 - sparse_categorical_accuracy: 0.8319 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5472 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5624 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5550 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5692 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5441 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5658 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5737 - sparse_categorical_accuracy: 0.8235 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5456 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5564 - sparse_categorical_accuracy: 0.8263 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5356 - sparse_categorical_accuracy: 0.8342 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5704 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5537 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 7.0  sigma= 0.44668359215096315\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5591 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5636 - sparse_categorical_accuracy: 0.8244 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5754 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5557 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5698 - sparse_categorical_accuracy: 0.8194 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5525 - sparse_categorical_accuracy: 0.8251 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5472 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5652 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5425 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5668 - sparse_categorical_accuracy: 0.8217 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5546 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5624 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5588 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.8223 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5455 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5644 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5764 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5743 - sparse_categorical_accuracy: 0.8187 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.8260 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5683 - sparse_categorical_accuracy: 0.8207 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5625 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5849 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5402 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5563 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5457 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.0020 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5563 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5663 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5554 - sparse_categorical_accuracy: 0.8193 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5662 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.8262 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5373 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5440 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5437 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5648 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5410 - sparse_categorical_accuracy: 0.8304 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.8300 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 7.5  sigma= 0.4216965034285822\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5405 - sparse_categorical_accuracy: 0.8301 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5663 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5506 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5350 - sparse_categorical_accuracy: 0.8309 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5434 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5482 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5556 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5480 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5453 - sparse_categorical_accuracy: 0.8288 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.8289 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5715 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5489 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.8282 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5482 - sparse_categorical_accuracy: 0.8290 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5612 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5436 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.8311 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5381 - sparse_categorical_accuracy: 0.8319 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5685 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5654 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5560 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5371 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5370 - sparse_categorical_accuracy: 0.8248 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5789 - sparse_categorical_accuracy: 0.8167 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.5414 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5652 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5595 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5634 - sparse_categorical_accuracy: 0.8211 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5509 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5545 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5600 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5723 - sparse_categorical_accuracy: 0.8193 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5541 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.8282 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5437 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5434 - sparse_categorical_accuracy: 0.8290 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.8293 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5703 - sparse_categorical_accuracy: 0.8205 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5617 - sparse_categorical_accuracy: 0.8269 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5487 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 8.0  sigma= 0.3981071705534972\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5530 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.8272 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5760 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5659 - sparse_categorical_accuracy: 0.8234 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5485 - sparse_categorical_accuracy: 0.8275 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5696 - sparse_categorical_accuracy: 0.8204 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5518 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5476 - sparse_categorical_accuracy: 0.8271 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5694 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5692 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5652 - sparse_categorical_accuracy: 0.8205 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5425 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5520 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5492 - sparse_categorical_accuracy: 0.8271 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5552 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5380 - sparse_categorical_accuracy: 0.8296 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.8279 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5434 - sparse_categorical_accuracy: 0.8288 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5387 - sparse_categorical_accuracy: 0.8343 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5563 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5435 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5718 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5687 - sparse_categorical_accuracy: 0.8200 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5357 - sparse_categorical_accuracy: 0.8311 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5395 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5565 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.8232 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5637 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.8243 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5364 - sparse_categorical_accuracy: 0.8305 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5576 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.8232 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5648 - sparse_categorical_accuracy: 0.8232 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5419 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5571 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5510 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5477 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5600 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 8.5  sigma= 0.3758374042884442\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.5559 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5542 - sparse_categorical_accuracy: 0.8245 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5496 - sparse_categorical_accuracy: 0.8224 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5533 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8256 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8261 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5392 - sparse_categorical_accuracy: 0.8331 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5281 - sparse_categorical_accuracy: 0.8325 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5631 - sparse_categorical_accuracy: 0.8203 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5610 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5489 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.8256 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5529 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5485 - sparse_categorical_accuracy: 0.8263 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5498 - sparse_categorical_accuracy: 0.8233 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5371 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5304 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5539 - sparse_categorical_accuracy: 0.8290 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5612 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5613 - sparse_categorical_accuracy: 0.8209 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5679 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 0.5416 - sparse_categorical_accuracy: 0.8306 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5510 - sparse_categorical_accuracy: 0.8265 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5437 - sparse_categorical_accuracy: 0.8311 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5473 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5730 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5702 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5456 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.8317 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5317 - sparse_categorical_accuracy: 0.8330 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5639 - sparse_categorical_accuracy: 0.8200 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5386 - sparse_categorical_accuracy: 0.8349 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5428 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5405 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5513 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5409 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5507 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5543 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5589 - sparse_categorical_accuracy: 0.8268 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5504 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5490 - sparse_categorical_accuracy: 0.8303 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5432 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.5601 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5414 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 9.0  sigma= 0.35481338923357547\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5431 - sparse_categorical_accuracy: 0.8312 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5470 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5623 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5405 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5330 - sparse_categorical_accuracy: 0.8313 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5568 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5239 - sparse_categorical_accuracy: 0.8358 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5566 - sparse_categorical_accuracy: 0.8280 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5780 - sparse_categorical_accuracy: 0.8193 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5515 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5418 - sparse_categorical_accuracy: 0.8276 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5545 - sparse_categorical_accuracy: 0.8244 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5468 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.8304 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5393 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5745 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5706 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5621 - sparse_categorical_accuracy: 0.8239 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5385 - sparse_categorical_accuracy: 0.8331 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5625 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.8320 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5487 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5241 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5219 - sparse_categorical_accuracy: 0.8356 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5514 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5433 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5281 - sparse_categorical_accuracy: 0.8334 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5483 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5615 - sparse_categorical_accuracy: 0.8269 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.8298 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5530 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5404 - sparse_categorical_accuracy: 0.8374 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5510 - sparse_categorical_accuracy: 0.8285 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5363 - sparse_categorical_accuracy: 0.8290 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5543 - sparse_categorical_accuracy: 0.8263 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5366 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5563 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5493 - sparse_categorical_accuracy: 0.8270 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5490 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5482 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5707 - sparse_categorical_accuracy: 0.8247 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.8220 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5441 - sparse_categorical_accuracy: 0.8311 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5493 - sparse_categorical_accuracy: 0.8254 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Training for SNR= 9.5  sigma= 0.33496543915782767\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5376 - sparse_categorical_accuracy: 0.8282 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5262 - sparse_categorical_accuracy: 0.8317 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5393 - sparse_categorical_accuracy: 0.8308 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5635 - sparse_categorical_accuracy: 0.8207 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5488 - sparse_categorical_accuracy: 0.8266 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5412 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5297 - sparse_categorical_accuracy: 0.8304 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5356 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5462 - sparse_categorical_accuracy: 0.8269 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5676 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5654 - sparse_categorical_accuracy: 0.8251 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5351 - sparse_categorical_accuracy: 0.8312 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5390 - sparse_categorical_accuracy: 0.8324 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5798 - sparse_categorical_accuracy: 0.8192 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5482 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5307 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.5459 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.5473 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5519 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5458 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5672 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5320 - sparse_categorical_accuracy: 0.8342 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5530 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.8309 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5514 - sparse_categorical_accuracy: 0.8267 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.8284 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.8287 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5564 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5305 - sparse_categorical_accuracy: 0.8321 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5480 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5769 - sparse_categorical_accuracy: 0.8218 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5465 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5370 - sparse_categorical_accuracy: 0.8343 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5402 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5611 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5519 - sparse_categorical_accuracy: 0.8249 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.8272 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5559 - sparse_categorical_accuracy: 0.8257 - val_loss: 0.0018 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5507 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5561 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5549 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5389 - sparse_categorical_accuracy: 0.8312 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjVpOnoOuF0o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ebfc1e4-dd3d-4e29-a3a3-eb4db613cd8d"
      },
      "source": [
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "#train_init = tf.global_variables_initializer ()\n",
        "#train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = training_input_message_one_hot [i:i+1]\n",
        "    print (input_message_xx)\n",
        "    #print (\"input\", input_message_xx)\n",
        "    #train_batch_size = 500\n",
        "    encoded_message = encoder.predict(training_input_message_one_hot)\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,CHANEL_SIZE])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,2*channel_size])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output1\", numpy.argmax(training_input_message_one_hot[i]))\n",
        "    #print (\"output2\", numpy.argmax(decoded_message[0]))\n",
        "    #print (\"output2\", training_input_message[0][i])\n",
        "    if (numpy.argmax(training_input_message_one_hot[i]) != numpy.argmax(decoded_message[0])):\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]]]\n",
            "[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 1. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 1. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 1. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 1. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]]]\n",
            "[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 1. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   1. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "   0. 0. 0. 0. 0. 0. 0. 1. 0.]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-62c4bd0150f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print (\"input\", input_message_xx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#train_batch_size = 500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mencoded_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_input_message_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m#encoded_message = numpy.around(encoded_message > 0.5).astype(int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#print(\"encoded:\",encoded_message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRESmjgq4c0V",
        "outputId": "6056b463-eb12-4241-fbbc-26f05c15d987"
      },
      "source": [
        "training_input_message_binary = conv_to_binary_from_decimal (training_input_message,NUM_OF_INPUT_MESSAGE*10,  input_message_length)\r\n",
        "ber_per_iter_dl_tensor, bler_per_iter_dl_tensor, channel_out  = get_onehot_ber_bler_of_model (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE), \r\n",
        "          encoder, decoder, \r\n",
        "          training_input_message_one_hot, \r\n",
        "          training_input_message_binary [0:NUM_OF_INPUT_MESSAGE*10], \r\n",
        "          NUM_OF_INPUT_MESSAGE*10, input_message_length,channel_size)\r\n",
        "print (ber_per_iter_dl_tensor)\r\n",
        "print (bler_per_iter_dl_tensor)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000:-> BLER: 0.336 BER: 0.168\n",
            "SNR: 0.500:-> BLER: 0.273 BER: 0.137\n",
            "SNR: 1.000:-> BLER: 0.209 BER: 0.106\n",
            "SNR: 1.500:-> BLER: 0.155 BER: 0.077\n",
            "SNR: 2.000:-> BLER: 0.102 BER: 0.051\n",
            "SNR: 2.500:-> BLER: 0.069 BER: 0.035\n",
            "SNR: 3.000:-> BLER: 0.044 BER: 0.022\n",
            "SNR: 3.500:-> BLER: 0.025 BER: 0.013\n",
            "SNR: 4.000:-> BLER: 0.014 BER: 0.007\n",
            "SNR: 4.500:-> BLER: 0.008 BER: 0.004\n",
            "SNR: 5.000:-> BLER: 0.003 BER: 0.001\n",
            "SNR: 5.500:-> BLER: 0.001 BER: 0.000\n",
            "SNR: 6.000:-> BLER: 0.001 BER: 0.000\n",
            "SNR: 6.500:-> BLER: 0.000 BER: 0.000\n",
            "SNR: 7.000:-> BLER: 0.000 BER: 0.000\n",
            "SNR: 7.500:-> BLER: 0.000 BER: 0.000\n",
            "SNR: 8.000:-> BLER: 0.000 BER: 0.000\n",
            "SNR: 8.500:-> BLER: 0.000 BER: 0.000\n",
            "SNR: 9.000:-> BLER: 0.000 BER: 0.000\n",
            "SNR: 9.500:-> BLER: 0.000 BER: 0.000\n",
            "[1.6763e-01 1.3702e-01 1.0564e-01 7.6820e-02 5.1310e-02 3.4700e-02\n",
            " 2.2130e-02 1.2500e-02 6.7000e-03 4.0300e-03 1.4100e-03 4.8000e-04\n",
            " 4.5000e-04 8.0000e-05 1.3000e-04 5.0000e-05 0.0000e+00 5.0000e-05\n",
            " 0.0000e+00 0.0000e+00]\n",
            "[3.357e-01 2.728e-01 2.092e-01 1.550e-01 1.017e-01 6.940e-02 4.380e-02\n",
            " 2.520e-02 1.360e-02 7.700e-03 2.700e-03 1.100e-03 1.100e-03 2.000e-04\n",
            " 2.000e-04 1.000e-04 0.000e+00 1.000e-04 0.000e+00 0.000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cALSMP2YvKvC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "8a57e9d5-743a-41c2-ed31-42aa845a5229"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(input=9,channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}