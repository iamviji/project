{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN-fading-channel_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWt+iMziAMunW4u6pORC+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/PostMidTerm/ref/DNN_fading_channel_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "L22bXNQquj7S",
        "outputId": "ad16b23d-2469-48d1-999c-ee436730674d"
      },
      "source": [
        "# importing libs\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import scipy.io\r\n",
        "import keras\r\n",
        "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout\r\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\r\n",
        "from keras.models import Model\r\n",
        "from keras import regularizers\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.optimizers import Adam,SGD\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "\r\n",
        "# for reproducing reslut\r\n",
        "from numpy.random import seed\r\n",
        "seed(1)\r\n",
        "#from tensorflow import set_random_seed\r\n",
        "#set_random_seed(3)\r\n",
        "#tf.compat.v1.set_random_seed(3)\r\n",
        "\r\n",
        "# defining parameters\r\n",
        "# define (n,k) here for (n,k) autoencoder\r\n",
        "# n = n_channel\r\n",
        "# k = log2(M)  ==> so for (7,4) autoencoder n_channel = 7 and M = 2^4 = 16\r\n",
        "M = 16\r\n",
        "k = np.log2(M)\r\n",
        "k = int(k)\r\n",
        "n_channel: int = 7\r\n",
        "R = k/n_channel\r\n",
        "print('M:',M,'k:',k,'n:',n_channel)\r\n",
        "\r\n",
        "N_train = 200000\r\n",
        "N_test = 100000\r\n",
        "EPOCHS = 50\r\n",
        "BATCH_SIZE = 256\r\n",
        "EbNo_train_dB = 15\r\n",
        "EbNo_train = 10**(EbNo_train_dB/10);#5.01187 #  coverted 7 db of EbNo\r\n",
        "print('EbNo_train', EbNo_train)\r\n",
        "label = np.random.randint(M,size=N_train)\r\n",
        "\r\n",
        "# creating one hot encoded vectors\r\n",
        "data = []\r\n",
        "for i in label:\r\n",
        "    temp = np.zeros(M)\r\n",
        "    temp[i] = 1\r\n",
        "    data.append(temp)\r\n",
        "\r\n",
        "# checking data shape\r\n",
        "data = np.array(data)\r\n",
        "print(data.shape)\r\n",
        "\r\n",
        "import matlab.engine\r\n",
        "eng = matlab.engine.start_matlab()\r\n",
        "eng.cd(r'/Users/shlim/Desktop/UWC simulator v2')\r\n",
        "eng.channel_gen(N_train, N_test, n_channel, nargout=0)\r\n",
        "\r\n",
        "\r\n",
        "# checking generated data with it's label\r\n",
        "#temp_check = [17,23,45,67,89,96,72,250,350]\r\n",
        "#for i in temp_check:\r\n",
        "#    print(label[i],data[i])\r\n",
        "from scipy.io import loadmat\r\n",
        "matlab_data1 = loadmat('channel_train.mat')\r\n",
        "#h_train=matlab_data1['h_train']\r\n",
        "h_train=np.absolute(matlab_data1['h_train'])\r\n",
        "matlab_data2 = loadmat('channel_test.mat')\r\n",
        "#h_test=matlab_data2['h_test']\r\n",
        "h_test=np.absolute(matlab_data2['h_test'])\r\n",
        "print('h_train=', h_train.shape)\r\n",
        "print('h_test=', h_test.shape)\r\n",
        "\r\n",
        "# defining autoencoder and it's layer\r\n",
        "input_signal = Input(shape=(M,))\r\n",
        "encoded = Dense(M, activation='relu')(input_signal)\r\n",
        "encoded1 = Dense(n_channel, activation='linear')(encoded)\r\n",
        "encoded2 = Lambda(lambda x: np.sqrt(n_channel)*K.l2_normalize(x, axis=1))(encoded1)\r\n",
        "#encoded2 = BatchNormalization()(encoded1)\r\n",
        "\r\n",
        "h = Input(shape=(n_channel,))\r\n",
        "#hx = Lambda(lambda x: np.multiply(x[0], x[1]), output_shape=(n_channel,))([encoded2, h])\r\n",
        "hx = Lambda(lambda x: np.multiply(x[0], x[1]))([encoded2, h])\r\n",
        "y_out = GaussianNoise(np.sqrt(1 / (2 * R * EbNo_train)))(hx)\r\n",
        "y_prime = Lambda(lambda x: K.concatenate([x[0], x[1]]))([h, y_out])\r\n",
        "#y_prime = Lambda(lambda x: K.concatenate([x[0], np.multiply((np.multiply(h**2, (2 * R * EbNo_train))/(np.multiply(h**2, (2 * R * EbNo_train))+1)),x[1])]))([h, y_out])\r\n",
        "\r\n",
        "#decoded0 = Dropout(0.4)(decoded0)\r\n",
        "# decoded = Dense(M, activation='relu')(y_prime)\r\n",
        "# decoded1 = Dense(M, activation='softmax')(decoded)\r\n",
        "decoded0 = Dense(M, activation='linear')(y_prime)\r\n",
        "#decoded0 = LeakyReLU(alpha=0.01)(y_prime)\r\n",
        "decoded = Dense(M, activation='relu')(decoded0)\r\n",
        "decoded1 = Dense(M, activation='softmax')(decoded)\r\n",
        "\r\n",
        "autoencoder = Model(inputs=[input_signal, h], outputs=decoded1)\r\n",
        "adam = Adam(lr=0.01)\r\n",
        "autoencoder.compile(optimizer='rmsprop', loss='categorical_crossentropy')\r\n",
        "# adam\r\n",
        "# rmsprop\r\n",
        "# printing summary of layers and it's trainable parameters\r\n",
        "print(autoencoder.summary())\r\n",
        "\r\n",
        "# traning auto encoder\r\n",
        "autoencoder.fit([data, h_train], data,\r\n",
        "                epochs=EPOCHS,\r\n",
        "                batch_size=BATCH_SIZE)\r\n",
        "\r\n",
        "# saving keras model\r\n",
        "from keras.models import load_model\r\n",
        "# if you want to save model then remove below comment\r\n",
        "# autoencoder.save('autoencoder_v_best.model')\r\n",
        "\r\n",
        "# making encoder from full autoencoder\r\n",
        "encoder = Model(input_signal, encoded2)\r\n",
        "\r\n",
        "# making decoder from full autoencoder\r\n",
        "encoded_input = Input(shape=(2*n_channel,))\r\n",
        "\r\n",
        "deco1 = autoencoder.layers[-3](encoded_input)\r\n",
        "deco = autoencoder.layers[-2](deco1)\r\n",
        "deco = autoencoder.layers[-1](deco)\r\n",
        "decoder = Model(encoded_input, deco)\r\n",
        "\r\n",
        "# deco = autoencoder.layers[-2](encoded_input)\r\n",
        "# deco = autoencoder.layers[-1](deco)\r\n",
        "# decoder = Model(encoded_input, deco)\r\n",
        "\r\n",
        "# generating data for checking BER\r\n",
        "# if you're not using t-sne for visulation than set N to 70,000 for better result\r\n",
        "# for t-sne use less N like N = 1500\r\n",
        "\r\n",
        "test_label = np.random.randint(M, size=N_test)\r\n",
        "test_data = []\r\n",
        "\r\n",
        "for i in test_label:\r\n",
        "    temp = np.zeros(M)\r\n",
        "    temp[i] = 1\r\n",
        "    test_data.append(temp)\r\n",
        "\r\n",
        "test_data = np.array(test_data)\r\n",
        "\r\n",
        "\r\n",
        "# checking generated data\r\n",
        "temp_test = 6\r\n",
        "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])\r\n",
        "\r\n",
        "# for plotting learned consteallation diagram\r\n",
        "#\r\n",
        "scatter_plot = []\r\n",
        "for i in range(0,M):\r\n",
        "    temp = np.zeros(M)\r\n",
        "    temp[i] = 1\r\n",
        "    scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\r\n",
        "scatter_plot = np.array(scatter_plot)\r\n",
        "print (scatter_plot.shape)\r\n",
        "\r\n",
        " # use this function for ploting constellation for higher dimenson like 7-D for (7,4) autoencoder\r\n",
        "#\r\n",
        "# x_emb = encoder.predict(test_data)\r\n",
        "# noise_std = np.sqrt(1/(2*R*5.011))\r\n",
        "# noise = noise_std * np.random.randn(N_test, n_channel)\r\n",
        "# #x_emb = np.multiply(h_test, x_emb) + noise\r\n",
        "# x_emb = x_emb + noise\r\n",
        "# from sklearn.manifold import TSNE\r\n",
        "# X_embedded = TSNE(learning_rate=700, n_components=2,n_iter=35000, random_state=0, perplexity=60).fit_transform(x_emb)\r\n",
        "# print (X_embedded.shape)\r\n",
        "# X_embedded = X_embedded / 7\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "# plt.scatter(X_embedded[:,0],X_embedded[:,1])\r\n",
        "# #plt.axis((-2.5,2.5,-2.5,2.5))\r\n",
        "# plt.grid()\r\n",
        "# plt.show()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# # ploting constellation diagram\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "scatter_plot = scatter_plot.reshape(M,n_channel,1)\r\n",
        "plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\r\n",
        "plt.axis((-2.5,2.5,-2.5,2.5))\r\n",
        "plt.grid()\r\n",
        "plt.show()\r\n",
        "scipy.io.savemat('constellation.mat', dict(constellation=scatter_plot))\r\n",
        "\r\n",
        "\r\n",
        "def frange(x, y, jump):\r\n",
        "  while x < y:\r\n",
        "    yield x\r\n",
        "    x += jump\r\n",
        "\r\n",
        "\r\n",
        "# calculating BER\r\n",
        "# this is optimized BER function so it can handle large number of N\r\n",
        "# previous code has another for loop which was making it slow\r\n",
        "EbNodB_range = list(frange(-5,20,0.5))\r\n",
        "ber = [None] * len(EbNodB_range)\r\n",
        "for n in range(0, len(EbNodB_range)):\r\n",
        "    EbNo = 10.0 ** (EbNodB_range[n] / 10.0)\r\n",
        "    noise_std = np.sqrt(1 / (2 * R * EbNo))\r\n",
        "    noise_mean = 0\r\n",
        "    no_errors = 0\r\n",
        "    nn = N_test\r\n",
        "    noise = noise_std * np.random.randn(nn, n_channel)\r\n",
        "    encoded_signal = encoder.predict(test_data)\r\n",
        "    #enc_sig_numpy = np.array(encoded_signal)\r\n",
        "    #ave_power = np.mean(np.square(enc_sig_numpy), axis=1)\r\n",
        "    #print(ave_power > 1)\r\n",
        "    #print('encoded signal:', enc_sig_numpy)\r\n",
        "    #print('encoded signal average power:', ave_power)\r\n",
        "    #print('encoded_signal size', encoded_signal.shape)\r\n",
        "    final_signal = np.multiply(h_test, encoded_signal) + noise\r\n",
        "    pred_final_signal = decoder.predict(np.concatenate([h_test, final_signal], axis=1))\r\n",
        "    pred_output = np.argmax(pred_final_signal, axis=1)\r\n",
        "    no_errors = (pred_output != test_label)\r\n",
        "    no_errors = no_errors.astype(int).sum()\r\n",
        "    ber[n] = no_errors / nn\r\n",
        "    print('SNR:', EbNodB_range[n], 'BER:', ber[n])\r\n",
        "    # use below line for generating matlab like matrix which can be copy and paste for plotting ber graph in matlab\r\n",
        "    # print(ber[n], \" \",end='')\r\n",
        "\r\n",
        "# ploting ber curve\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy import interpolate\r\n",
        "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder(7,4)')\r\n",
        "plt.yscale('log')\r\n",
        "plt.xlabel('SNR Range')\r\n",
        "plt.ylabel('Block Error Rate')\r\n",
        "plt.grid()\r\n",
        "plt.legend(loc='upper right',ncol = 1)\r\n",
        "\r\n",
        "# for saving figure remove below comment\r\n",
        "#plt.savefig('AutoEncoder_2_2_constrained_BER_matplotlib')\r\n",
        "scipy.io.savemat('DNN.mat', dict(EbNodB=EbNodB_range, ber=ber))\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M: 16 k: 4 n: 7\n",
            "EbNo_train 31.622776601683793\n",
            "(200000, 16)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7d4df1a519b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_matlab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/shlim/Desktop/UWC simulator v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matlab'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}