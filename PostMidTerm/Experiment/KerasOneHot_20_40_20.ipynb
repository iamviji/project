{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasOneHot_20_40_20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/PostMidTerm/Experiment/KerasOneHot_20_40_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dLvr1Rr1K8"
      },
      "source": [
        "import numpy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "input_message_length = 20\n",
        "encoder_output_length = 40\n",
        "channel_size = 20\n",
        "NUM_OF_INPUT_MESSAGE = 1000\n",
        "SNR_STEP_SIZE = .5\n",
        "\n",
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "\n",
        "bler_per_iter_uncoded_commpy_psk_2= [0.521, 0.473, 0.436, 0.37,  0.304, 0.259, 0.187, 0.138, 0.098, 0.098, 0.052, 0.028, 0.012, 0.011, 0.009, 0.002, 0.0,  0.001, 0.,    0.0]\n",
        "bler_per_iter_uncoded_itpp_psk_2= [0.518, 0.478, 0.415, 0.355, 0.305, 0.227, 0.177, 0.149, 0.11,  0.075, 0.055, 0.023, 0.014, 0.014, 0.015, 0.001, 0.003, 0.001, 0.,    0. ]\n",
        "bler_per_iter_uncoded_commpy_psk_4 = [0.815, 0.793, 0.75,  0.714, 0.64,  0.639, 0.526, 0.49,  0.433, 0.371, 0.335, 0.236, 0.204, 0.154, 0.129, 0.08,  0.063, 0.046, 0.023, 0.018]\n",
        "bler_per_iter_uncoded_itpp_psk_4 = [0.814, 0.767, 0.729, 0.702, 0.66,  0.616, 0.563, 0.511, 0.442, 0.4,   0.294, 0.277, 0.228, 0.17,  0.114, 0.087, 0.05,  0.037, 0.022, 0.017]\n",
        "bler_per_iter_ldpc_itpp_psk_4 = [0.584, 0.488, 0.404, 0.332, 0.218, 0.151, 0.097, 0.058, 0.041, 0.024, 0.007, 0.004, 0.002, 0.001, 0.001, 0.,    0.,    0.,    0.,    0.,   ]\n",
        "bler_per_iter_ham_itpp_psk_4= [0.51, 0.479, 0.419, 0.333, 0.313, 0.247, 0.212, 0.132, 0.114, 0.093, 0.042, 0.027, 0.024, 0.016, 0.006, 0.005, 0.003, 0.002, 0.,    0.  ]\n",
        "\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = 10 ** (- snr / 20)\n",
        "  return sigma\n",
        "\n",
        "\n",
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIqZA3RCrJgd",
        "outputId": "3f1e6985-829e-4888-d002-cd095f26d52f"
      },
      "source": [
        "\n",
        "snr_std = 7.0\n",
        "\n",
        "input_message_x = Input(shape=(2**input_message_length,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "enc_layer1 = Dense(encoder_output_length, activation='tanh')(input_message_x)\n",
        "enc_layer2 = Dense(2*channel_size, activation='tanh')(enc_layer1)\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(2*channel_size,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(2*channel_size,))\n",
        "dec_layer1 = Dense(encoder_output_length, activation='tanh')(encoded_input)\n",
        "dec_layer2 = Dense(2**input_message_length, activation=\"softmax\")(dec_layer1)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "\n",
        "\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1048576)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 40)           41943080    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 40)           1640        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square (TensorFlowO multiple             0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean (TensorFlowOpL multiple             0           tf_op_layer_Square[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt (TensorFlowOpL multiple             0           tf_op_layer_Mean[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorFlow multiple             0           dense_1[0][0]                    \n",
            "                                                                 tf_op_layer_Sqrt[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 41,944,720\n",
            "Trainable params: 41,944,720\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 40)]              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1048576)           42991616  \n",
            "=================================================================\n",
            "Total params: 42,993,256\n",
            "Trainable params: 42,993,256\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1048576)]         0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 40)                41944720  \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "functional_3 (Functional)    (None, 1048576)           42993256  \n",
            "=================================================================\n",
            "Total params: 84,937,976\n",
            "Trainable params: 84,937,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IidQMKlts65l"
      },
      "source": [
        "training_input_message = numpy.random.randint(2**input_message_length, size=(1,NUM_OF_INPUT_MESSAGE*10))\n",
        "training_input_message_one_hot = numpy.zeros((training_input_message.size, 2**input_message_length))\n",
        "training_input_message_one_hot[numpy.arange(training_input_message.size),training_input_message] = 1\n",
        "print(training_input_message_one_hot)\n",
        "print (training_input_message_one_hot.shape)\n",
        "print (training_input_message.shape)\n",
        "\n",
        "test_input_message = numpy.random.randint(2**input_message_length, size=(1,NUM_OF_INPUT_MESSAGE*2))\n",
        "test_input_message_one_hot = numpy.zeros((test_input_message.size, 2**input_message_length))\n",
        "test_input_message_one_hot[numpy.arange(test_input_message.size),test_input_message] = 1\n",
        "print(test_input_message_one_hot)\n",
        "print (test_input_message_one_hot.shape)\n",
        "print (test_input_message.shape)\n",
        "\n",
        "training_input_message_label = training_input_message.reshape(training_input_message.shape[1])\n",
        "print (training_input_message)\n",
        "print (training_input_message_label)\n",
        "test_input_message_label = test_input_message.reshape(test_input_message.shape[1])\n",
        "print (test_input_message)\n",
        "print (test_input_message_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbiBvRFNtUly"
      },
      "source": [
        "import keras\n",
        "#Note : 3rd Round\n",
        "#def custom_losff_fucntion (act, pred):\n",
        "#  return (tf.reduce_mean(-1*(act * tf.log(pred) + (1-act)*tf.log(1-pred))))\n",
        "\n",
        "#opt = keras.optimizers.Adam(learning_rate=1)\n",
        "#autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "#loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "autoencoder.compile(optimizer=keras.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])\n",
        "#autoencoder.compile(optimizer=opt, loss=custom_losff_fucntion)\n",
        "#loss='mean_squared_error'\n",
        "#for snr in (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)):\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  snr_std = sigma\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss=loss_fn)\n",
        "  #autoencoder.compile(optimizer=keras.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['sparse_categorical_accuracy'])\n",
        "  autoencoder.fit(training_input_message_one_hot, training_input_message_label,\n",
        "                epochs=50,#original\n",
        "                #epochs=20,\n",
        "                batch_size=500,\n",
        "                shuffle=False,\n",
        "                validation_data=(test_input_message_one_hot, test_input_message_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjVpOnoOuF0o"
      },
      "source": [
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "#train_init = tf.global_variables_initializer ()\n",
        "#train_sess = tf.Session ()\n",
        "\n",
        "channel_in = []\n",
        "channel_out = []\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = training_input_message_one_hot [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    channel_in.append(encoded_message[0])\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,CHANEL_SIZE])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,2*channel_size])\n",
        "    channel_out.append(noised_message[0]) \n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output1\", numpy.argmax(training_input_message_one_hot[i]))\n",
        "    #print (\"output2\", numpy.argmax(decoded_message[0]))\n",
        "    #print (\"output2\", training_input_message[0][i])\n",
        "    if (numpy.argmax(training_input_message_one_hot[i]) != numpy.argmax(decoded_message[0])):\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cALSMP2YvKvC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(input=9,channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzX49hmQtgV-"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "channel_in_array = numpy.transpose(channel_in)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.scatter(channel_in_array[i*2], channel_in_array[i*2+1])\n",
        "  plt.show()\n",
        "  plt.hist2d(channel_in_array[i*2], channel_in_array[i*2+1], cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dojDHRXWtj5f"
      },
      "source": [
        "channel_out_array = numpy.transpose(channel_out)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.hist2d(channel_out_array[2*i], channel_out_array[2*i+1], (50, 50), cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55MOI_pigX8l"
      },
      "source": [
        "post_train_input_message = numpy.random.randint(2**input_message_length, size=(1,NUM_OF_INPUT_MESSAGE*10))\n",
        "post_train_input_message_one_hot = numpy.zeros((post_train_input_message.size, 2**input_message_length))\n",
        "post_train_input_message_one_hot[numpy.arange(post_train_input_message.size),post_train_input_message] = 1\n",
        "print(post_train_input_message_one_hot)\n",
        "print (post_train_input_message_one_hot.shape)\n",
        "print (post_train_input_message.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_YwhCFhg2LV"
      },
      "source": [
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#train_init = tf.global_variables_initializer ()\n",
        "#train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = post_train_input_message_one_hot [i:i+1]\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,2*channel_size])\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    if (numpy.argmax(post_train_input_message_one_hot[i]) != numpy.argmax(decoded_message[0])):\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USeaWSrehQge"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(input=9,channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}