{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_50_100_50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/PostMidTerm/Experiment/Keras_50_100_50_mse_tmp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dLvr1Rr1K8"
      },
      "source": [
        "import numpy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.disable_v2_behavior ()\n",
        "\n",
        "input_message_length = 50\n",
        "encoder_output_length = 100\n",
        "channel_size = 50\n",
        "NUM_OF_INPUT_MESSAGE = 100000\n",
        "SNR_STEP_SIZE = .5\n",
        "\n",
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "\n",
        "bler_per_iter_uncoded_commpy_psk_2= [0.521, 0.473, 0.436, 0.37,  0.304, 0.259, 0.187, 0.138, 0.098, 0.098, 0.052, 0.028, 0.012, 0.011, 0.009, 0.002, 0.0,  0.001, 0.,    0.0]\n",
        "bler_per_iter_uncoded_itpp_psk_2= [0.518, 0.478, 0.415, 0.355, 0.305, 0.227, 0.177, 0.149, 0.11,  0.075, 0.055, 0.023, 0.014, 0.014, 0.015, 0.001, 0.003, 0.001, 0.,    0. ]\n",
        "bler_per_iter_uncoded_commpy_psk_4 = [0.815, 0.793, 0.75,  0.714, 0.64,  0.639, 0.526, 0.49,  0.433, 0.371, 0.335, 0.236, 0.204, 0.154, 0.129, 0.08,  0.063, 0.046, 0.023, 0.018]\n",
        "bler_per_iter_uncoded_itpp_psk_4 = [0.814, 0.767, 0.729, 0.702, 0.66,  0.616, 0.563, 0.511, 0.442, 0.4,   0.294, 0.277, 0.228, 0.17,  0.114, 0.087, 0.05,  0.037, 0.022, 0.017]\n",
        "bler_per_iter_ldpc_itpp_psk_4 = [0.584, 0.488, 0.404, 0.332, 0.218, 0.151, 0.097, 0.058, 0.041, 0.024, 0.007, 0.004, 0.002, 0.001, 0.001, 0.,    0.,    0.,    0.,    0.,   ]\n",
        "bler_per_iter_ham_itpp_psk_4= [0.51, 0.479, 0.419, 0.333, 0.313, 0.247, 0.212, 0.132, 0.114, 0.093, 0.042, 0.027, 0.024, 0.016, 0.006, 0.005, 0.003, 0.002, 0.,    0.  ]\n",
        "bler_per_iter_ldpc_50_100_itpp_psk_4 = [1., 1., 0.997, 0.989, 0.92,  0.697, 0.391, 0.123, 0.042, 0.011, 0.,    0.,  0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]\n",
        "bler_per_iter_uncoded_50_100_itpp_psk_4 = [1.,    1.,    1.,    1.,    1.,    1.,    1.,    1.,    0.997, 0.991, 0.97,  0.948, 0.924, 0.821, 0.74,  0.566, 0.444, 0.296, 0.211, 0.136]\n",
        "\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = 10 ** (- snr / 20)\n",
        "  return sigma\n",
        "\n",
        "\n",
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIqZA3RCrJgd",
        "outputId": "3f1af23f-adaa-4eee-ad59-e317d2436982"
      },
      "source": [
        "\n",
        "from keras import backend as K\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [2*channel_size])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "\n",
        "#decoder_input_x = tf.placeholder(\"float32\", [None, input_message_length], name=\"decoder_input_x\")\n",
        "\n",
        "snr_std = -100\n",
        "\n",
        "def my_loss(y_true, y_pred):\n",
        "  #tf.reduce_mean (-1 * (y_true*tf.log(y_pred) + (1 - y_true)*tf.log(1 - y_pred) ))\n",
        "  tf.reduce_mean ((tf.reduce_sum(tf.square(y_true-y_pred), axis=1)))\n",
        "\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "   squared_difference = tf.square(y_true - y_pred)\n",
        "   return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "def _loss_tensor(y_true, y_pred):\n",
        "    print (y_true)\n",
        "    #y_true_x = tf.cast(y_true, dtype=tf.float32)\n",
        "    #y_pred_x = tf.cast(y_pred, dtype=tf.float32)\n",
        "    #out = -(y_true_x * K.log(y_pred_x) + (1.0 - y_true_x) * K.log(1.0 - y_pred_x))\n",
        "    out = -(y_true * K.log(y_pred) + (1.0 - y_true) * K.log(1.0 - y_pred))\n",
        "    return K.mean(out, axis=-1)\n",
        "\n",
        "input_message_x = Input(shape=(input_message_length,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "enc_layer1 = Dense(encoder_output_length, activation='tanh')(input_message_x)\n",
        "enc_layer2 = Dense(2*channel_size, activation='tanh')(enc_layer1)\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(2*channel_size,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(2*channel_size,))\n",
        "dec_layer1 = Dense(encoder_output_length, activation='tanh')(encoded_input)\n",
        "dec_layer2 = Dense(input_message_length, activation=\"sigmoid\")(dec_layer1)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "\n",
        "#decoder_output = (tf.nn.sigmoid(decoder_input_x))\n",
        "\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_53\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 100)          5100        input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 100)          10100       dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_2 (TensorFlo multiple             0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_2 (TensorFlowO multiple             0           tf_op_layer_Square_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt_2 (TensorFlowO multiple             0           tf_op_layer_Mean_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv_2 (TensorFl multiple             0           dense_9[0][0]                    \n",
            "                                                                 tf_op_layer_Sqrt_2[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 15,200\n",
            "Trainable params: 15,200\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"functional_55\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 50)                5050      \n",
            "=================================================================\n",
            "Total params: 15,150\n",
            "Trainable params: 15,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_57\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 50)]              0         \n",
            "_________________________________________________________________\n",
            "functional_53 (Functional)   (None, 100)               15200     \n",
            "_________________________________________________________________\n",
            "gaussian_noise_22 (GaussianN (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "functional_55 (Functional)   (None, 50)                15150     \n",
            "=================================================================\n",
            "Total params: 30,350\n",
            "Trainable params: 30,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IidQMKlts65l",
        "outputId": "1508d5a3-602f-46a8-d497-16e4b666e579"
      },
      "source": [
        "training_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "training_input_message = tf.cast(training_input_message, dtype=tf.float32)\n",
        "#training_input_message_label = training_input_message.reshape(,1)\n",
        "#training_input_message_label = []\n",
        "#= training_input_message.reshape(training_input_message.shape[NUM_OF_INPUT_MESSAGE*10])\n",
        "#for i in range (NUM_OF_INPUT_MESSAGE*10):\n",
        "#  training_input_message_label.append (training_input_message[i][0])\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))\n",
        "print ('x')\n",
        "#print (training_input_message_label)\n",
        "print(input_message_length)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0. 0. 0. ... 1. 1. 0.]\n",
            " [1. 1. 0. ... 1. 0. 1.]\n",
            " [0. 0. 1. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 0.]\n",
            " [1. 0. 1. ... 0. 0. 0.]], shape=(1000000, 50), dtype=float32)\n",
            "1000000\n",
            "x\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORw0oaAjsrXG",
        "outputId": "11779c65-07ff-49eb-dfe0-fcc019acd2ee"
      },
      "source": [
        "test_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "test_input_message = tf.cast(test_input_message, dtype=tf.float32)\n",
        "test_input_message_label = []\n",
        "for i in range (NUM_OF_INPUT_MESSAGE*10):\n",
        "  test_input_message_label.append (test_input_message[i][0])\n",
        "print (test_input_message)\n",
        "print (len(test_input_message))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 0.]\n",
            " [0. 1. 1. ... 0. 1. 1.]\n",
            " ...\n",
            " [0. 1. 1. ... 1. 1. 0.]\n",
            " [1. 0. 1. ... 1. 0. 0.]\n",
            " [0. 0. 1. ... 1. 1. 0.]], shape=(1000000, 50), dtype=float32)\n",
            "1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IbiBvRFNtUly",
        "outputId": "48a657ea-d40e-4905-81ce-b01f44e49640"
      },
      "source": [
        "import keras\n",
        "\n",
        "#def custom_losff_fucntion (act, pred):\n",
        "#  return (tf.reduce_mean(-1*(act * tf.log(pred) + (1-act)*tf.log(1-pred))))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#autoencoder.compile(optimizer=opt, loss=custom_losff_fucntion)\n",
        "#loss='mean_squared_error'\n",
        "#for snr in (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)):\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  snr_std = sigma\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "  autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss=[tf.keras.losses.sparse_categorical_crossentropy],metrics=['accuracy'])\n",
        "  autoencoder.compile(optimizer=opt, loss='mse',metrics=['accuracy'])\n",
        "  autoencoder.fit(training_input_message, training_input_message,\n",
        "                #epochs=50, original\n",
        "                epochs=20,\n",
        "                batch_size=5000,\n",
        "                shuffle=False)#,\n",
        "                #validation_data=(test_input_message_label, test_input_message_label))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for SNR= 0.0  sigma= 1.0\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1368 - accuracy: 0.0317\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0857 - accuracy: 0.0348\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0760 - accuracy: 0.0368\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0710 - accuracy: 0.0368\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0682 - accuracy: 0.0373\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0664 - accuracy: 0.0377\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0652 - accuracy: 0.0380\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0642 - accuracy: 0.0383\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0634 - accuracy: 0.0382\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0629 - accuracy: 0.0386\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0624 - accuracy: 0.0391\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0620 - accuracy: 0.0390\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0617 - accuracy: 0.0391\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0614 - accuracy: 0.0387\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0612 - accuracy: 0.0393\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0610 - accuracy: 0.0391\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0608 - accuracy: 0.0393\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0606 - accuracy: 0.0394\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0604 - accuracy: 0.0396\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0604 - accuracy: 0.0400\n",
            "Training for SNR= 0.5  sigma= 0.9440608762859234\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0524 - accuracy: 0.0396\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0522 - accuracy: 0.0391\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0521 - accuracy: 0.0393\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0520 - accuracy: 0.0400\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0519 - accuracy: 0.0399\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0518 - accuracy: 0.0395\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0518 - accuracy: 0.0398\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0517 - accuracy: 0.0399\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0516 - accuracy: 0.0401\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0516 - accuracy: 0.0401\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0515 - accuracy: 0.0410\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0515 - accuracy: 0.0404\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0514 - accuracy: 0.0403\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0514 - accuracy: 0.0402\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0514 - accuracy: 0.0410\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0514 - accuracy: 0.0408\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0513 - accuracy: 0.0401\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0513 - accuracy: 0.0405\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0512 - accuracy: 0.0409\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0512 - accuracy: 0.0400\n",
            "Training for SNR= 1.0  sigma= 0.8912509381337456\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0436 - accuracy: 0.0413\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0436 - accuracy: 0.0403\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0436 - accuracy: 0.0402\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0435 - accuracy: 0.0407\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0435 - accuracy: 0.0409\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0435 - accuracy: 0.0411\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0435 - accuracy: 0.0403\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0434 - accuracy: 0.0396\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0434 - accuracy: 0.0400\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0434 - accuracy: 0.0404\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0434 - accuracy: 0.0405\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0434 - accuracy: 0.0411\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0433 - accuracy: 0.0403\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0434 - accuracy: 0.0405\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0433 - accuracy: 0.0403\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0433 - accuracy: 0.0404\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0433 - accuracy: 0.0405\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0433 - accuracy: 0.0408\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0433 - accuracy: 0.0408\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0433 - accuracy: 0.0408\n",
            "Training for SNR= 1.5  sigma= 0.8413951416451951\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0362 - accuracy: 0.0404\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0362 - accuracy: 0.0406\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0362 - accuracy: 0.0411\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0362 - accuracy: 0.0401\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0362 - accuracy: 0.0410\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0361 - accuracy: 0.0406\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0361 - accuracy: 0.0412\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0361 - accuracy: 0.0409\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0361 - accuracy: 0.0408\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0361 - accuracy: 0.0414\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0361 - accuracy: 0.0408\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0361 - accuracy: 0.0405\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0361 - accuracy: 0.0414\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0360 - accuracy: 0.0398\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0361 - accuracy: 0.0408\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0361 - accuracy: 0.0404\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0360 - accuracy: 0.0406\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0360 - accuracy: 0.0414\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0360 - accuracy: 0.0407\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0360 - accuracy: 0.0405\n",
            "Training for SNR= 2.0  sigma= 0.7943282347242815\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0296 - accuracy: 0.0411\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0296 - accuracy: 0.0408\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0296 - accuracy: 0.0406\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0296 - accuracy: 0.0409\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0296 - accuracy: 0.0410\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0296 - accuracy: 0.0416\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0406\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0416\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0411\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0401\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0405\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0410\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0411\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0414\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0414\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0408\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0294 - accuracy: 0.0410\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0410\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0408\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0295 - accuracy: 0.0411\n",
            "Training for SNR= 2.5  sigma= 0.7498942093324559\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0407\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0409\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0410\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0406\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0405\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0410\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0413\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0413\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0406\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0414\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0237 - accuracy: 0.0407\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0236 - accuracy: 0.0410\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0236 - accuracy: 0.0402\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0410\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0407\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0237 - accuracy: 0.0413\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0236 - accuracy: 0.0406\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0236 - accuracy: 0.0408\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0236 - accuracy: 0.0414\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0236 - accuracy: 0.0416\n",
            "Training for SNR= 3.0  sigma= 0.7079457843841379\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0418\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0421\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0411\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0412\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0186 - accuracy: 0.0413\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0412\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0418\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0413\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0410\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0416\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0186 - accuracy: 0.0417\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0416\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0186 - accuracy: 0.0410\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0185 - accuracy: 0.0410\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0416\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0186 - accuracy: 0.0420\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0185 - accuracy: 0.0423\n",
            "Epoch 18/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0185 - accuracy: 0.0424\n",
            "Epoch 19/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0185 - accuracy: 0.0422\n",
            "Epoch 20/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0185 - accuracy: 0.0418\n",
            "Training for SNR= 3.5  sigma= 0.6683439175686147\n",
            "Epoch 1/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0411\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0142 - accuracy: 0.0428\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0422\n",
            "Epoch 4/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0418\n",
            "Epoch 5/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0418\n",
            "Epoch 6/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0426\n",
            "Epoch 7/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0142 - accuracy: 0.0428\n",
            "Epoch 8/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0429\n",
            "Epoch 9/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0435\n",
            "Epoch 10/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0429\n",
            "Epoch 11/20\n",
            "200/200 [==============================] - 7s 36ms/step - loss: 0.0142 - accuracy: 0.0429\n",
            "Epoch 12/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0432\n",
            "Epoch 13/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0439\n",
            "Epoch 14/20\n",
            "200/200 [==============================] - 8s 38ms/step - loss: 0.0142 - accuracy: 0.0434\n",
            "Epoch 15/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0433\n",
            "Epoch 16/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0432\n",
            "Epoch 17/20\n",
            "200/200 [==============================] - 7s 37ms/step - loss: 0.0142 - accuracy: 0.0432\n",
            "Epoch 18/20\n",
            " 91/200 [============>.................] - ETA: 4s - loss: 0.0142 - accuracy: 0.0433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9fddd5b90cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 shuffle=False)#,\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0;31m#validation_data=(test_input_message_label, test_input_message_label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "FjVpOnoOuF0o",
        "outputId": "c7ab4dc0-276e-4803-bf97-e80745c87c4d"
      },
      "source": [
        "NUM_OF_INPUT_MESSAGE_BER = 600\n",
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE_BER/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(channel_size,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [channel_size])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "#train_init = tf.global_variables_initializer ()\n",
        "#train_sess = tf.Session ()\n",
        "channel_in = []\n",
        "channel_out = []\n",
        "training_input_message_int = numpy.around(training_input_message).astype(int)\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE_BER):\n",
        "    input_message_xx = training_input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    channel_in.append(encoded_message[0])\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,2*channel_size])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,2*channel_size])\n",
        "    channel_out.append(noised_message[0]) \n",
        "    #noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,channel_size])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    #training_input_message_int = numpy.around(training_input_message[i]).astype(int)\n",
        "    #tf.cast(training_input_message[i], dtype=tf.int32)\n",
        "    #print (training_input_message_int)\n",
        "    if abs(decoded_message-training_input_message_int[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE_BER\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 150 - Last 150.0 iterations took 11.36s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6e8ad8fa3c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m#noised_message = awgn_layer (encoded_message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m#print(noised_message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mdecoded_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoised_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m#print (\"decoded1:\", decoded_message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1725\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m     \"\"\"\n\u001b[0;32m-> 1727\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m   def interleave(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4121\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4122\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 4123\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   4124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4125\u001b[0m       raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2939\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3363\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3364\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_batch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         index_remainder = dataset_ops.DatasetV2.from_tensors(array_ops.slice(\n\u001b[0;32m--> 354\u001b[0;31m             indices, [num_in_full_batch], [self._partial_batch_size]))\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mflat_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_remainder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m   \"\"\"\n\u001b[0;32m-> 1080\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   9254\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9255\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 9256\u001b[0;31m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[0m\u001b[1;32m   9257\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    468\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m               \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m               preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                          as_ref=False):\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m--> 286\u001b[0;31m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    591\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3485\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3486\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3539\u001b[0m     \u001b[0;31m# Apply a kernel label if one has been specified for this op type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3540\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3541\u001b[0;31m       \u001b[0mkernel_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op_to_kernel_label_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3542\u001b[0m       op._set_attr(\"_kernel\",  # pylint: disable=protected-access\n\u001b[1;32m   3543\u001b[0m                    attr_value_pb2.AttrValue(s=compat.as_bytes(kernel_label)))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2377\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m     \u001b[0;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2379\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "cALSMP2YvKvC",
        "outputId": "8f251eaf-180b-40d4-f285-d652bed31774"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#import numpy\n",
        "%matplotlib inline\n",
        "ber_per_iter_dl_tensor = [.99,.98,.95,.93,.91,.83,.74,.66,.55,.46,.38,.26,.19,.10,.07,.05,.02,0.02,0.01,0.0]\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "#ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_50_100_itpp_psk_4,'', label=\"itpp-ldpc(50,100, 5,10)-qpsk\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(50-100-50)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_50_100_itpp_psk_4,'', label=\"itpp-psk-4-uncoded(100)\") # plot BER vs SNR\n",
        "#ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "#ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "#ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "#ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCaLkoTuGAcD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "channel_in_array = numpy.transpose(channel_in)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.scatter(channel_in_array[i*2], channel_in_array[i*2+1])\n",
        "  plt.show()\n",
        "  plt.hist2d(channel_in_array[i*2], channel_in_array[i*2+1], cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IFjn8KSGDM7"
      },
      "source": [
        "channel_out_array = numpy.transpose(channel_out)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.hist2d(channel_out_array[2*i], channel_out_array[2*i+1], (50, 50), cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f941H6lZvxF6"
      },
      "source": [
        "\n",
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(channel_size,))\n",
        "\n",
        "\n",
        "#train_init = tf.global_variables_initializer ()\n",
        "#train_sess = tf.Session ()\n",
        "\n",
        "channel_in = []\n",
        "channel_out = []\n",
        "test_input_message_int = numpy.around(test_input_message).astype(int)\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = test_input_message [i:i+1]\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    channel_in.append(encoded_message[0])\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,2*channel_size])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,2*channel_size])\n",
        "    channel_out.append(noised_message[0]) \n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    if abs(decoded_message-test_input_message_int[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkx6sASfv9Uk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(input=9,channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}