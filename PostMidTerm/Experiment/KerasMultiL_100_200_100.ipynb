{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasMultiL_100_200_100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/PostMidTerm/Experiment/KerasMultiL_100_200_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5dLvr1Rr1K8"
      },
      "source": [
        "import numpy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "input_message_length = 100\n",
        "encoder_output_length = 200\n",
        "channel_size = 100\n",
        "NUM_OF_INPUT_MESSAGE = 100000\n",
        "SNR_STEP_SIZE = .5\n",
        "\n",
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "\n",
        "bler_per_iter_uncoded_commpy_psk_2= [0.521, 0.473, 0.436, 0.37,  0.304, 0.259, 0.187, 0.138, 0.098, 0.098, 0.052, 0.028, 0.012, 0.011, 0.009, 0.002, 0.0,  0.001, 0.,    0.0]\n",
        "bler_per_iter_uncoded_itpp_psk_2= [0.518, 0.478, 0.415, 0.355, 0.305, 0.227, 0.177, 0.149, 0.11,  0.075, 0.055, 0.023, 0.014, 0.014, 0.015, 0.001, 0.003, 0.001, 0.,    0. ]\n",
        "bler_per_iter_uncoded_commpy_psk_4 = [0.815, 0.793, 0.75,  0.714, 0.64,  0.639, 0.526, 0.49,  0.433, 0.371, 0.335, 0.236, 0.204, 0.154, 0.129, 0.08,  0.063, 0.046, 0.023, 0.018]\n",
        "bler_per_iter_uncoded_itpp_psk_4 = [0.814, 0.767, 0.729, 0.702, 0.66,  0.616, 0.563, 0.511, 0.442, 0.4,   0.294, 0.277, 0.228, 0.17,  0.114, 0.087, 0.05,  0.037, 0.022, 0.017]\n",
        "bler_per_iter_ldpc_itpp_psk_4 = [0.584, 0.488, 0.404, 0.332, 0.218, 0.151, 0.097, 0.058, 0.041, 0.024, 0.007, 0.004, 0.002, 0.001, 0.001, 0.,    0.,    0.,    0.,    0.,   ]\n",
        "bler_per_iter_ham_itpp_psk_4= [0.51, 0.479, 0.419, 0.333, 0.313, 0.247, 0.212, 0.132, 0.114, 0.093, 0.042, 0.027, 0.024, 0.016, 0.006, 0.005, 0.003, 0.002, 0.,    0.  ]\n",
        "\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = 10 ** (- snr / 20)\n",
        "  return sigma\n",
        "\n",
        "\n",
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIqZA3RCrJgd",
        "outputId": "46a08b5e-214c-4014-da0e-8029477eda57"
      },
      "source": [
        "\n",
        "snr_std = 7.0\n",
        "\n",
        "input_message_x = Input(shape=(input_message_length,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "enc_layer1 = Dense(encoder_output_length, activation='tanh')(input_message_x)\n",
        "enc_layer2 = Dense(2*channel_size, activation='tanh')(enc_layer1)\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(2*channel_size,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(2*channel_size,))\n",
        "dec_layer1 = Dense(encoder_output_length, activation='tanh')(encoded_input)\n",
        "dec_layer2 = Dense(input_message_length, activation='sigmoid')(dec_layer1)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "\n",
        "\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 200)          20200       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 200)          40200       dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_1 (TensorFlo multiple             0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_1 (TensorFlowO multiple             0           tf_op_layer_Square_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt_1 (TensorFlowO multiple             0           tf_op_layer_Mean_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RealDiv_1 (TensorFl multiple             0           dense_5[0][0]                    \n",
            "                                                                 tf_op_layer_Sqrt_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 60,400\n",
            "Trainable params: 60,400\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               20100     \n",
            "=================================================================\n",
            "Total params: 60,300\n",
            "Trainable params: 60,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "functional_7 (Functional)    (None, 200)               60400     \n",
            "_________________________________________________________________\n",
            "gaussian_noise_1 (GaussianNo (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "functional_9 (Functional)    (None, 100)               60300     \n",
            "=================================================================\n",
            "Total params: 120,700\n",
            "Trainable params: 120,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IidQMKlts65l",
        "outputId": "d22394b8-551d-470b-d367-8d763c1a5b26"
      },
      "source": [
        "training_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))\n",
        "print(input_message_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 1 ... 0 0 1]\n",
            " [0 0 0 ... 0 1 1]\n",
            " [1 0 1 ... 1 0 0]\n",
            " ...\n",
            " [0 1 1 ... 0 1 0]\n",
            " [0 1 1 ... 1 0 0]\n",
            " [1 1 1 ... 1 1 1]]\n",
            "1000000\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORw0oaAjsrXG",
        "outputId": "a2b30065-b03e-46a2-e71f-7286a49d2bbf"
      },
      "source": [
        "test_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (test_input_message)\n",
        "print (len(test_input_message))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 1 ... 1 1 1]\n",
            " [0 0 1 ... 1 1 1]\n",
            " [0 0 0 ... 1 0 0]\n",
            " ...\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 1 1 ... 1 1 0]]\n",
            "1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbiBvRFNtUly",
        "outputId": "994eeddf-d11e-43eb-ba61-d05b5db659e8"
      },
      "source": [
        "import keras\n",
        "\n",
        "#def custom_losff_fucntion (act, pred):\n",
        "#  return (tf.reduce_mean(-1*(act * tf.log(pred) + (1-act)*tf.log(1-pred))))\n",
        "\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "#autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "#autoencoder.compile(optimizer=opt, loss=custom_losff_fucntion)\n",
        "#loss='mean_squared_error'\n",
        "#for snr in (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)):\n",
        "#awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "#autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "#autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  snr_std = sigma\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  autoencoder.fit(training_input_message, training_input_message,\n",
        "                #epochs=50, original\n",
        "                epochs=20,\n",
        "                batch_size=10000,\n",
        "                shuffle=False,\n",
        "                validation_data=(test_input_message, test_input_message))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for SNR= 0.0  sigma= 1.0\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.4110 - accuracy: 0.0161 - val_loss: 0.2143 - val_accuracy: 0.0184\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.1872 - accuracy: 0.0167 - val_loss: 0.1080 - val_accuracy: 0.0153\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.1258 - accuracy: 0.0169 - val_loss: 0.0706 - val_accuracy: 0.0168\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0985 - accuracy: 0.0169 - val_loss: 0.0503 - val_accuracy: 0.0162\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0802 - accuracy: 0.0171 - val_loss: 0.0368 - val_accuracy: 0.0170\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0671 - accuracy: 0.0171 - val_loss: 0.0283 - val_accuracy: 0.0158\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0579 - accuracy: 0.0176 - val_loss: 0.0225 - val_accuracy: 0.0156\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0509 - accuracy: 0.0176 - val_loss: 0.0183 - val_accuracy: 0.0177\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0455 - accuracy: 0.0178 - val_loss: 0.0151 - val_accuracy: 0.0180\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0411 - accuracy: 0.0174 - val_loss: 0.0127 - val_accuracy: 0.0146\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0375 - accuracy: 0.0174 - val_loss: 0.0107 - val_accuracy: 0.0175\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0345 - accuracy: 0.0177 - val_loss: 0.0091 - val_accuracy: 0.0159\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0320 - accuracy: 0.0175 - val_loss: 0.0079 - val_accuracy: 0.0172\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0298 - accuracy: 0.0177 - val_loss: 0.0068 - val_accuracy: 0.0176\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0279 - accuracy: 0.0177 - val_loss: 0.0059 - val_accuracy: 0.0183\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0262 - accuracy: 0.0177 - val_loss: 0.0052 - val_accuracy: 0.0159\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0247 - accuracy: 0.0179 - val_loss: 0.0046 - val_accuracy: 0.0173\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.0234 - accuracy: 0.0178 - val_loss: 0.0041 - val_accuracy: 0.0168\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0222 - accuracy: 0.0178 - val_loss: 0.0036 - val_accuracy: 0.0139\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0211 - accuracy: 0.0178 - val_loss: 0.0032 - val_accuracy: 0.0174\n",
            "Training for SNR= 0.5  sigma= 0.9440608762859234\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0202 - accuracy: 0.0177 - val_loss: 0.0029 - val_accuracy: 0.0164\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0193 - accuracy: 0.0177 - val_loss: 0.0026 - val_accuracy: 0.0148\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0185 - accuracy: 0.0180 - val_loss: 0.0023 - val_accuracy: 0.0158\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0177 - accuracy: 0.0179 - val_loss: 0.0021 - val_accuracy: 0.0150\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0171 - accuracy: 0.0178 - val_loss: 0.0019 - val_accuracy: 0.0180\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0164 - accuracy: 0.0180 - val_loss: 0.0017 - val_accuracy: 0.0174\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0158 - accuracy: 0.0181 - val_loss: 0.0016 - val_accuracy: 0.0146\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0153 - accuracy: 0.0181 - val_loss: 0.0014 - val_accuracy: 0.0154\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0148 - accuracy: 0.0181 - val_loss: 0.0013 - val_accuracy: 0.0148\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.0143 - accuracy: 0.0179 - val_loss: 0.0012 - val_accuracy: 0.0119\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0139 - accuracy: 0.0180 - val_loss: 0.0011 - val_accuracy: 0.0130\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0135 - accuracy: 0.0176 - val_loss: 9.9165e-04 - val_accuracy: 0.0152\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0131 - accuracy: 0.0178 - val_loss: 9.0993e-04 - val_accuracy: 0.0160\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0127 - accuracy: 0.0184 - val_loss: 8.3315e-04 - val_accuracy: 0.0122\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0123 - accuracy: 0.0180 - val_loss: 7.6856e-04 - val_accuracy: 0.0187\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0120 - accuracy: 0.0178 - val_loss: 7.0574e-04 - val_accuracy: 0.0175\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0117 - accuracy: 0.0181 - val_loss: 6.4474e-04 - val_accuracy: 0.0151\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0114 - accuracy: 0.0179 - val_loss: 5.9701e-04 - val_accuracy: 0.0211\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0111 - accuracy: 0.0181 - val_loss: 5.5203e-04 - val_accuracy: 0.0169\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0108 - accuracy: 0.0179 - val_loss: 5.1082e-04 - val_accuracy: 0.0165\n",
            "Training for SNR= 1.0  sigma= 0.8912509381337456\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0106 - accuracy: 0.0183 - val_loss: 4.7407e-04 - val_accuracy: 0.0167\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0103 - accuracy: 0.0181 - val_loss: 4.3756e-04 - val_accuracy: 0.0138\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0101 - accuracy: 0.0185 - val_loss: 4.0228e-04 - val_accuracy: 0.0145\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0099 - accuracy: 0.0184 - val_loss: 3.7447e-04 - val_accuracy: 0.0146\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0097 - accuracy: 0.0180 - val_loss: 3.4675e-04 - val_accuracy: 0.0141\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0095 - accuracy: 0.0178 - val_loss: 3.2047e-04 - val_accuracy: 0.0187\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0093 - accuracy: 0.0184 - val_loss: 2.9792e-04 - val_accuracy: 0.0168\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0091 - accuracy: 0.0180 - val_loss: 2.7532e-04 - val_accuracy: 0.0175\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0090 - accuracy: 0.0181 - val_loss: 2.5632e-04 - val_accuracy: 0.0264\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0088 - accuracy: 0.0184 - val_loss: 2.3727e-04 - val_accuracy: 0.0148\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0086 - accuracy: 0.0186 - val_loss: 2.2280e-04 - val_accuracy: 0.0131\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0085 - accuracy: 0.0180 - val_loss: 2.0783e-04 - val_accuracy: 0.0218\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0083 - accuracy: 0.0185 - val_loss: 1.9402e-04 - val_accuracy: 0.0201\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0082 - accuracy: 0.0187 - val_loss: 1.8037e-04 - val_accuracy: 0.0176\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0081 - accuracy: 0.0188 - val_loss: 1.6889e-04 - val_accuracy: 0.0131\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0079 - accuracy: 0.0185 - val_loss: 1.5772e-04 - val_accuracy: 0.0132\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0078 - accuracy: 0.0187 - val_loss: 1.4714e-04 - val_accuracy: 0.0219\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0077 - accuracy: 0.0187 - val_loss: 1.3661e-04 - val_accuracy: 0.0214\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0076 - accuracy: 0.0184 - val_loss: 1.2794e-04 - val_accuracy: 0.0138\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0074 - accuracy: 0.0185 - val_loss: 1.2014e-04 - val_accuracy: 0.0162\n",
            "Training for SNR= 1.5  sigma= 0.8413951416451951\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0073 - accuracy: 0.0189 - val_loss: 1.1289e-04 - val_accuracy: 0.0163\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0072 - accuracy: 0.0186 - val_loss: 1.0606e-04 - val_accuracy: 0.0110\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0071 - accuracy: 0.0181 - val_loss: 9.9624e-05 - val_accuracy: 0.0239\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0071 - accuracy: 0.0185 - val_loss: 9.4438e-05 - val_accuracy: 0.0141\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0070 - accuracy: 0.0183 - val_loss: 8.7721e-05 - val_accuracy: 0.0220\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0069 - accuracy: 0.0188 - val_loss: 8.2060e-05 - val_accuracy: 0.0124\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0068 - accuracy: 0.0190 - val_loss: 7.7460e-05 - val_accuracy: 0.0152\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0067 - accuracy: 0.0187 - val_loss: 7.2661e-05 - val_accuracy: 0.0160\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0066 - accuracy: 0.0187 - val_loss: 6.9123e-05 - val_accuracy: 0.0150\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0066 - accuracy: 0.0192 - val_loss: 6.5052e-05 - val_accuracy: 0.0102\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0065 - accuracy: 0.0182 - val_loss: 6.0941e-05 - val_accuracy: 0.0206\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0064 - accuracy: 0.0193 - val_loss: 5.8229e-05 - val_accuracy: 0.0155\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0064 - accuracy: 0.0190 - val_loss: 5.4047e-05 - val_accuracy: 0.0227\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0063 - accuracy: 0.0191 - val_loss: 5.1454e-05 - val_accuracy: 0.0238\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0062 - accuracy: 0.0187 - val_loss: 4.9000e-05 - val_accuracy: 0.0206\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0062 - accuracy: 0.0187 - val_loss: 4.6391e-05 - val_accuracy: 0.0182\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0061 - accuracy: 0.0190 - val_loss: 4.3193e-05 - val_accuracy: 0.0156\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0061 - accuracy: 0.0186 - val_loss: 4.1215e-05 - val_accuracy: 0.0236\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0060 - accuracy: 0.0191 - val_loss: 3.9255e-05 - val_accuracy: 0.0113\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0060 - accuracy: 0.0188 - val_loss: 3.7776e-05 - val_accuracy: 0.0192\n",
            "Training for SNR= 2.0  sigma= 0.7943282347242815\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0059 - accuracy: 0.0185 - val_loss: 3.5969e-05 - val_accuracy: 0.0189\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0059 - accuracy: 0.0193 - val_loss: 3.4480e-05 - val_accuracy: 0.0079\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0058 - accuracy: 0.0192 - val_loss: 3.2382e-05 - val_accuracy: 0.0154\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0058 - accuracy: 0.0189 - val_loss: 3.0854e-05 - val_accuracy: 0.0224\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0057 - accuracy: 0.0190 - val_loss: 2.9533e-05 - val_accuracy: 0.0176\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0057 - accuracy: 0.0194 - val_loss: 2.8577e-05 - val_accuracy: 0.0168\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0056 - accuracy: 0.0189 - val_loss: 2.7138e-05 - val_accuracy: 0.0172\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0056 - accuracy: 0.0192 - val_loss: 2.5252e-05 - val_accuracy: 0.0189\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0056 - accuracy: 0.0185 - val_loss: 2.4887e-05 - val_accuracy: 0.0340\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0055 - accuracy: 0.0189 - val_loss: 2.3480e-05 - val_accuracy: 0.0158\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0055 - accuracy: 0.0194 - val_loss: 2.2759e-05 - val_accuracy: 0.0153\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0055 - accuracy: 0.0195 - val_loss: 2.1593e-05 - val_accuracy: 0.0192\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0054 - accuracy: 0.0190 - val_loss: 2.0725e-05 - val_accuracy: 0.0109\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0054 - accuracy: 0.0187 - val_loss: 1.9771e-05 - val_accuracy: 0.0258\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0054 - accuracy: 0.0197 - val_loss: 1.9178e-05 - val_accuracy: 0.0278\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0054 - accuracy: 0.0197 - val_loss: 1.8355e-05 - val_accuracy: 0.0213\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0053 - accuracy: 0.0202 - val_loss: 1.7688e-05 - val_accuracy: 0.0217\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0053 - accuracy: 0.0193 - val_loss: 1.6865e-05 - val_accuracy: 0.0176\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0053 - accuracy: 0.0196 - val_loss: 1.6731e-05 - val_accuracy: 0.0222\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0052 - accuracy: 0.0196 - val_loss: 1.5868e-05 - val_accuracy: 0.0175\n",
            "Training for SNR= 2.5  sigma= 0.7498942093324559\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0052 - accuracy: 0.0195 - val_loss: 1.4965e-05 - val_accuracy: 0.0134\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0052 - accuracy: 0.0193 - val_loss: 1.4647e-05 - val_accuracy: 0.0114\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0052 - accuracy: 0.0189 - val_loss: 1.3822e-05 - val_accuracy: 0.0189\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0051 - accuracy: 0.0194 - val_loss: 1.3619e-05 - val_accuracy: 0.0202\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0051 - accuracy: 0.0193 - val_loss: 1.3168e-05 - val_accuracy: 0.0248\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0051 - accuracy: 0.0199 - val_loss: 1.2711e-05 - val_accuracy: 0.0206\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0051 - accuracy: 0.0200 - val_loss: 1.2218e-05 - val_accuracy: 0.0104\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0051 - accuracy: 0.0195 - val_loss: 1.1765e-05 - val_accuracy: 0.0142\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0050 - accuracy: 0.0200 - val_loss: 1.1385e-05 - val_accuracy: 0.0116\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0050 - accuracy: 0.0198 - val_loss: 1.1165e-05 - val_accuracy: 0.0099\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0050 - accuracy: 0.0194 - val_loss: 1.0727e-05 - val_accuracy: 0.0123\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0050 - accuracy: 0.0196 - val_loss: 1.0431e-05 - val_accuracy: 0.0142\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0050 - accuracy: 0.0197 - val_loss: 1.0118e-05 - val_accuracy: 0.0100\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0049 - accuracy: 0.0200 - val_loss: 9.8468e-06 - val_accuracy: 0.0229\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0049 - accuracy: 0.0197 - val_loss: 9.5258e-06 - val_accuracy: 0.0190\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0049 - accuracy: 0.0198 - val_loss: 9.2501e-06 - val_accuracy: 0.0357\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0049 - accuracy: 0.0196 - val_loss: 9.0502e-06 - val_accuracy: 0.0183\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0049 - accuracy: 0.0193 - val_loss: 8.6569e-06 - val_accuracy: 0.0134\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0049 - accuracy: 0.0201 - val_loss: 8.4840e-06 - val_accuracy: 0.0079\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0049 - accuracy: 0.0196 - val_loss: 8.2064e-06 - val_accuracy: 0.0151\n",
            "Training for SNR= 3.0  sigma= 0.7079457843841379\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0048 - accuracy: 0.0192 - val_loss: 7.9004e-06 - val_accuracy: 0.0173\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0048 - accuracy: 0.0188 - val_loss: 7.8496e-06 - val_accuracy: 0.0173\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0048 - accuracy: 0.0186 - val_loss: 7.4745e-06 - val_accuracy: 0.0197\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0048 - accuracy: 0.0192 - val_loss: 7.6031e-06 - val_accuracy: 0.0157\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0048 - accuracy: 0.0192 - val_loss: 7.2666e-06 - val_accuracy: 0.0194\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0048 - accuracy: 0.0193 - val_loss: 7.0288e-06 - val_accuracy: 0.0159\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0048 - accuracy: 0.0200 - val_loss: 6.8433e-06 - val_accuracy: 0.0235\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0047 - accuracy: 0.0194 - val_loss: 6.6323e-06 - val_accuracy: 0.0232\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0047 - accuracy: 0.0195 - val_loss: 6.4314e-06 - val_accuracy: 0.0187\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0047 - accuracy: 0.0201 - val_loss: 6.2485e-06 - val_accuracy: 0.0347\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0047 - accuracy: 0.0201 - val_loss: 6.1633e-06 - val_accuracy: 0.0133\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0047 - accuracy: 0.0192 - val_loss: 6.0683e-06 - val_accuracy: 0.0147\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0047 - accuracy: 0.0198 - val_loss: 5.7741e-06 - val_accuracy: 0.0191\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0047 - accuracy: 0.0202 - val_loss: 5.7056e-06 - val_accuracy: 0.0183\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0047 - accuracy: 0.0203 - val_loss: 5.6474e-06 - val_accuracy: 0.0090\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0047 - accuracy: 0.0202 - val_loss: 5.6262e-06 - val_accuracy: 0.0189\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0047 - accuracy: 0.0200 - val_loss: 5.4851e-06 - val_accuracy: 0.0077\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0047 - accuracy: 0.0205 - val_loss: 5.3329e-06 - val_accuracy: 0.0216\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0046 - accuracy: 0.0192 - val_loss: 5.1781e-06 - val_accuracy: 0.0185\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0046 - accuracy: 0.0194 - val_loss: 5.0211e-06 - val_accuracy: 0.0142\n",
            "Training for SNR= 3.5  sigma= 0.6683439175686147\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0046 - accuracy: 0.0198 - val_loss: 4.8542e-06 - val_accuracy: 0.0112\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0046 - accuracy: 0.0197 - val_loss: 4.8373e-06 - val_accuracy: 0.0303\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0046 - accuracy: 0.0205 - val_loss: 4.6582e-06 - val_accuracy: 0.0104\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0046 - accuracy: 0.0202 - val_loss: 4.7104e-06 - val_accuracy: 0.0478\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0046 - accuracy: 0.0200 - val_loss: 4.6074e-06 - val_accuracy: 0.0202\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0046 - accuracy: 0.0197 - val_loss: 4.4815e-06 - val_accuracy: 0.0220\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0046 - accuracy: 0.0203 - val_loss: 4.5180e-06 - val_accuracy: 0.0207\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0046 - accuracy: 0.0198 - val_loss: 4.2265e-06 - val_accuracy: 0.0245\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0045 - accuracy: 0.0188 - val_loss: 4.1241e-06 - val_accuracy: 0.0268\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0046 - accuracy: 0.0199 - val_loss: 4.0255e-06 - val_accuracy: 0.0180\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0045 - accuracy: 0.0208 - val_loss: 4.0467e-06 - val_accuracy: 0.0222\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0045 - accuracy: 0.0200 - val_loss: 3.9416e-06 - val_accuracy: 0.0218\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0045 - accuracy: 0.0202 - val_loss: 3.7976e-06 - val_accuracy: 0.0178\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0045 - accuracy: 0.0202 - val_loss: 3.7977e-06 - val_accuracy: 0.0198\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0045 - accuracy: 0.0198 - val_loss: 3.7476e-06 - val_accuracy: 0.0101\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0045 - accuracy: 0.0195 - val_loss: 3.6117e-06 - val_accuracy: 0.0230\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0045 - accuracy: 0.0201 - val_loss: 3.4899e-06 - val_accuracy: 0.0176\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0045 - accuracy: 0.0194 - val_loss: 3.5390e-06 - val_accuracy: 0.0088\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0045 - accuracy: 0.0197 - val_loss: 3.4022e-06 - val_accuracy: 0.0136\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0045 - accuracy: 0.0193 - val_loss: 3.3736e-06 - val_accuracy: 0.0119\n",
            "Training for SNR= 4.0  sigma= 0.6309573444801932\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0045 - accuracy: 0.0198 - val_loss: 3.2802e-06 - val_accuracy: 0.0225\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0045 - accuracy: 0.0201 - val_loss: 3.2525e-06 - val_accuracy: 0.0121\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0045 - accuracy: 0.0201 - val_loss: 3.2198e-06 - val_accuracy: 0.0120\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 29s 295ms/step - loss: 0.0045 - accuracy: 0.0189 - val_loss: 3.0817e-06 - val_accuracy: 0.0250\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0045 - accuracy: 0.0194 - val_loss: 3.0497e-06 - val_accuracy: 0.0103\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0045 - accuracy: 0.0201 - val_loss: 3.0714e-06 - val_accuracy: 0.0261\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0045 - accuracy: 0.0200 - val_loss: 2.9941e-06 - val_accuracy: 0.0108\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0044 - accuracy: 0.0199 - val_loss: 3.0030e-06 - val_accuracy: 0.0121\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0044 - accuracy: 0.0200 - val_loss: 2.8550e-06 - val_accuracy: 0.0362\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0044 - accuracy: 0.0202 - val_loss: 2.8586e-06 - val_accuracy: 0.0145\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0044 - accuracy: 0.0205 - val_loss: 2.8158e-06 - val_accuracy: 0.0234\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0044 - accuracy: 0.0190 - val_loss: 2.8081e-06 - val_accuracy: 0.0272\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0044 - accuracy: 0.0197 - val_loss: 2.7192e-06 - val_accuracy: 0.0112\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.0044 - accuracy: 0.0199 - val_loss: 2.6502e-06 - val_accuracy: 0.0218\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0044 - accuracy: 0.0198 - val_loss: 2.5899e-06 - val_accuracy: 0.0158\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0044 - accuracy: 0.0205 - val_loss: 2.6531e-06 - val_accuracy: 0.0112\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0044 - accuracy: 0.0188 - val_loss: 2.5893e-06 - val_accuracy: 0.0233\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0044 - accuracy: 0.0202 - val_loss: 2.4985e-06 - val_accuracy: 0.0203\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0044 - accuracy: 0.0199 - val_loss: 2.4480e-06 - val_accuracy: 0.0144\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0044 - accuracy: 0.0197 - val_loss: 2.4931e-06 - val_accuracy: 0.0114\n",
            "Training for SNR= 4.5  sigma= 0.5956621435290105\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0044 - accuracy: 0.0196 - val_loss: 2.3226e-06 - val_accuracy: 0.0147\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0044 - accuracy: 0.0197 - val_loss: 2.3497e-06 - val_accuracy: 0.0313\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0044 - accuracy: 0.0205 - val_loss: 2.3191e-06 - val_accuracy: 0.0250\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0044 - accuracy: 0.0197 - val_loss: 2.2764e-06 - val_accuracy: 0.0196\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0044 - accuracy: 0.0201 - val_loss: 2.2454e-06 - val_accuracy: 0.0225\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0044 - accuracy: 0.0202 - val_loss: 2.2284e-06 - val_accuracy: 0.0204\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0043 - accuracy: 0.0200 - val_loss: 2.1458e-06 - val_accuracy: 0.0141\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0044 - accuracy: 0.0200 - val_loss: 2.1878e-06 - val_accuracy: 0.0163\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0044 - accuracy: 0.0197 - val_loss: 2.1675e-06 - val_accuracy: 0.0101\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0043 - accuracy: 0.0202 - val_loss: 2.1305e-06 - val_accuracy: 0.0235\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0197 - val_loss: 2.0592e-06 - val_accuracy: 0.0345\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0200 - val_loss: 2.0988e-06 - val_accuracy: 0.0088\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0043 - accuracy: 0.0202 - val_loss: 2.0215e-06 - val_accuracy: 0.0188\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0207 - val_loss: 1.9883e-06 - val_accuracy: 0.0237\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0043 - accuracy: 0.0204 - val_loss: 1.9428e-06 - val_accuracy: 0.0286\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0196 - val_loss: 1.9281e-06 - val_accuracy: 0.0120\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0196 - val_loss: 1.8850e-06 - val_accuracy: 0.0177\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0202 - val_loss: 1.8329e-06 - val_accuracy: 0.0268\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0206 - val_loss: 1.8426e-06 - val_accuracy: 0.0135\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0197 - val_loss: 1.8362e-06 - val_accuracy: 0.0173\n",
            "Training for SNR= 5.0  sigma= 0.5623413251903491\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0201 - val_loss: 1.8194e-06 - val_accuracy: 0.0168\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0198 - val_loss: 1.8103e-06 - val_accuracy: 0.0208\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0200 - val_loss: 1.7818e-06 - val_accuracy: 0.0128\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0200 - val_loss: 1.7851e-06 - val_accuracy: 0.0195\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0204 - val_loss: 1.7619e-06 - val_accuracy: 0.0261\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0043 - accuracy: 0.0215 - val_loss: 1.7646e-06 - val_accuracy: 0.0134\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0203 - val_loss: 1.7223e-06 - val_accuracy: 0.0425\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0043 - accuracy: 0.0199 - val_loss: 1.7080e-06 - val_accuracy: 0.0339\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0043 - accuracy: 0.0193 - val_loss: 1.6768e-06 - val_accuracy: 0.0127\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0201 - val_loss: 1.6415e-06 - val_accuracy: 0.0245\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0203 - val_loss: 1.6375e-06 - val_accuracy: 0.0239\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0200 - val_loss: 1.5924e-06 - val_accuracy: 0.0180\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0193 - val_loss: 1.5835e-06 - val_accuracy: 0.0104\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0196 - val_loss: 1.5647e-06 - val_accuracy: 0.0202\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0210 - val_loss: 1.5720e-06 - val_accuracy: 0.0171\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0043 - accuracy: 0.0203 - val_loss: 1.5237e-06 - val_accuracy: 0.0101\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0198 - val_loss: 1.4920e-06 - val_accuracy: 0.0475\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0197 - val_loss: 1.4569e-06 - val_accuracy: 0.0173\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0198 - val_loss: 1.4738e-06 - val_accuracy: 0.0268\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0043 - accuracy: 0.0203 - val_loss: 1.4533e-06 - val_accuracy: 0.0147\n",
            "Training for SNR= 5.5  sigma= 0.5308844442309884\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0210 - val_loss: 1.4214e-06 - val_accuracy: 0.0226\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0204 - val_loss: 1.4286e-06 - val_accuracy: 0.0199\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0192 - val_loss: 1.4349e-06 - val_accuracy: 0.0133\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0194 - val_loss: 1.3821e-06 - val_accuracy: 0.0192\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0043 - accuracy: 0.0199 - val_loss: 1.3689e-06 - val_accuracy: 0.0144\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0203 - val_loss: 1.2990e-06 - val_accuracy: 0.0184\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0203 - val_loss: 1.3200e-06 - val_accuracy: 0.0089\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0198 - val_loss: 1.3240e-06 - val_accuracy: 0.0147\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0043 - accuracy: 0.0204 - val_loss: 1.3549e-06 - val_accuracy: 0.0077\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0042 - accuracy: 0.0205 - val_loss: 1.2951e-06 - val_accuracy: 0.0101\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0042 - accuracy: 0.0202 - val_loss: 1.2658e-06 - val_accuracy: 0.0153\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0208 - val_loss: 1.2613e-06 - val_accuracy: 0.0177\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0192 - val_loss: 1.2802e-06 - val_accuracy: 0.0188\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0042 - accuracy: 0.0185 - val_loss: 1.2699e-06 - val_accuracy: 0.0102\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0199 - val_loss: 1.2266e-06 - val_accuracy: 0.0118\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0042 - accuracy: 0.0201 - val_loss: 1.2132e-06 - val_accuracy: 0.0270\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0042 - accuracy: 0.0206 - val_loss: 1.2132e-06 - val_accuracy: 0.0142\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0042 - accuracy: 0.0196 - val_loss: 1.2395e-06 - val_accuracy: 0.0103\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0188 - val_loss: 1.2107e-06 - val_accuracy: 0.0186\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0195 - val_loss: 1.2134e-06 - val_accuracy: 0.0216\n",
            "Training for SNR= 6.0  sigma= 0.5011872336272722\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0202 - val_loss: 1.2064e-06 - val_accuracy: 0.0204\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0042 - accuracy: 0.0196 - val_loss: 1.1505e-06 - val_accuracy: 0.0152\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 1.1385e-06 - val_accuracy: 0.0118\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0205 - val_loss: 1.1500e-06 - val_accuracy: 0.0278\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0197 - val_loss: 1.1324e-06 - val_accuracy: 0.0078\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0195 - val_loss: 1.1235e-06 - val_accuracy: 0.0216\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0042 - accuracy: 0.0198 - val_loss: 1.1241e-06 - val_accuracy: 0.0080\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0199 - val_loss: 1.1200e-06 - val_accuracy: 0.0168\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 1.1237e-06 - val_accuracy: 0.0061\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0206 - val_loss: 1.0912e-06 - val_accuracy: 0.0122\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0205 - val_loss: 1.0624e-06 - val_accuracy: 0.0222\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0196 - val_loss: 1.0946e-06 - val_accuracy: 0.0106\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0042 - accuracy: 0.0199 - val_loss: 1.0330e-06 - val_accuracy: 0.0136\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0196 - val_loss: 1.0388e-06 - val_accuracy: 0.0150\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 1.0121e-06 - val_accuracy: 0.0297\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0193 - val_loss: 1.0323e-06 - val_accuracy: 0.0146\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0042 - accuracy: 0.0197 - val_loss: 9.9857e-07 - val_accuracy: 0.0270\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 1.0141e-06 - val_accuracy: 0.0357\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0042 - accuracy: 0.0197 - val_loss: 9.9236e-07 - val_accuracy: 0.0118\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0042 - accuracy: 0.0193 - val_loss: 9.5962e-07 - val_accuracy: 0.0448\n",
            "Training for SNR= 6.5  sigma= 0.47315125896148047\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0042 - accuracy: 0.0203 - val_loss: 9.5754e-07 - val_accuracy: 0.0109\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0195 - val_loss: 9.9162e-07 - val_accuracy: 0.0234\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0201 - val_loss: 9.5006e-07 - val_accuracy: 0.0303\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.0042 - accuracy: 0.0199 - val_loss: 9.3887e-07 - val_accuracy: 0.0184\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0207 - val_loss: 9.4738e-07 - val_accuracy: 0.0155\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0042 - accuracy: 0.0205 - val_loss: 9.5267e-07 - val_accuracy: 0.0190\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0042 - accuracy: 0.0202 - val_loss: 9.1316e-07 - val_accuracy: 0.0425\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 32s 319ms/step - loss: 0.0042 - accuracy: 0.0198 - val_loss: 9.4522e-07 - val_accuracy: 0.0205\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 9.1624e-07 - val_accuracy: 0.0200\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 9.0837e-07 - val_accuracy: 0.0170\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0041 - accuracy: 0.0198 - val_loss: 9.0473e-07 - val_accuracy: 0.0171\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.0042 - accuracy: 0.0206 - val_loss: 8.9711e-07 - val_accuracy: 0.0134\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0042 - accuracy: 0.0201 - val_loss: 9.0493e-07 - val_accuracy: 0.0611\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0042 - accuracy: 0.0199 - val_loss: 8.6300e-07 - val_accuracy: 0.0192\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 8.8874e-07 - val_accuracy: 0.0130\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0042 - accuracy: 0.0204 - val_loss: 8.5013e-07 - val_accuracy: 0.0137\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0203 - val_loss: 8.4118e-07 - val_accuracy: 0.0324\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0042 - accuracy: 0.0205 - val_loss: 8.4880e-07 - val_accuracy: 0.0344\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 8.4181e-07 - val_accuracy: 0.0197\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0041 - accuracy: 0.0192 - val_loss: 8.1448e-07 - val_accuracy: 0.0197\n",
            "Training for SNR= 7.0  sigma= 0.44668359215096315\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0042 - accuracy: 0.0195 - val_loss: 8.2586e-07 - val_accuracy: 0.0190\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0041 - accuracy: 0.0192 - val_loss: 7.9737e-07 - val_accuracy: 0.0193\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 8.1868e-07 - val_accuracy: 0.0224\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0195 - val_loss: 8.2435e-07 - val_accuracy: 0.0233\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0042 - accuracy: 0.0207 - val_loss: 7.9148e-07 - val_accuracy: 0.0361\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0041 - accuracy: 0.0209 - val_loss: 7.8082e-07 - val_accuracy: 0.0195\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0201 - val_loss: 8.0632e-07 - val_accuracy: 0.0114\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0198 - val_loss: 7.9337e-07 - val_accuracy: 0.0174\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0202 - val_loss: 7.6899e-07 - val_accuracy: 0.0197\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0201 - val_loss: 7.6370e-07 - val_accuracy: 0.0098\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0042 - accuracy: 0.0200 - val_loss: 7.7371e-07 - val_accuracy: 0.0214\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0200 - val_loss: 7.6414e-07 - val_accuracy: 0.0211\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0203 - val_loss: 7.6041e-07 - val_accuracy: 0.0311\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 7.4956e-07 - val_accuracy: 0.0123\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0206 - val_loss: 7.5043e-07 - val_accuracy: 0.0164\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0204 - val_loss: 7.1766e-07 - val_accuracy: 0.0115\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0202 - val_loss: 7.4681e-07 - val_accuracy: 0.0185\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 7.5012e-07 - val_accuracy: 0.0129\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0208 - val_loss: 7.2030e-07 - val_accuracy: 0.0350\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0201 - val_loss: 7.2260e-07 - val_accuracy: 0.0313\n",
            "Training for SNR= 7.5  sigma= 0.4216965034285822\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0193 - val_loss: 7.0481e-07 - val_accuracy: 0.0127\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0195 - val_loss: 7.2113e-07 - val_accuracy: 0.0241\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0211 - val_loss: 7.3682e-07 - val_accuracy: 0.0079\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0197 - val_loss: 7.1736e-07 - val_accuracy: 0.0107\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0209 - val_loss: 6.9135e-07 - val_accuracy: 0.0329\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0196 - val_loss: 6.8021e-07 - val_accuracy: 0.0218\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0193 - val_loss: 6.9433e-07 - val_accuracy: 0.0207\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0041 - accuracy: 0.0192 - val_loss: 6.8510e-07 - val_accuracy: 0.0125\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 6.6510e-07 - val_accuracy: 0.0320\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0200 - val_loss: 7.0001e-07 - val_accuracy: 0.0124\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0186 - val_loss: 6.6280e-07 - val_accuracy: 0.0183\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0195 - val_loss: 6.5504e-07 - val_accuracy: 0.0125\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0041 - accuracy: 0.0194 - val_loss: 6.5663e-07 - val_accuracy: 0.0157\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 6.6443e-07 - val_accuracy: 0.0170\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0193 - val_loss: 6.5369e-07 - val_accuracy: 0.0190\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0197 - val_loss: 6.2211e-07 - val_accuracy: 0.0380\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0202 - val_loss: 6.4098e-07 - val_accuracy: 0.0144\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 6.1982e-07 - val_accuracy: 0.0253\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 6.2273e-07 - val_accuracy: 0.0184\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0197 - val_loss: 6.2884e-07 - val_accuracy: 0.0240\n",
            "Training for SNR= 8.0  sigma= 0.3981071705534972\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 6.4020e-07 - val_accuracy: 0.0158\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0196 - val_loss: 6.3456e-07 - val_accuracy: 0.0228\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0204 - val_loss: 6.1369e-07 - val_accuracy: 0.0197\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0205 - val_loss: 6.1305e-07 - val_accuracy: 0.0179\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0206 - val_loss: 6.0998e-07 - val_accuracy: 0.0438\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0204 - val_loss: 6.0597e-07 - val_accuracy: 0.0155\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0201 - val_loss: 5.9816e-07 - val_accuracy: 0.0232\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 6.0126e-07 - val_accuracy: 0.0228\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0198 - val_loss: 5.8389e-07 - val_accuracy: 0.0325\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0191 - val_loss: 6.1196e-07 - val_accuracy: 0.0141\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0197 - val_loss: 5.9914e-07 - val_accuracy: 0.0167\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0204 - val_loss: 5.7369e-07 - val_accuracy: 0.0208\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 5.8580e-07 - val_accuracy: 0.0221\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0202 - val_loss: 5.6517e-07 - val_accuracy: 0.0181\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0206 - val_loss: 5.7451e-07 - val_accuracy: 0.0202\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0201 - val_loss: 5.6486e-07 - val_accuracy: 0.0223\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0212 - val_loss: 5.6193e-07 - val_accuracy: 0.0309\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0041 - accuracy: 0.0201 - val_loss: 5.5850e-07 - val_accuracy: 0.0333\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 5.4944e-07 - val_accuracy: 0.0107\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0187 - val_loss: 5.4123e-07 - val_accuracy: 0.0080\n",
            "Training for SNR= 8.5  sigma= 0.3758374042884442\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0193 - val_loss: 5.6916e-07 - val_accuracy: 0.0141\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0041 - accuracy: 0.0188 - val_loss: 5.5032e-07 - val_accuracy: 0.0111\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0194 - val_loss: 5.3884e-07 - val_accuracy: 0.0138\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0196 - val_loss: 5.4598e-07 - val_accuracy: 0.0103\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0196 - val_loss: 5.4776e-07 - val_accuracy: 0.0139\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0197 - val_loss: 5.4233e-07 - val_accuracy: 0.0208\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0200 - val_loss: 5.3785e-07 - val_accuracy: 0.0233\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0041 - accuracy: 0.0192 - val_loss: 5.2249e-07 - val_accuracy: 0.0330\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0205 - val_loss: 5.1547e-07 - val_accuracy: 0.0203\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 5.2025e-07 - val_accuracy: 0.0300\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0200 - val_loss: 5.2448e-07 - val_accuracy: 0.0154\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 5.1875e-07 - val_accuracy: 0.0455\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0041 - accuracy: 0.0202 - val_loss: 5.3353e-07 - val_accuracy: 0.0202\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0206 - val_loss: 4.9560e-07 - val_accuracy: 0.0370\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0194 - val_loss: 5.2900e-07 - val_accuracy: 0.0142\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0041 - accuracy: 0.0196 - val_loss: 4.8959e-07 - val_accuracy: 0.0273\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0203 - val_loss: 5.0997e-07 - val_accuracy: 0.0287\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0198 - val_loss: 4.9388e-07 - val_accuracy: 0.0089\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 5.0589e-07 - val_accuracy: 0.0111\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0195 - val_loss: 5.0281e-07 - val_accuracy: 0.0212\n",
            "Training for SNR= 9.0  sigma= 0.35481338923357547\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0205 - val_loss: 4.8782e-07 - val_accuracy: 0.0150\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0204 - val_loss: 5.0138e-07 - val_accuracy: 0.0306\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0196 - val_loss: 4.8859e-07 - val_accuracy: 0.0137\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0041 - accuracy: 0.0205 - val_loss: 4.8750e-07 - val_accuracy: 0.0127\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0205 - val_loss: 4.7221e-07 - val_accuracy: 0.0145\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0206 - val_loss: 4.6654e-07 - val_accuracy: 0.0309\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0205 - val_loss: 4.5465e-07 - val_accuracy: 0.0218\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0203 - val_loss: 4.7748e-07 - val_accuracy: 0.0215\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 4.6624e-07 - val_accuracy: 0.0169\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0203 - val_loss: 4.7473e-07 - val_accuracy: 0.0195\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0198 - val_loss: 4.6355e-07 - val_accuracy: 0.0166\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0193 - val_loss: 4.5209e-07 - val_accuracy: 0.0101\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0041 - accuracy: 0.0194 - val_loss: 4.6299e-07 - val_accuracy: 0.0121\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0207 - val_loss: 4.4988e-07 - val_accuracy: 0.0143\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0041 - accuracy: 0.0208 - val_loss: 4.6177e-07 - val_accuracy: 0.0125\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0202 - val_loss: 4.5698e-07 - val_accuracy: 0.0133\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 4.4321e-07 - val_accuracy: 0.0140\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0041 - accuracy: 0.0205 - val_loss: 4.3607e-07 - val_accuracy: 0.0109\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0194 - val_loss: 4.4900e-07 - val_accuracy: 0.0354\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0203 - val_loss: 4.3003e-07 - val_accuracy: 0.0145\n",
            "Training for SNR= 9.5  sigma= 0.33496543915782767\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0041 - accuracy: 0.0196 - val_loss: 4.3707e-07 - val_accuracy: 0.0342\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0190 - val_loss: 4.2968e-07 - val_accuracy: 0.0132\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0041 - accuracy: 0.0197 - val_loss: 4.3585e-07 - val_accuracy: 0.0263\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0040 - accuracy: 0.0202 - val_loss: 4.5114e-07 - val_accuracy: 0.0503\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0040 - accuracy: 0.0210 - val_loss: 4.1871e-07 - val_accuracy: 0.0234\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0040 - accuracy: 0.0202 - val_loss: 4.3577e-07 - val_accuracy: 0.0173\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0041 - accuracy: 0.0194 - val_loss: 4.3332e-07 - val_accuracy: 0.0198\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0040 - accuracy: 0.0194 - val_loss: 4.3212e-07 - val_accuracy: 0.0136\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0040 - accuracy: 0.0195 - val_loss: 4.2477e-07 - val_accuracy: 0.0160\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0041 - accuracy: 0.0199 - val_loss: 4.0782e-07 - val_accuracy: 0.0217\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0040 - accuracy: 0.0193 - val_loss: 4.1718e-07 - val_accuracy: 0.0219\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0040 - accuracy: 0.0199 - val_loss: 4.0730e-07 - val_accuracy: 0.0087\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0040 - accuracy: 0.0187 - val_loss: 4.0783e-07 - val_accuracy: 0.0149\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0040 - accuracy: 0.0206 - val_loss: 4.0281e-07 - val_accuracy: 0.0128\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0040 - accuracy: 0.0203 - val_loss: 4.0224e-07 - val_accuracy: 0.0184\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0040 - accuracy: 0.0206 - val_loss: 4.0919e-07 - val_accuracy: 0.0167\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.0040 - accuracy: 0.0204 - val_loss: 4.1402e-07 - val_accuracy: 0.0182\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0041 - accuracy: 0.0206 - val_loss: 4.1252e-07 - val_accuracy: 0.0174\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0040 - accuracy: 0.0198 - val_loss: 4.0496e-07 - val_accuracy: 0.0150\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0040 - accuracy: 0.0199 - val_loss: 3.9071e-07 - val_accuracy: 0.0327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FjVpOnoOuF0o",
        "outputId": "9440f8d6-d578-4f0d-b862-3862dd9bb8da"
      },
      "source": [
        "NUM_OF_TEST_MESSAGE  = 1000\n",
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_TEST_MESSAGE/40\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(channel_size,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [channel_size])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "#train_init = tf.global_variables_initializer ()\n",
        "#train_sess = tf.Session ()\n",
        "\n",
        "channel_in = []\n",
        "channel_out = []\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  for i in range (NUM_OF_TEST_MESSAGE):\n",
        "    input_message_xx = training_input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    channel_in.append(encoded_message[0])\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,2*channel_size])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,2*channel_size])\n",
        "    channel_out.append(noised_message[0]) \n",
        "    #noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,channel_size])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(channel_size,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    if abs(decoded_message-training_input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_TEST_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 25 - Last 25.0 iterations took 1.88s\n",
            "SNR: 0.000 - Iter: 50 - Last 25.0 iterations took 3.62s\n",
            "SNR: 0.000 - Iter: 75 - Last 25.0 iterations took 5.36s\n",
            "SNR: 0.000 - Iter: 100 - Last 25.0 iterations took 7.13s\n",
            "SNR: 0.000 - Iter: 125 - Last 25.0 iterations took 8.86s\n",
            "SNR: 0.000 - Iter: 150 - Last 25.0 iterations took 10.65s\n",
            "SNR: 0.000 - Iter: 175 - Last 25.0 iterations took 12.41s\n",
            "SNR: 0.000 - Iter: 200 - Last 25.0 iterations took 14.18s\n",
            "SNR: 0.000 - Iter: 225 - Last 25.0 iterations took 16.10s\n",
            "SNR: 0.000 - Iter: 250 - Last 25.0 iterations took 17.87s\n",
            "SNR: 0.000 - Iter: 275 - Last 25.0 iterations took 19.66s\n",
            "SNR: 0.000 - Iter: 300 - Last 25.0 iterations took 21.46s\n",
            "SNR: 0.000 - Iter: 325 - Last 25.0 iterations took 23.25s\n",
            "SNR: 0.000 - Iter: 350 - Last 25.0 iterations took 25.10s\n",
            "SNR: 0.000 - Iter: 375 - Last 25.0 iterations took 26.89s\n",
            "SNR: 0.000 - Iter: 400 - Last 25.0 iterations took 28.66s\n",
            "SNR: 0.000 - Iter: 425 - Last 25.0 iterations took 30.44s\n",
            "SNR: 0.000 - Iter: 450 - Last 25.0 iterations took 32.29s\n",
            "SNR: 0.000 - Iter: 475 - Last 25.0 iterations took 34.12s\n",
            "SNR: 0.000 - Iter: 500 - Last 25.0 iterations took 36.13s\n",
            "SNR: 0.000 - Iter: 525 - Last 25.0 iterations took 37.90s\n",
            "SNR: 0.000 - Iter: 550 - Last 25.0 iterations took 39.71s\n",
            "SNR: 0.000 - Iter: 575 - Last 25.0 iterations took 41.51s\n",
            "SNR: 0.000 - Iter: 600 - Last 25.0 iterations took 43.33s\n",
            "SNR: 0.000 - Iter: 625 - Last 25.0 iterations took 45.14s\n",
            "SNR: 0.000 - Iter: 650 - Last 25.0 iterations took 46.96s\n",
            "SNR: 0.000 - Iter: 675 - Last 25.0 iterations took 48.78s\n",
            "SNR: 0.000 - Iter: 700 - Last 25.0 iterations took 50.63s\n",
            "SNR: 0.000 - Iter: 725 - Last 25.0 iterations took 52.52s\n",
            "SNR: 0.000 - Iter: 750 - Last 25.0 iterations took 54.36s\n",
            "SNR: 0.000 - Iter: 775 - Last 25.0 iterations took 56.34s\n",
            "SNR: 0.000 - Iter: 800 - Last 25.0 iterations took 58.16s\n",
            "SNR: 0.000 - Iter: 825 - Last 25.0 iterations took 59.94s\n",
            "SNR: 0.000 - Iter: 850 - Last 25.0 iterations took 61.76s\n",
            "SNR: 0.000 - Iter: 875 - Last 25.0 iterations took 63.58s\n",
            "SNR: 0.000 - Iter: 900 - Last 25.0 iterations took 65.36s\n",
            "SNR: 0.000 - Iter: 925 - Last 25.0 iterations took 67.12s\n",
            "SNR: 0.000 - Iter: 950 - Last 25.0 iterations took 68.92s\n",
            "SNR: 0.000 - Iter: 975 - Last 25.0 iterations took 70.70s\n",
            "SNR: 0.000 - Iter: 1000 - Last 25.0 iterations took 72.56s\n",
            "SNR: 0.000:\n",
            " -> BER: 1.00\n",
            " -> Total Time: 1481.35s\n",
            "SNR: 0.500 - Iter: 25 - Last 25.0 iterations took 1.79s\n",
            "SNR: 0.500 - Iter: 50 - Last 25.0 iterations took 3.74s\n",
            "SNR: 0.500 - Iter: 75 - Last 25.0 iterations took 5.59s\n",
            "SNR: 0.500 - Iter: 100 - Last 25.0 iterations took 7.43s\n",
            "SNR: 0.500 - Iter: 125 - Last 25.0 iterations took 9.25s\n",
            "SNR: 0.500 - Iter: 150 - Last 25.0 iterations took 11.09s\n",
            "SNR: 0.500 - Iter: 175 - Last 25.0 iterations took 12.89s\n",
            "SNR: 0.500 - Iter: 200 - Last 25.0 iterations took 14.74s\n",
            "SNR: 0.500 - Iter: 225 - Last 25.0 iterations took 16.55s\n",
            "SNR: 0.500 - Iter: 250 - Last 25.0 iterations took 18.36s\n",
            "SNR: 0.500 - Iter: 275 - Last 25.0 iterations took 20.15s\n",
            "SNR: 0.500 - Iter: 300 - Last 25.0 iterations took 22.15s\n",
            "SNR: 0.500 - Iter: 325 - Last 25.0 iterations took 23.96s\n",
            "SNR: 0.500 - Iter: 350 - Last 25.0 iterations took 25.77s\n",
            "SNR: 0.500 - Iter: 375 - Last 25.0 iterations took 27.59s\n",
            "SNR: 0.500 - Iter: 400 - Last 25.0 iterations took 29.40s\n",
            "SNR: 0.500 - Iter: 425 - Last 25.0 iterations took 31.18s\n",
            "SNR: 0.500 - Iter: 450 - Last 25.0 iterations took 32.99s\n",
            "SNR: 0.500 - Iter: 475 - Last 25.0 iterations took 34.80s\n",
            "SNR: 0.500 - Iter: 500 - Last 25.0 iterations took 36.60s\n",
            "SNR: 0.500 - Iter: 525 - Last 25.0 iterations took 38.60s\n",
            "SNR: 0.500 - Iter: 550 - Last 25.0 iterations took 40.61s\n",
            "SNR: 0.500 - Iter: 575 - Last 25.0 iterations took 42.82s\n",
            "SNR: 0.500 - Iter: 600 - Last 25.0 iterations took 44.86s\n",
            "SNR: 0.500 - Iter: 625 - Last 25.0 iterations took 46.93s\n",
            "SNR: 0.500 - Iter: 650 - Last 25.0 iterations took 48.95s\n",
            "SNR: 0.500 - Iter: 675 - Last 25.0 iterations took 50.82s\n",
            "SNR: 0.500 - Iter: 700 - Last 25.0 iterations took 52.69s\n",
            "SNR: 0.500 - Iter: 725 - Last 25.0 iterations took 54.55s\n",
            "SNR: 0.500 - Iter: 750 - Last 25.0 iterations took 56.44s\n",
            "SNR: 0.500 - Iter: 775 - Last 25.0 iterations took 58.49s\n",
            "SNR: 0.500 - Iter: 800 - Last 25.0 iterations took 60.40s\n",
            "SNR: 0.500 - Iter: 825 - Last 25.0 iterations took 62.28s\n",
            "SNR: 0.500 - Iter: 850 - Last 25.0 iterations took 64.38s\n",
            "SNR: 0.500 - Iter: 875 - Last 25.0 iterations took 66.27s\n",
            "SNR: 0.500 - Iter: 900 - Last 25.0 iterations took 68.20s\n",
            "SNR: 0.500 - Iter: 925 - Last 25.0 iterations took 70.12s\n",
            "SNR: 0.500 - Iter: 950 - Last 25.0 iterations took 72.08s\n",
            "SNR: 0.500 - Iter: 975 - Last 25.0 iterations took 73.97s\n",
            "SNR: 0.500 - Iter: 1000 - Last 25.0 iterations took 75.85s\n",
            "SNR: 0.500:\n",
            " -> BER: 1.00\n",
            " -> Total Time: 1535.33s\n",
            "SNR: 1.000 - Iter: 25 - Last 25.0 iterations took 1.91s\n",
            "SNR: 1.000 - Iter: 50 - Last 25.0 iterations took 3.87s\n",
            "SNR: 1.000 - Iter: 75 - Last 25.0 iterations took 5.79s\n",
            "SNR: 1.000 - Iter: 100 - Last 25.0 iterations took 8.01s\n",
            "SNR: 1.000 - Iter: 125 - Last 25.0 iterations took 9.99s\n",
            "SNR: 1.000 - Iter: 150 - Last 25.0 iterations took 11.92s\n",
            "SNR: 1.000 - Iter: 175 - Last 25.0 iterations took 13.92s\n",
            "SNR: 1.000 - Iter: 200 - Last 25.0 iterations took 15.83s\n",
            "SNR: 1.000 - Iter: 225 - Last 25.0 iterations took 17.75s\n",
            "SNR: 1.000 - Iter: 250 - Last 25.0 iterations took 19.80s\n",
            "SNR: 1.000 - Iter: 275 - Last 25.0 iterations took 21.81s\n",
            "SNR: 1.000 - Iter: 300 - Last 25.0 iterations took 23.75s\n",
            "SNR: 1.000 - Iter: 325 - Last 25.0 iterations took 25.66s\n",
            "SNR: 1.000 - Iter: 350 - Last 25.0 iterations took 27.72s\n",
            "SNR: 1.000 - Iter: 375 - Last 25.0 iterations took 29.88s\n",
            "SNR: 1.000 - Iter: 400 - Last 25.0 iterations took 31.81s\n",
            "SNR: 1.000 - Iter: 425 - Last 25.0 iterations took 33.71s\n",
            "SNR: 1.000 - Iter: 450 - Last 25.0 iterations took 35.63s\n",
            "SNR: 1.000 - Iter: 475 - Last 25.0 iterations took 37.55s\n",
            "SNR: 1.000 - Iter: 500 - Last 25.0 iterations took 39.50s\n",
            "SNR: 1.000 - Iter: 525 - Last 25.0 iterations took 41.39s\n",
            "SNR: 1.000 - Iter: 550 - Last 25.0 iterations took 43.32s\n",
            "SNR: 1.000 - Iter: 575 - Last 25.0 iterations took 45.23s\n",
            "SNR: 1.000 - Iter: 600 - Last 25.0 iterations took 47.12s\n",
            "SNR: 1.000 - Iter: 625 - Last 25.0 iterations took 49.07s\n",
            "SNR: 1.000 - Iter: 650 - Last 25.0 iterations took 51.13s\n",
            "SNR: 1.000 - Iter: 675 - Last 25.0 iterations took 53.01s\n",
            "SNR: 1.000 - Iter: 700 - Last 25.0 iterations took 54.90s\n",
            "SNR: 1.000 - Iter: 725 - Last 25.0 iterations took 56.84s\n",
            "SNR: 1.000 - Iter: 750 - Last 25.0 iterations took 58.79s\n",
            "SNR: 1.000 - Iter: 775 - Last 25.0 iterations took 60.70s\n",
            "SNR: 1.000 - Iter: 800 - Last 25.0 iterations took 62.66s\n",
            "SNR: 1.000 - Iter: 825 - Last 25.0 iterations took 64.58s\n",
            "SNR: 1.000 - Iter: 850 - Last 25.0 iterations took 66.54s\n",
            "SNR: 1.000 - Iter: 875 - Last 25.0 iterations took 68.49s\n",
            "SNR: 1.000 - Iter: 900 - Last 25.0 iterations took 70.41s\n",
            "SNR: 1.000 - Iter: 925 - Last 25.0 iterations took 72.48s\n",
            "SNR: 1.000 - Iter: 950 - Last 25.0 iterations took 74.39s\n",
            "SNR: 1.000 - Iter: 975 - Last 25.0 iterations took 76.52s\n",
            "SNR: 1.000 - Iter: 1000 - Last 25.0 iterations took 78.77s\n",
            "SNR: 1.000:\n",
            " -> BER: 1.00\n",
            " -> Total Time: 1612.12s\n",
            "SNR: 1.500 - Iter: 25 - Last 25.0 iterations took 2.18s\n",
            "SNR: 1.500 - Iter: 50 - Last 25.0 iterations took 4.52s\n",
            "SNR: 1.500 - Iter: 75 - Last 25.0 iterations took 6.77s\n",
            "SNR: 1.500 - Iter: 100 - Last 25.0 iterations took 8.61s\n",
            "SNR: 1.500 - Iter: 125 - Last 25.0 iterations took 10.45s\n",
            "SNR: 1.500 - Iter: 150 - Last 25.0 iterations took 12.32s\n",
            "SNR: 1.500 - Iter: 175 - Last 25.0 iterations took 14.33s\n",
            "SNR: 1.500 - Iter: 200 - Last 25.0 iterations took 16.17s\n",
            "SNR: 1.500 - Iter: 225 - Last 25.0 iterations took 18.00s\n",
            "SNR: 1.500 - Iter: 250 - Last 25.0 iterations took 19.91s\n",
            "SNR: 1.500 - Iter: 275 - Last 25.0 iterations took 21.75s\n",
            "SNR: 1.500 - Iter: 300 - Last 25.0 iterations took 23.60s\n",
            "SNR: 1.500 - Iter: 325 - Last 25.0 iterations took 25.43s\n",
            "SNR: 1.500 - Iter: 350 - Last 25.0 iterations took 27.28s\n",
            "SNR: 1.500 - Iter: 375 - Last 25.0 iterations took 29.17s\n",
            "SNR: 1.500 - Iter: 400 - Last 25.0 iterations took 31.07s\n",
            "SNR: 1.500 - Iter: 425 - Last 25.0 iterations took 32.91s\n",
            "SNR: 1.500 - Iter: 450 - Last 25.0 iterations took 34.96s\n",
            "SNR: 1.500 - Iter: 475 - Last 25.0 iterations took 36.83s\n",
            "SNR: 1.500 - Iter: 500 - Last 25.0 iterations took 38.69s\n",
            "SNR: 1.500 - Iter: 525 - Last 25.0 iterations took 40.55s\n",
            "SNR: 1.500 - Iter: 550 - Last 25.0 iterations took 42.44s\n",
            "SNR: 1.500 - Iter: 575 - Last 25.0 iterations took 44.71s\n",
            "SNR: 1.500 - Iter: 600 - Last 25.0 iterations took 47.07s\n",
            "SNR: 1.500 - Iter: 625 - Last 25.0 iterations took 49.37s\n",
            "SNR: 1.500 - Iter: 650 - Last 25.0 iterations took 51.27s\n",
            "SNR: 1.500 - Iter: 675 - Last 25.0 iterations took 53.15s\n",
            "SNR: 1.500 - Iter: 700 - Last 25.0 iterations took 54.98s\n",
            "SNR: 1.500 - Iter: 725 - Last 25.0 iterations took 56.95s\n",
            "SNR: 1.500 - Iter: 750 - Last 25.0 iterations took 58.76s\n",
            "SNR: 1.500 - Iter: 775 - Last 25.0 iterations took 60.60s\n",
            "SNR: 1.500 - Iter: 800 - Last 25.0 iterations took 62.46s\n",
            "SNR: 1.500 - Iter: 825 - Last 25.0 iterations took 64.31s\n",
            "SNR: 1.500 - Iter: 850 - Last 25.0 iterations took 66.20s\n",
            "SNR: 1.500 - Iter: 875 - Last 25.0 iterations took 68.05s\n",
            "SNR: 1.500 - Iter: 900 - Last 25.0 iterations took 69.88s\n",
            "SNR: 1.500 - Iter: 925 - Last 25.0 iterations took 71.72s\n",
            "SNR: 1.500 - Iter: 950 - Last 25.0 iterations took 73.55s\n",
            "SNR: 1.500 - Iter: 975 - Last 25.0 iterations took 75.41s\n",
            "SNR: 1.500 - Iter: 1000 - Last 25.0 iterations took 77.44s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.99\n",
            " -> Total Time: 1603.82s\n",
            "SNR: 2.000 - Iter: 25 - Last 25.0 iterations took 1.83s\n",
            "SNR: 2.000 - Iter: 50 - Last 25.0 iterations took 3.67s\n",
            "SNR: 2.000 - Iter: 75 - Last 25.0 iterations took 5.50s\n",
            "SNR: 2.000 - Iter: 100 - Last 25.0 iterations took 7.34s\n",
            "SNR: 2.000 - Iter: 125 - Last 25.0 iterations took 9.17s\n",
            "SNR: 2.000 - Iter: 150 - Last 25.0 iterations took 11.03s\n",
            "SNR: 2.000 - Iter: 175 - Last 25.0 iterations took 12.84s\n",
            "SNR: 2.000 - Iter: 200 - Last 25.0 iterations took 14.69s\n",
            "SNR: 2.000 - Iter: 225 - Last 25.0 iterations took 16.53s\n",
            "SNR: 2.000 - Iter: 250 - Last 25.0 iterations took 18.58s\n",
            "SNR: 2.000 - Iter: 275 - Last 25.0 iterations took 20.39s\n",
            "SNR: 2.000 - Iter: 300 - Last 25.0 iterations took 22.20s\n",
            "SNR: 2.000 - Iter: 325 - Last 25.0 iterations took 24.04s\n",
            "SNR: 2.000 - Iter: 350 - Last 25.0 iterations took 26.04s\n",
            "SNR: 2.000 - Iter: 375 - Last 25.0 iterations took 27.95s\n",
            "SNR: 2.000 - Iter: 400 - Last 25.0 iterations took 29.86s\n",
            "SNR: 2.000 - Iter: 425 - Last 25.0 iterations took 31.76s\n",
            "SNR: 2.000 - Iter: 450 - Last 25.0 iterations took 33.62s\n",
            "SNR: 2.000 - Iter: 475 - Last 25.0 iterations took 35.45s\n",
            "SNR: 2.000 - Iter: 500 - Last 25.0 iterations took 37.38s\n",
            "SNR: 2.000 - Iter: 525 - Last 25.0 iterations took 39.39s\n",
            "SNR: 2.000 - Iter: 550 - Last 25.0 iterations took 41.25s\n",
            "SNR: 2.000 - Iter: 575 - Last 25.0 iterations took 43.11s\n",
            "SNR: 2.000 - Iter: 600 - Last 25.0 iterations took 45.03s\n",
            "SNR: 2.000 - Iter: 625 - Last 25.0 iterations took 46.86s\n",
            "SNR: 2.000 - Iter: 650 - Last 25.0 iterations took 48.70s\n",
            "SNR: 2.000 - Iter: 675 - Last 25.0 iterations took 50.52s\n",
            "SNR: 2.000 - Iter: 700 - Last 25.0 iterations took 52.33s\n",
            "SNR: 2.000 - Iter: 725 - Last 25.0 iterations took 54.16s\n",
            "SNR: 2.000 - Iter: 750 - Last 25.0 iterations took 56.01s\n",
            "SNR: 2.000 - Iter: 775 - Last 25.0 iterations took 57.89s\n",
            "SNR: 2.000 - Iter: 800 - Last 25.0 iterations took 59.95s\n",
            "SNR: 2.000 - Iter: 825 - Last 25.0 iterations took 61.90s\n",
            "SNR: 2.000 - Iter: 850 - Last 25.0 iterations took 63.83s\n",
            "SNR: 2.000 - Iter: 875 - Last 25.0 iterations took 65.71s\n",
            "SNR: 2.000 - Iter: 900 - Last 25.0 iterations took 67.56s\n",
            "SNR: 2.000 - Iter: 925 - Last 25.0 iterations took 69.38s\n",
            "SNR: 2.000 - Iter: 950 - Last 25.0 iterations took 71.24s\n",
            "SNR: 2.000 - Iter: 975 - Last 25.0 iterations took 73.06s\n",
            "SNR: 2.000 - Iter: 1000 - Last 25.0 iterations took 74.89s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.98\n",
            " -> Total Time: 1532.62s\n",
            "SNR: 2.500 - Iter: 25 - Last 25.0 iterations took 1.85s\n",
            "SNR: 2.500 - Iter: 50 - Last 25.0 iterations took 3.88s\n",
            "SNR: 2.500 - Iter: 75 - Last 25.0 iterations took 5.75s\n",
            "SNR: 2.500 - Iter: 100 - Last 25.0 iterations took 7.61s\n",
            "SNR: 2.500 - Iter: 125 - Last 25.0 iterations took 9.45s\n",
            "SNR: 2.500 - Iter: 150 - Last 25.0 iterations took 11.28s\n",
            "SNR: 2.500 - Iter: 175 - Last 25.0 iterations took 13.18s\n",
            "SNR: 2.500 - Iter: 200 - Last 25.0 iterations took 15.03s\n",
            "SNR: 2.500 - Iter: 225 - Last 25.0 iterations took 16.92s\n",
            "SNR: 2.500 - Iter: 250 - Last 25.0 iterations took 18.81s\n",
            "SNR: 2.500 - Iter: 275 - Last 25.0 iterations took 20.65s\n",
            "SNR: 2.500 - Iter: 300 - Last 25.0 iterations took 22.53s\n",
            "SNR: 2.500 - Iter: 325 - Last 25.0 iterations took 24.52s\n",
            "SNR: 2.500 - Iter: 350 - Last 25.0 iterations took 26.34s\n",
            "SNR: 2.500 - Iter: 375 - Last 25.0 iterations took 28.18s\n",
            "SNR: 2.500 - Iter: 400 - Last 25.0 iterations took 30.08s\n",
            "SNR: 2.500 - Iter: 425 - Last 25.0 iterations took 31.93s\n",
            "SNR: 2.500 - Iter: 450 - Last 25.0 iterations took 33.81s\n",
            "SNR: 2.500 - Iter: 475 - Last 25.0 iterations took 35.66s\n",
            "SNR: 2.500 - Iter: 500 - Last 25.0 iterations took 37.46s\n",
            "SNR: 2.500 - Iter: 525 - Last 25.0 iterations took 39.30s\n",
            "SNR: 2.500 - Iter: 550 - Last 25.0 iterations took 41.17s\n",
            "SNR: 2.500 - Iter: 575 - Last 25.0 iterations took 43.03s\n",
            "SNR: 2.500 - Iter: 600 - Last 25.0 iterations took 45.04s\n",
            "SNR: 2.500 - Iter: 625 - Last 25.0 iterations took 46.85s\n",
            "SNR: 2.500 - Iter: 650 - Last 25.0 iterations took 48.67s\n",
            "SNR: 2.500 - Iter: 675 - Last 25.0 iterations took 50.56s\n",
            "SNR: 2.500 - Iter: 700 - Last 25.0 iterations took 52.41s\n",
            "SNR: 2.500 - Iter: 725 - Last 25.0 iterations took 54.26s\n",
            "SNR: 2.500 - Iter: 750 - Last 25.0 iterations took 56.07s\n",
            "SNR: 2.500 - Iter: 775 - Last 25.0 iterations took 57.88s\n",
            "SNR: 2.500 - Iter: 800 - Last 25.0 iterations took 59.77s\n",
            "SNR: 2.500 - Iter: 825 - Last 25.0 iterations took 61.62s\n",
            "SNR: 2.500 - Iter: 850 - Last 25.0 iterations took 63.43s\n",
            "SNR: 2.500 - Iter: 875 - Last 25.0 iterations took 65.44s\n",
            "SNR: 2.500 - Iter: 900 - Last 25.0 iterations took 67.30s\n",
            "SNR: 2.500 - Iter: 925 - Last 25.0 iterations took 69.12s\n",
            "SNR: 2.500 - Iter: 950 - Last 25.0 iterations took 70.95s\n",
            "SNR: 2.500 - Iter: 975 - Last 25.0 iterations took 72.81s\n",
            "SNR: 2.500 - Iter: 1000 - Last 25.0 iterations took 74.67s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.96\n",
            " -> Total Time: 1535.28s\n",
            "SNR: 3.000 - Iter: 25 - Last 25.0 iterations took 1.86s\n",
            "SNR: 3.000 - Iter: 50 - Last 25.0 iterations took 3.69s\n",
            "SNR: 3.000 - Iter: 75 - Last 25.0 iterations took 5.53s\n",
            "SNR: 3.000 - Iter: 100 - Last 25.0 iterations took 7.37s\n",
            "SNR: 3.000 - Iter: 125 - Last 25.0 iterations took 9.35s\n",
            "SNR: 3.000 - Iter: 150 - Last 25.0 iterations took 11.18s\n",
            "SNR: 3.000 - Iter: 175 - Last 25.0 iterations took 12.97s\n",
            "SNR: 3.000 - Iter: 200 - Last 25.0 iterations took 14.79s\n",
            "SNR: 3.000 - Iter: 225 - Last 25.0 iterations took 16.62s\n",
            "SNR: 3.000 - Iter: 250 - Last 25.0 iterations took 18.46s\n",
            "SNR: 3.000 - Iter: 275 - Last 25.0 iterations took 20.22s\n",
            "SNR: 3.000 - Iter: 300 - Last 25.0 iterations took 22.05s\n",
            "SNR: 3.000 - Iter: 325 - Last 25.0 iterations took 23.90s\n",
            "SNR: 3.000 - Iter: 350 - Last 25.0 iterations took 25.70s\n",
            "SNR: 3.000 - Iter: 375 - Last 25.0 iterations took 27.56s\n",
            "SNR: 3.000 - Iter: 400 - Last 25.0 iterations took 29.56s\n",
            "SNR: 3.000 - Iter: 425 - Last 25.0 iterations took 31.41s\n",
            "SNR: 3.000 - Iter: 450 - Last 25.0 iterations took 33.28s\n",
            "SNR: 3.000 - Iter: 475 - Last 25.0 iterations took 35.13s\n",
            "SNR: 3.000 - Iter: 500 - Last 25.0 iterations took 37.02s\n",
            "SNR: 3.000 - Iter: 525 - Last 25.0 iterations took 38.83s\n",
            "SNR: 3.000 - Iter: 550 - Last 25.0 iterations took 40.66s\n",
            "SNR: 3.000 - Iter: 575 - Last 25.0 iterations took 42.48s\n",
            "SNR: 3.000 - Iter: 600 - Last 25.0 iterations took 44.36s\n",
            "SNR: 3.000 - Iter: 625 - Last 25.0 iterations took 46.16s\n",
            "SNR: 3.000 - Iter: 650 - Last 25.0 iterations took 47.99s\n",
            "SNR: 3.000 - Iter: 675 - Last 25.0 iterations took 50.02s\n",
            "SNR: 3.000 - Iter: 700 - Last 25.0 iterations took 51.84s\n",
            "SNR: 3.000 - Iter: 725 - Last 25.0 iterations took 53.66s\n",
            "SNR: 3.000 - Iter: 750 - Last 25.0 iterations took 55.48s\n",
            "SNR: 3.000 - Iter: 775 - Last 25.0 iterations took 57.29s\n",
            "SNR: 3.000 - Iter: 800 - Last 25.0 iterations took 59.14s\n",
            "SNR: 3.000 - Iter: 825 - Last 25.0 iterations took 61.00s\n",
            "SNR: 3.000 - Iter: 850 - Last 25.0 iterations took 62.84s\n",
            "SNR: 3.000 - Iter: 875 - Last 25.0 iterations took 64.65s\n",
            "SNR: 3.000 - Iter: 900 - Last 25.0 iterations took 66.47s\n",
            "SNR: 3.000 - Iter: 925 - Last 25.0 iterations took 68.29s\n",
            "SNR: 3.000 - Iter: 950 - Last 25.0 iterations took 70.27s\n",
            "SNR: 3.000 - Iter: 975 - Last 25.0 iterations took 72.04s\n",
            "SNR: 3.000 - Iter: 1000 - Last 25.0 iterations took 73.82s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.93\n",
            " -> Total Time: 1514.93s\n",
            "SNR: 3.500 - Iter: 25 - Last 25.0 iterations took 1.79s\n",
            "SNR: 3.500 - Iter: 50 - Last 25.0 iterations took 3.55s\n",
            "SNR: 3.500 - Iter: 75 - Last 25.0 iterations took 5.34s\n",
            "SNR: 3.500 - Iter: 100 - Last 25.0 iterations took 7.15s\n",
            "SNR: 3.500 - Iter: 125 - Last 25.0 iterations took 9.07s\n",
            "SNR: 3.500 - Iter: 150 - Last 25.0 iterations took 10.98s\n",
            "SNR: 3.500 - Iter: 175 - Last 25.0 iterations took 12.87s\n",
            "SNR: 3.500 - Iter: 200 - Last 25.0 iterations took 14.99s\n",
            "SNR: 3.500 - Iter: 225 - Last 25.0 iterations took 16.90s\n",
            "SNR: 3.500 - Iter: 250 - Last 25.0 iterations took 18.78s\n",
            "SNR: 3.500 - Iter: 275 - Last 25.0 iterations took 20.56s\n",
            "SNR: 3.500 - Iter: 300 - Last 25.0 iterations took 22.34s\n",
            "SNR: 3.500 - Iter: 325 - Last 25.0 iterations took 24.15s\n",
            "SNR: 3.500 - Iter: 350 - Last 25.0 iterations took 25.93s\n",
            "SNR: 3.500 - Iter: 375 - Last 25.0 iterations took 27.69s\n",
            "SNR: 3.500 - Iter: 400 - Last 25.0 iterations took 29.45s\n",
            "SNR: 3.500 - Iter: 425 - Last 25.0 iterations took 31.22s\n",
            "SNR: 3.500 - Iter: 450 - Last 25.0 iterations took 33.00s\n",
            "SNR: 3.500 - Iter: 475 - Last 25.0 iterations took 34.95s\n",
            "SNR: 3.500 - Iter: 500 - Last 25.0 iterations took 36.76s\n",
            "SNR: 3.500 - Iter: 525 - Last 25.0 iterations took 38.56s\n",
            "SNR: 3.500 - Iter: 550 - Last 25.0 iterations took 40.34s\n",
            "SNR: 3.500 - Iter: 575 - Last 25.0 iterations took 42.12s\n",
            "SNR: 3.500 - Iter: 600 - Last 25.0 iterations took 43.92s\n",
            "SNR: 3.500 - Iter: 625 - Last 25.0 iterations took 45.72s\n",
            "SNR: 3.500 - Iter: 650 - Last 25.0 iterations took 47.56s\n",
            "SNR: 3.500 - Iter: 675 - Last 25.0 iterations took 49.34s\n",
            "SNR: 3.500 - Iter: 700 - Last 25.0 iterations took 51.21s\n",
            "SNR: 3.500 - Iter: 725 - Last 25.0 iterations took 53.14s\n",
            "SNR: 3.500 - Iter: 750 - Last 25.0 iterations took 55.20s\n",
            "SNR: 3.500 - Iter: 775 - Last 25.0 iterations took 57.05s\n",
            "SNR: 3.500 - Iter: 800 - Last 25.0 iterations took 58.82s\n",
            "SNR: 3.500 - Iter: 825 - Last 25.0 iterations took 60.58s\n",
            "SNR: 3.500 - Iter: 850 - Last 25.0 iterations took 62.37s\n",
            "SNR: 3.500 - Iter: 875 - Last 25.0 iterations took 64.15s\n",
            "SNR: 3.500 - Iter: 900 - Last 25.0 iterations took 65.99s\n",
            "SNR: 3.500 - Iter: 925 - Last 25.0 iterations took 67.75s\n",
            "SNR: 3.500 - Iter: 950 - Last 25.0 iterations took 69.53s\n",
            "SNR: 3.500 - Iter: 975 - Last 25.0 iterations took 71.32s\n",
            "SNR: 3.500 - Iter: 1000 - Last 25.0 iterations took 73.25s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.87\n",
            " -> Total Time: 1505.39s\n",
            "SNR: 4.000 - Iter: 25 - Last 25.0 iterations took 1.76s\n",
            "SNR: 4.000 - Iter: 50 - Last 25.0 iterations took 3.53s\n",
            "SNR: 4.000 - Iter: 75 - Last 25.0 iterations took 5.28s\n",
            "SNR: 4.000 - Iter: 100 - Last 25.0 iterations took 7.04s\n",
            "SNR: 4.000 - Iter: 125 - Last 25.0 iterations took 8.78s\n",
            "SNR: 4.000 - Iter: 150 - Last 25.0 iterations took 10.61s\n",
            "SNR: 4.000 - Iter: 175 - Last 25.0 iterations took 12.35s\n",
            "SNR: 4.000 - Iter: 200 - Last 25.0 iterations took 14.13s\n",
            "SNR: 4.000 - Iter: 225 - Last 25.0 iterations took 15.88s\n",
            "SNR: 4.000 - Iter: 250 - Last 25.0 iterations took 17.65s\n",
            "SNR: 4.000 - Iter: 275 - Last 25.0 iterations took 19.58s\n",
            "SNR: 4.000 - Iter: 300 - Last 25.0 iterations took 21.34s\n",
            "SNR: 4.000 - Iter: 325 - Last 25.0 iterations took 23.12s\n",
            "SNR: 4.000 - Iter: 350 - Last 25.0 iterations took 24.96s\n",
            "SNR: 4.000 - Iter: 375 - Last 25.0 iterations took 26.78s\n",
            "SNR: 4.000 - Iter: 400 - Last 25.0 iterations took 28.57s\n",
            "SNR: 4.000 - Iter: 425 - Last 25.0 iterations took 30.33s\n",
            "SNR: 4.000 - Iter: 450 - Last 25.0 iterations took 32.11s\n",
            "SNR: 4.000 - Iter: 475 - Last 25.0 iterations took 33.88s\n",
            "SNR: 4.000 - Iter: 500 - Last 25.0 iterations took 35.62s\n",
            "SNR: 4.000 - Iter: 525 - Last 25.0 iterations took 37.42s\n",
            "SNR: 4.000 - Iter: 550 - Last 25.0 iterations took 39.37s\n",
            "SNR: 4.000 - Iter: 575 - Last 25.0 iterations took 41.13s\n",
            "SNR: 4.000 - Iter: 600 - Last 25.0 iterations took 42.88s\n",
            "SNR: 4.000 - Iter: 625 - Last 25.0 iterations took 44.63s\n",
            "SNR: 4.000 - Iter: 650 - Last 25.0 iterations took 46.37s\n",
            "SNR: 4.000 - Iter: 675 - Last 25.0 iterations took 48.18s\n",
            "SNR: 4.000 - Iter: 700 - Last 25.0 iterations took 49.93s\n",
            "SNR: 4.000 - Iter: 725 - Last 25.0 iterations took 51.67s\n",
            "SNR: 4.000 - Iter: 750 - Last 25.0 iterations took 53.45s\n",
            "SNR: 4.000 - Iter: 775 - Last 25.0 iterations took 55.19s\n",
            "SNR: 4.000 - Iter: 800 - Last 25.0 iterations took 56.96s\n",
            "SNR: 4.000 - Iter: 825 - Last 25.0 iterations took 58.88s\n",
            "SNR: 4.000 - Iter: 850 - Last 25.0 iterations took 60.67s\n",
            "SNR: 4.000 - Iter: 875 - Last 25.0 iterations took 62.43s\n",
            "SNR: 4.000 - Iter: 900 - Last 25.0 iterations took 64.18s\n",
            "SNR: 4.000 - Iter: 925 - Last 25.0 iterations took 65.91s\n",
            "SNR: 4.000 - Iter: 950 - Last 25.0 iterations took 67.68s\n",
            "SNR: 4.000 - Iter: 975 - Last 25.0 iterations took 69.41s\n",
            "SNR: 4.000 - Iter: 1000 - Last 25.0 iterations took 71.20s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.77\n",
            " -> Total Time: 1460.85s\n",
            "SNR: 4.500 - Iter: 25 - Last 25.0 iterations took 1.70s\n",
            "SNR: 4.500 - Iter: 50 - Last 25.0 iterations took 3.46s\n",
            "SNR: 4.500 - Iter: 75 - Last 25.0 iterations took 5.37s\n",
            "SNR: 4.500 - Iter: 100 - Last 25.0 iterations took 7.11s\n",
            "SNR: 4.500 - Iter: 125 - Last 25.0 iterations took 8.85s\n",
            "SNR: 4.500 - Iter: 150 - Last 25.0 iterations took 10.62s\n",
            "SNR: 4.500 - Iter: 175 - Last 25.0 iterations took 12.44s\n",
            "SNR: 4.500 - Iter: 200 - Last 25.0 iterations took 14.21s\n",
            "SNR: 4.500 - Iter: 225 - Last 25.0 iterations took 15.97s\n",
            "SNR: 4.500 - Iter: 250 - Last 25.0 iterations took 17.74s\n",
            "SNR: 4.500 - Iter: 275 - Last 25.0 iterations took 19.50s\n",
            "SNR: 4.500 - Iter: 300 - Last 25.0 iterations took 21.27s\n",
            "SNR: 4.500 - Iter: 325 - Last 25.0 iterations took 23.03s\n",
            "SNR: 4.500 - Iter: 350 - Last 25.0 iterations took 24.94s\n",
            "SNR: 4.500 - Iter: 375 - Last 25.0 iterations took 26.74s\n",
            "SNR: 4.500 - Iter: 400 - Last 25.0 iterations took 28.58s\n",
            "SNR: 4.500 - Iter: 425 - Last 25.0 iterations took 30.37s\n",
            "SNR: 4.500 - Iter: 450 - Last 25.0 iterations took 32.14s\n",
            "SNR: 4.500 - Iter: 475 - Last 25.0 iterations took 33.92s\n",
            "SNR: 4.500 - Iter: 500 - Last 25.0 iterations took 35.69s\n",
            "SNR: 4.500 - Iter: 525 - Last 25.0 iterations took 37.46s\n",
            "SNR: 4.500 - Iter: 550 - Last 25.0 iterations took 39.22s\n",
            "SNR: 4.500 - Iter: 575 - Last 25.0 iterations took 40.97s\n",
            "SNR: 4.500 - Iter: 600 - Last 25.0 iterations took 42.78s\n",
            "SNR: 4.500 - Iter: 625 - Last 25.0 iterations took 44.70s\n",
            "SNR: 4.500 - Iter: 650 - Last 25.0 iterations took 46.49s\n",
            "SNR: 4.500 - Iter: 675 - Last 25.0 iterations took 48.30s\n",
            "SNR: 4.500 - Iter: 700 - Last 25.0 iterations took 50.10s\n",
            "SNR: 4.500 - Iter: 725 - Last 25.0 iterations took 51.87s\n",
            "SNR: 4.500 - Iter: 750 - Last 25.0 iterations took 53.68s\n",
            "SNR: 4.500 - Iter: 775 - Last 25.0 iterations took 55.47s\n",
            "SNR: 4.500 - Iter: 800 - Last 25.0 iterations took 57.27s\n",
            "SNR: 4.500 - Iter: 825 - Last 25.0 iterations took 59.03s\n",
            "SNR: 4.500 - Iter: 850 - Last 25.0 iterations took 60.82s\n",
            "SNR: 4.500 - Iter: 875 - Last 25.0 iterations took 62.58s\n",
            "SNR: 4.500 - Iter: 900 - Last 25.0 iterations took 64.50s\n",
            "SNR: 4.500 - Iter: 925 - Last 25.0 iterations took 66.30s\n",
            "SNR: 4.500 - Iter: 950 - Last 25.0 iterations took 68.11s\n",
            "SNR: 4.500 - Iter: 975 - Last 25.0 iterations took 69.88s\n",
            "SNR: 4.500 - Iter: 1000 - Last 25.0 iterations took 71.68s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.66\n",
            " -> Total Time: 1464.86s\n",
            "SNR: 5.000 - Iter: 25 - Last 25.0 iterations took 1.80s\n",
            "SNR: 5.000 - Iter: 50 - Last 25.0 iterations took 3.57s\n",
            "SNR: 5.000 - Iter: 75 - Last 25.0 iterations took 5.35s\n",
            "SNR: 5.000 - Iter: 100 - Last 25.0 iterations took 7.14s\n",
            "SNR: 5.000 - Iter: 125 - Last 25.0 iterations took 8.91s\n",
            "SNR: 5.000 - Iter: 150 - Last 25.0 iterations took 10.88s\n",
            "SNR: 5.000 - Iter: 175 - Last 25.0 iterations took 12.65s\n",
            "SNR: 5.000 - Iter: 200 - Last 25.0 iterations took 14.42s\n",
            "SNR: 5.000 - Iter: 225 - Last 25.0 iterations took 16.21s\n",
            "SNR: 5.000 - Iter: 250 - Last 25.0 iterations took 17.98s\n",
            "SNR: 5.000 - Iter: 275 - Last 25.0 iterations took 19.75s\n",
            "SNR: 5.000 - Iter: 300 - Last 25.0 iterations took 21.57s\n",
            "SNR: 5.000 - Iter: 325 - Last 25.0 iterations took 23.35s\n",
            "SNR: 5.000 - Iter: 350 - Last 25.0 iterations took 25.16s\n",
            "SNR: 5.000 - Iter: 375 - Last 25.0 iterations took 26.99s\n",
            "SNR: 5.000 - Iter: 400 - Last 25.0 iterations took 28.77s\n",
            "SNR: 5.000 - Iter: 425 - Last 25.0 iterations took 30.70s\n",
            "SNR: 5.000 - Iter: 450 - Last 25.0 iterations took 32.57s\n",
            "SNR: 5.000 - Iter: 475 - Last 25.0 iterations took 34.42s\n",
            "SNR: 5.000 - Iter: 500 - Last 25.0 iterations took 36.23s\n",
            "SNR: 5.000 - Iter: 525 - Last 25.0 iterations took 38.01s\n",
            "SNR: 5.000 - Iter: 550 - Last 25.0 iterations took 39.79s\n",
            "SNR: 5.000 - Iter: 575 - Last 25.0 iterations took 41.56s\n",
            "SNR: 5.000 - Iter: 600 - Last 25.0 iterations took 43.34s\n",
            "SNR: 5.000 - Iter: 625 - Last 25.0 iterations took 45.12s\n",
            "SNR: 5.000 - Iter: 650 - Last 25.0 iterations took 46.88s\n",
            "SNR: 5.000 - Iter: 675 - Last 25.0 iterations took 48.70s\n",
            "SNR: 5.000 - Iter: 700 - Last 25.0 iterations took 50.68s\n",
            "SNR: 5.000 - Iter: 725 - Last 25.0 iterations took 52.51s\n",
            "SNR: 5.000 - Iter: 750 - Last 25.0 iterations took 54.42s\n",
            "SNR: 5.000 - Iter: 775 - Last 25.0 iterations took 56.22s\n",
            "SNR: 5.000 - Iter: 800 - Last 25.0 iterations took 58.04s\n",
            "SNR: 5.000 - Iter: 825 - Last 25.0 iterations took 59.87s\n",
            "SNR: 5.000 - Iter: 850 - Last 25.0 iterations took 61.71s\n",
            "SNR: 5.000 - Iter: 875 - Last 25.0 iterations took 63.52s\n",
            "SNR: 5.000 - Iter: 900 - Last 25.0 iterations took 65.32s\n",
            "SNR: 5.000 - Iter: 925 - Last 25.0 iterations took 67.13s\n",
            "SNR: 5.000 - Iter: 950 - Last 25.0 iterations took 68.96s\n",
            "SNR: 5.000 - Iter: 975 - Last 25.0 iterations took 70.97s\n",
            "SNR: 5.000 - Iter: 1000 - Last 25.0 iterations took 72.80s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.55\n",
            " -> Total Time: 1483.97s\n",
            "SNR: 5.500 - Iter: 25 - Last 25.0 iterations took 1.83s\n",
            "SNR: 5.500 - Iter: 50 - Last 25.0 iterations took 3.64s\n",
            "SNR: 5.500 - Iter: 75 - Last 25.0 iterations took 5.43s\n",
            "SNR: 5.500 - Iter: 100 - Last 25.0 iterations took 7.23s\n",
            "SNR: 5.500 - Iter: 125 - Last 25.0 iterations took 9.08s\n",
            "SNR: 5.500 - Iter: 150 - Last 25.0 iterations took 10.91s\n",
            "SNR: 5.500 - Iter: 175 - Last 25.0 iterations took 12.77s\n",
            "SNR: 5.500 - Iter: 200 - Last 25.0 iterations took 14.57s\n",
            "SNR: 5.500 - Iter: 225 - Last 25.0 iterations took 16.57s\n",
            "SNR: 5.500 - Iter: 250 - Last 25.0 iterations took 18.39s\n",
            "SNR: 5.500 - Iter: 275 - Last 25.0 iterations took 20.23s\n",
            "SNR: 5.500 - Iter: 300 - Last 25.0 iterations took 22.04s\n",
            "SNR: 5.500 - Iter: 325 - Last 25.0 iterations took 23.85s\n",
            "SNR: 5.500 - Iter: 350 - Last 25.0 iterations took 25.69s\n",
            "SNR: 5.500 - Iter: 375 - Last 25.0 iterations took 27.50s\n",
            "SNR: 5.500 - Iter: 400 - Last 25.0 iterations took 29.36s\n",
            "SNR: 5.500 - Iter: 425 - Last 25.0 iterations took 31.23s\n",
            "SNR: 5.500 - Iter: 450 - Last 25.0 iterations took 33.21s\n",
            "SNR: 5.500 - Iter: 475 - Last 25.0 iterations took 35.27s\n",
            "SNR: 5.500 - Iter: 500 - Last 25.0 iterations took 37.38s\n",
            "SNR: 5.500 - Iter: 525 - Last 25.0 iterations took 39.30s\n",
            "SNR: 5.500 - Iter: 550 - Last 25.0 iterations took 41.22s\n",
            "SNR: 5.500 - Iter: 575 - Last 25.0 iterations took 43.16s\n",
            "SNR: 5.500 - Iter: 600 - Last 25.0 iterations took 45.15s\n",
            "SNR: 5.500 - Iter: 625 - Last 25.0 iterations took 47.16s\n",
            "SNR: 5.500 - Iter: 650 - Last 25.0 iterations took 49.16s\n",
            "SNR: 5.500 - Iter: 675 - Last 25.0 iterations took 51.07s\n",
            "SNR: 5.500 - Iter: 700 - Last 25.0 iterations took 53.03s\n",
            "SNR: 5.500 - Iter: 725 - Last 25.0 iterations took 54.87s\n",
            "SNR: 5.500 - Iter: 750 - Last 25.0 iterations took 56.71s\n",
            "SNR: 5.500 - Iter: 775 - Last 25.0 iterations took 58.76s\n",
            "SNR: 5.500 - Iter: 800 - Last 25.0 iterations took 60.60s\n",
            "SNR: 5.500 - Iter: 825 - Last 25.0 iterations took 62.41s\n",
            "SNR: 5.500 - Iter: 850 - Last 25.0 iterations took 64.28s\n",
            "SNR: 5.500 - Iter: 875 - Last 25.0 iterations took 66.13s\n",
            "SNR: 5.500 - Iter: 900 - Last 25.0 iterations took 67.98s\n",
            "SNR: 5.500 - Iter: 925 - Last 25.0 iterations took 69.89s\n",
            "SNR: 5.500 - Iter: 950 - Last 25.0 iterations took 71.83s\n",
            "SNR: 5.500 - Iter: 975 - Last 25.0 iterations took 73.82s\n",
            "SNR: 5.500 - Iter: 1000 - Last 25.0 iterations took 75.84s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.42\n",
            " -> Total Time: 1538.53s\n",
            "SNR: 6.000 - Iter: 25 - Last 25.0 iterations took 1.83s\n",
            "SNR: 6.000 - Iter: 50 - Last 25.0 iterations took 3.83s\n",
            "SNR: 6.000 - Iter: 75 - Last 25.0 iterations took 5.65s\n",
            "SNR: 6.000 - Iter: 100 - Last 25.0 iterations took 7.46s\n",
            "SNR: 6.000 - Iter: 125 - Last 25.0 iterations took 9.31s\n",
            "SNR: 6.000 - Iter: 150 - Last 25.0 iterations took 11.17s\n",
            "SNR: 6.000 - Iter: 175 - Last 25.0 iterations took 13.00s\n",
            "SNR: 6.000 - Iter: 200 - Last 25.0 iterations took 14.83s\n",
            "SNR: 6.000 - Iter: 225 - Last 25.0 iterations took 16.65s\n",
            "SNR: 6.000 - Iter: 250 - Last 25.0 iterations took 18.47s\n",
            "SNR: 6.000 - Iter: 275 - Last 25.0 iterations took 20.29s\n",
            "SNR: 6.000 - Iter: 300 - Last 25.0 iterations took 22.28s\n",
            "SNR: 6.000 - Iter: 325 - Last 25.0 iterations took 24.09s\n",
            "SNR: 6.000 - Iter: 350 - Last 25.0 iterations took 25.91s\n",
            "SNR: 6.000 - Iter: 375 - Last 25.0 iterations took 27.69s\n",
            "SNR: 6.000 - Iter: 400 - Last 25.0 iterations took 29.48s\n",
            "SNR: 6.000 - Iter: 425 - Last 25.0 iterations took 31.30s\n",
            "SNR: 6.000 - Iter: 450 - Last 25.0 iterations took 33.08s\n",
            "SNR: 6.000 - Iter: 475 - Last 25.0 iterations took 34.84s\n",
            "SNR: 6.000 - Iter: 500 - Last 25.0 iterations took 36.65s\n",
            "SNR: 6.000 - Iter: 525 - Last 25.0 iterations took 38.43s\n",
            "SNR: 6.000 - Iter: 550 - Last 25.0 iterations took 40.21s\n",
            "SNR: 6.000 - Iter: 575 - Last 25.0 iterations took 42.18s\n",
            "SNR: 6.000 - Iter: 600 - Last 25.0 iterations took 43.98s\n",
            "SNR: 6.000 - Iter: 625 - Last 25.0 iterations took 45.78s\n",
            "SNR: 6.000 - Iter: 650 - Last 25.0 iterations took 47.55s\n",
            "SNR: 6.000 - Iter: 675 - Last 25.0 iterations took 49.35s\n",
            "SNR: 6.000 - Iter: 700 - Last 25.0 iterations took 51.10s\n",
            "SNR: 6.000 - Iter: 725 - Last 25.0 iterations took 52.86s\n",
            "SNR: 6.000 - Iter: 750 - Last 25.0 iterations took 54.64s\n",
            "SNR: 6.000 - Iter: 775 - Last 25.0 iterations took 56.45s\n",
            "SNR: 6.000 - Iter: 800 - Last 25.0 iterations took 58.26s\n",
            "SNR: 6.000 - Iter: 825 - Last 25.0 iterations took 60.06s\n",
            "SNR: 6.000 - Iter: 850 - Last 25.0 iterations took 62.03s\n",
            "SNR: 6.000 - Iter: 875 - Last 25.0 iterations took 63.86s\n",
            "SNR: 6.000 - Iter: 900 - Last 25.0 iterations took 65.67s\n",
            "SNR: 6.000 - Iter: 925 - Last 25.0 iterations took 67.49s\n",
            "SNR: 6.000 - Iter: 950 - Last 25.0 iterations took 69.27s\n",
            "SNR: 6.000 - Iter: 975 - Last 25.0 iterations took 71.05s\n",
            "SNR: 6.000 - Iter: 1000 - Last 25.0 iterations took 72.85s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.31\n",
            " -> Total Time: 1500.86s\n",
            "SNR: 6.500 - Iter: 25 - Last 25.0 iterations took 1.79s\n",
            "SNR: 6.500 - Iter: 50 - Last 25.0 iterations took 3.58s\n",
            "SNR: 6.500 - Iter: 75 - Last 25.0 iterations took 5.37s\n",
            "SNR: 6.500 - Iter: 100 - Last 25.0 iterations took 7.33s\n",
            "SNR: 6.500 - Iter: 125 - Last 25.0 iterations took 9.11s\n",
            "SNR: 6.500 - Iter: 150 - Last 25.0 iterations took 10.93s\n",
            "SNR: 6.500 - Iter: 175 - Last 25.0 iterations took 12.73s\n",
            "SNR: 6.500 - Iter: 200 - Last 25.0 iterations took 14.55s\n",
            "SNR: 6.500 - Iter: 225 - Last 25.0 iterations took 16.36s\n",
            "SNR: 6.500 - Iter: 250 - Last 25.0 iterations took 18.16s\n",
            "SNR: 6.500 - Iter: 275 - Last 25.0 iterations took 19.97s\n",
            "SNR: 6.500 - Iter: 300 - Last 25.0 iterations took 21.80s\n",
            "SNR: 6.500 - Iter: 325 - Last 25.0 iterations took 23.58s\n",
            "SNR: 6.500 - Iter: 350 - Last 25.0 iterations took 25.44s\n",
            "SNR: 6.500 - Iter: 375 - Last 25.0 iterations took 27.41s\n",
            "SNR: 6.500 - Iter: 400 - Last 25.0 iterations took 29.26s\n",
            "SNR: 6.500 - Iter: 425 - Last 25.0 iterations took 31.06s\n",
            "SNR: 6.500 - Iter: 450 - Last 25.0 iterations took 32.91s\n",
            "SNR: 6.500 - Iter: 475 - Last 25.0 iterations took 34.74s\n",
            "SNR: 6.500 - Iter: 500 - Last 25.0 iterations took 36.55s\n",
            "SNR: 6.500 - Iter: 525 - Last 25.0 iterations took 38.34s\n",
            "SNR: 6.500 - Iter: 550 - Last 25.0 iterations took 40.12s\n",
            "SNR: 6.500 - Iter: 575 - Last 25.0 iterations took 41.90s\n",
            "SNR: 6.500 - Iter: 600 - Last 25.0 iterations took 43.72s\n",
            "SNR: 6.500 - Iter: 625 - Last 25.0 iterations took 45.49s\n",
            "SNR: 6.500 - Iter: 650 - Last 25.0 iterations took 47.45s\n",
            "SNR: 6.500 - Iter: 675 - Last 25.0 iterations took 49.27s\n",
            "SNR: 6.500 - Iter: 700 - Last 25.0 iterations took 51.06s\n",
            "SNR: 6.500 - Iter: 725 - Last 25.0 iterations took 52.86s\n",
            "SNR: 6.500 - Iter: 750 - Last 25.0 iterations took 54.66s\n",
            "SNR: 6.500 - Iter: 775 - Last 25.0 iterations took 56.49s\n",
            "SNR: 6.500 - Iter: 800 - Last 25.0 iterations took 58.27s\n",
            "SNR: 6.500 - Iter: 825 - Last 25.0 iterations took 60.07s\n",
            "SNR: 6.500 - Iter: 850 - Last 25.0 iterations took 61.82s\n",
            "SNR: 6.500 - Iter: 875 - Last 25.0 iterations took 63.61s\n",
            "SNR: 6.500 - Iter: 900 - Last 25.0 iterations took 65.42s\n",
            "SNR: 6.500 - Iter: 925 - Last 25.0 iterations took 67.37s\n",
            "SNR: 6.500 - Iter: 950 - Last 25.0 iterations took 69.23s\n",
            "SNR: 6.500 - Iter: 975 - Last 25.0 iterations took 71.03s\n",
            "SNR: 6.500 - Iter: 1000 - Last 25.0 iterations took 72.84s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.20\n",
            " -> Total Time: 1493.66s\n",
            "SNR: 7.000 - Iter: 25 - Last 25.0 iterations took 1.78s\n",
            "SNR: 7.000 - Iter: 50 - Last 25.0 iterations took 3.60s\n",
            "SNR: 7.000 - Iter: 75 - Last 25.0 iterations took 5.40s\n",
            "SNR: 7.000 - Iter: 100 - Last 25.0 iterations took 7.19s\n",
            "SNR: 7.000 - Iter: 125 - Last 25.0 iterations took 9.02s\n",
            "SNR: 7.000 - Iter: 150 - Last 25.0 iterations took 10.87s\n",
            "SNR: 7.000 - Iter: 175 - Last 25.0 iterations took 12.82s\n",
            "SNR: 7.000 - Iter: 200 - Last 25.0 iterations took 14.63s\n",
            "SNR: 7.000 - Iter: 225 - Last 25.0 iterations took 16.43s\n",
            "SNR: 7.000 - Iter: 250 - Last 25.0 iterations took 18.23s\n",
            "SNR: 7.000 - Iter: 275 - Last 25.0 iterations took 20.05s\n",
            "SNR: 7.000 - Iter: 300 - Last 25.0 iterations took 21.90s\n",
            "SNR: 7.000 - Iter: 325 - Last 25.0 iterations took 23.72s\n",
            "SNR: 7.000 - Iter: 350 - Last 25.0 iterations took 25.55s\n",
            "SNR: 7.000 - Iter: 375 - Last 25.0 iterations took 27.41s\n",
            "SNR: 7.000 - Iter: 400 - Last 25.0 iterations took 29.22s\n",
            "SNR: 7.000 - Iter: 425 - Last 25.0 iterations took 31.07s\n",
            "SNR: 7.000 - Iter: 450 - Last 25.0 iterations took 33.05s\n",
            "SNR: 7.000 - Iter: 475 - Last 25.0 iterations took 34.83s\n",
            "SNR: 7.000 - Iter: 500 - Last 25.0 iterations took 36.66s\n",
            "SNR: 7.000 - Iter: 525 - Last 25.0 iterations took 38.47s\n",
            "SNR: 7.000 - Iter: 550 - Last 25.0 iterations took 40.31s\n",
            "SNR: 7.000 - Iter: 575 - Last 25.0 iterations took 42.14s\n",
            "SNR: 7.000 - Iter: 600 - Last 25.0 iterations took 43.97s\n",
            "SNR: 7.000 - Iter: 625 - Last 25.0 iterations took 45.75s\n",
            "SNR: 7.000 - Iter: 650 - Last 25.0 iterations took 47.55s\n",
            "SNR: 7.000 - Iter: 675 - Last 25.0 iterations took 49.34s\n",
            "SNR: 7.000 - Iter: 700 - Last 25.0 iterations took 51.14s\n",
            "SNR: 7.000 - Iter: 725 - Last 25.0 iterations took 53.10s\n",
            "SNR: 7.000 - Iter: 750 - Last 25.0 iterations took 54.95s\n",
            "SNR: 7.000 - Iter: 775 - Last 25.0 iterations took 56.76s\n",
            "SNR: 7.000 - Iter: 800 - Last 25.0 iterations took 58.62s\n",
            "SNR: 7.000 - Iter: 825 - Last 25.0 iterations took 60.43s\n",
            "SNR: 7.000 - Iter: 850 - Last 25.0 iterations took 62.27s\n",
            "SNR: 7.000 - Iter: 875 - Last 25.0 iterations took 64.10s\n",
            "SNR: 7.000 - Iter: 900 - Last 25.0 iterations took 65.98s\n",
            "SNR: 7.000 - Iter: 925 - Last 25.0 iterations took 67.79s\n",
            "SNR: 7.000 - Iter: 950 - Last 25.0 iterations took 69.64s\n",
            "SNR: 7.000 - Iter: 975 - Last 25.0 iterations took 71.50s\n",
            "SNR: 7.000 - Iter: 1000 - Last 25.0 iterations took 73.58s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.13\n",
            " -> Total Time: 1500.81s\n",
            "SNR: 7.500 - Iter: 25 - Last 25.0 iterations took 1.91s\n",
            "SNR: 7.500 - Iter: 50 - Last 25.0 iterations took 3.88s\n",
            "SNR: 7.500 - Iter: 75 - Last 25.0 iterations took 5.80s\n",
            "SNR: 7.500 - Iter: 100 - Last 25.0 iterations took 7.68s\n",
            "SNR: 7.500 - Iter: 125 - Last 25.0 iterations took 9.52s\n",
            "SNR: 7.500 - Iter: 150 - Last 25.0 iterations took 11.34s\n",
            "SNR: 7.500 - Iter: 175 - Last 25.0 iterations took 13.18s\n",
            "SNR: 7.500 - Iter: 200 - Last 25.0 iterations took 15.08s\n",
            "SNR: 7.500 - Iter: 225 - Last 25.0 iterations took 16.97s\n",
            "SNR: 7.500 - Iter: 250 - Last 25.0 iterations took 19.07s\n",
            "SNR: 7.500 - Iter: 275 - Last 25.0 iterations took 20.92s\n",
            "SNR: 7.500 - Iter: 300 - Last 25.0 iterations took 22.81s\n",
            "SNR: 7.500 - Iter: 325 - Last 25.0 iterations took 24.59s\n",
            "SNR: 7.500 - Iter: 350 - Last 25.0 iterations took 26.39s\n",
            "SNR: 7.500 - Iter: 375 - Last 25.0 iterations took 28.15s\n",
            "SNR: 7.500 - Iter: 400 - Last 25.0 iterations took 29.99s\n",
            "SNR: 7.500 - Iter: 425 - Last 25.0 iterations took 31.84s\n",
            "SNR: 7.500 - Iter: 450 - Last 25.0 iterations took 33.67s\n",
            "SNR: 7.500 - Iter: 475 - Last 25.0 iterations took 35.50s\n",
            "SNR: 7.500 - Iter: 500 - Last 25.0 iterations took 37.29s\n",
            "SNR: 7.500 - Iter: 525 - Last 25.0 iterations took 39.25s\n",
            "SNR: 7.500 - Iter: 550 - Last 25.0 iterations took 41.09s\n",
            "SNR: 7.500 - Iter: 575 - Last 25.0 iterations took 42.90s\n",
            "SNR: 7.500 - Iter: 600 - Last 25.0 iterations took 44.74s\n",
            "SNR: 7.500 - Iter: 625 - Last 25.0 iterations took 46.58s\n",
            "SNR: 7.500 - Iter: 650 - Last 25.0 iterations took 48.40s\n",
            "SNR: 7.500 - Iter: 675 - Last 25.0 iterations took 50.25s\n",
            "SNR: 7.500 - Iter: 700 - Last 25.0 iterations took 52.13s\n",
            "SNR: 7.500 - Iter: 725 - Last 25.0 iterations took 54.01s\n",
            "SNR: 7.500 - Iter: 750 - Last 25.0 iterations took 55.84s\n",
            "SNR: 7.500 - Iter: 775 - Last 25.0 iterations took 57.70s\n",
            "SNR: 7.500 - Iter: 800 - Last 25.0 iterations took 59.78s\n",
            "SNR: 7.500 - Iter: 825 - Last 25.0 iterations took 61.78s\n",
            "SNR: 7.500 - Iter: 850 - Last 25.0 iterations took 63.81s\n",
            "SNR: 7.500 - Iter: 875 - Last 25.0 iterations took 65.75s\n",
            "SNR: 7.500 - Iter: 900 - Last 25.0 iterations took 67.80s\n",
            "SNR: 7.500 - Iter: 925 - Last 25.0 iterations took 69.73s\n",
            "SNR: 7.500 - Iter: 950 - Last 25.0 iterations took 71.63s\n",
            "SNR: 7.500 - Iter: 975 - Last 25.0 iterations took 73.56s\n",
            "SNR: 7.500 - Iter: 1000 - Last 25.0 iterations took 75.45s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.08\n",
            " -> Total Time: 1537.76s\n",
            "SNR: 8.000 - Iter: 25 - Last 25.0 iterations took 1.91s\n",
            "SNR: 8.000 - Iter: 50 - Last 25.0 iterations took 4.06s\n",
            "SNR: 8.000 - Iter: 75 - Last 25.0 iterations took 5.94s\n",
            "SNR: 8.000 - Iter: 100 - Last 25.0 iterations took 7.79s\n",
            "SNR: 8.000 - Iter: 125 - Last 25.0 iterations took 9.72s\n",
            "SNR: 8.000 - Iter: 150 - Last 25.0 iterations took 11.65s\n",
            "SNR: 8.000 - Iter: 175 - Last 25.0 iterations took 13.60s\n",
            "SNR: 8.000 - Iter: 200 - Last 25.0 iterations took 15.40s\n",
            "SNR: 8.000 - Iter: 225 - Last 25.0 iterations took 17.22s\n",
            "SNR: 8.000 - Iter: 250 - Last 25.0 iterations took 19.04s\n",
            "SNR: 8.000 - Iter: 275 - Last 25.0 iterations took 20.84s\n",
            "SNR: 8.000 - Iter: 300 - Last 25.0 iterations took 22.60s\n",
            "SNR: 8.000 - Iter: 325 - Last 25.0 iterations took 24.54s\n",
            "SNR: 8.000 - Iter: 350 - Last 25.0 iterations took 26.31s\n",
            "SNR: 8.000 - Iter: 375 - Last 25.0 iterations took 28.13s\n",
            "SNR: 8.000 - Iter: 400 - Last 25.0 iterations took 29.93s\n",
            "SNR: 8.000 - Iter: 425 - Last 25.0 iterations took 31.75s\n",
            "SNR: 8.000 - Iter: 450 - Last 25.0 iterations took 33.60s\n",
            "SNR: 8.000 - Iter: 475 - Last 25.0 iterations took 35.41s\n",
            "SNR: 8.000 - Iter: 500 - Last 25.0 iterations took 37.23s\n",
            "SNR: 8.000 - Iter: 525 - Last 25.0 iterations took 39.04s\n",
            "SNR: 8.000 - Iter: 550 - Last 25.0 iterations took 40.83s\n",
            "SNR: 8.000 - Iter: 575 - Last 25.0 iterations took 42.64s\n",
            "SNR: 8.000 - Iter: 600 - Last 25.0 iterations took 44.64s\n",
            "SNR: 8.000 - Iter: 625 - Last 25.0 iterations took 46.46s\n",
            "SNR: 8.000 - Iter: 650 - Last 25.0 iterations took 48.30s\n",
            "SNR: 8.000 - Iter: 675 - Last 25.0 iterations took 50.09s\n",
            "SNR: 8.000 - Iter: 700 - Last 25.0 iterations took 51.89s\n",
            "SNR: 8.000 - Iter: 725 - Last 25.0 iterations took 53.68s\n",
            "SNR: 8.000 - Iter: 750 - Last 25.0 iterations took 55.46s\n",
            "SNR: 8.000 - Iter: 775 - Last 25.0 iterations took 57.24s\n",
            "SNR: 8.000 - Iter: 800 - Last 25.0 iterations took 59.06s\n",
            "SNR: 8.000 - Iter: 825 - Last 25.0 iterations took 60.85s\n",
            "SNR: 8.000 - Iter: 850 - Last 25.0 iterations took 62.63s\n",
            "SNR: 8.000 - Iter: 875 - Last 25.0 iterations took 64.56s\n",
            "SNR: 8.000 - Iter: 900 - Last 25.0 iterations took 66.33s\n",
            "SNR: 8.000 - Iter: 925 - Last 25.0 iterations took 68.10s\n",
            "SNR: 8.000 - Iter: 950 - Last 25.0 iterations took 69.85s\n",
            "SNR: 8.000 - Iter: 975 - Last 25.0 iterations took 71.65s\n",
            "SNR: 8.000 - Iter: 1000 - Last 25.0 iterations took 73.44s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 1523.41s\n",
            "SNR: 8.500 - Iter: 25 - Last 25.0 iterations took 1.77s\n",
            "SNR: 8.500 - Iter: 50 - Last 25.0 iterations took 3.56s\n",
            "SNR: 8.500 - Iter: 75 - Last 25.0 iterations took 5.29s\n",
            "SNR: 8.500 - Iter: 100 - Last 25.0 iterations took 7.05s\n",
            "SNR: 8.500 - Iter: 125 - Last 25.0 iterations took 8.98s\n",
            "SNR: 8.500 - Iter: 150 - Last 25.0 iterations took 10.73s\n",
            "SNR: 8.500 - Iter: 175 - Last 25.0 iterations took 12.47s\n",
            "SNR: 8.500 - Iter: 200 - Last 25.0 iterations took 14.29s\n",
            "SNR: 8.500 - Iter: 225 - Last 25.0 iterations took 16.05s\n",
            "SNR: 8.500 - Iter: 250 - Last 25.0 iterations took 17.86s\n",
            "SNR: 8.500 - Iter: 275 - Last 25.0 iterations took 19.65s\n",
            "SNR: 8.500 - Iter: 300 - Last 25.0 iterations took 21.42s\n",
            "SNR: 8.500 - Iter: 325 - Last 25.0 iterations took 23.19s\n",
            "SNR: 8.500 - Iter: 350 - Last 25.0 iterations took 25.00s\n",
            "SNR: 8.500 - Iter: 375 - Last 25.0 iterations took 26.74s\n",
            "SNR: 8.500 - Iter: 400 - Last 25.0 iterations took 28.67s\n",
            "SNR: 8.500 - Iter: 425 - Last 25.0 iterations took 30.45s\n",
            "SNR: 8.500 - Iter: 450 - Last 25.0 iterations took 32.25s\n",
            "SNR: 8.500 - Iter: 475 - Last 25.0 iterations took 34.04s\n",
            "SNR: 8.500 - Iter: 500 - Last 25.0 iterations took 35.88s\n",
            "SNR: 8.500 - Iter: 525 - Last 25.0 iterations took 37.72s\n",
            "SNR: 8.500 - Iter: 550 - Last 25.0 iterations took 39.57s\n",
            "SNR: 8.500 - Iter: 575 - Last 25.0 iterations took 41.34s\n",
            "SNR: 8.500 - Iter: 600 - Last 25.0 iterations took 43.14s\n",
            "SNR: 8.500 - Iter: 625 - Last 25.0 iterations took 44.90s\n",
            "SNR: 8.500 - Iter: 650 - Last 25.0 iterations took 46.70s\n",
            "SNR: 8.500 - Iter: 675 - Last 25.0 iterations took 48.63s\n",
            "SNR: 8.500 - Iter: 700 - Last 25.0 iterations took 50.41s\n",
            "SNR: 8.500 - Iter: 725 - Last 25.0 iterations took 52.17s\n",
            "SNR: 8.500 - Iter: 750 - Last 25.0 iterations took 53.98s\n",
            "SNR: 8.500 - Iter: 775 - Last 25.0 iterations took 55.75s\n",
            "SNR: 8.500 - Iter: 800 - Last 25.0 iterations took 57.55s\n",
            "SNR: 8.500 - Iter: 825 - Last 25.0 iterations took 59.36s\n",
            "SNR: 8.500 - Iter: 850 - Last 25.0 iterations took 61.17s\n",
            "SNR: 8.500 - Iter: 875 - Last 25.0 iterations took 62.96s\n",
            "SNR: 8.500 - Iter: 900 - Last 25.0 iterations took 64.78s\n",
            "SNR: 8.500 - Iter: 925 - Last 25.0 iterations took 66.61s\n",
            "SNR: 8.500 - Iter: 950 - Last 25.0 iterations took 68.61s\n",
            "SNR: 8.500 - Iter: 975 - Last 25.0 iterations took 70.41s\n",
            "SNR: 8.500 - Iter: 1000 - Last 25.0 iterations took 72.23s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 1473.28s\n",
            "SNR: 9.000 - Iter: 25 - Last 25.0 iterations took 1.82s\n",
            "SNR: 9.000 - Iter: 50 - Last 25.0 iterations took 3.63s\n",
            "SNR: 9.000 - Iter: 75 - Last 25.0 iterations took 5.44s\n",
            "SNR: 9.000 - Iter: 100 - Last 25.0 iterations took 7.25s\n",
            "SNR: 9.000 - Iter: 125 - Last 25.0 iterations took 9.05s\n",
            "SNR: 9.000 - Iter: 150 - Last 25.0 iterations took 10.88s\n",
            "SNR: 9.000 - Iter: 175 - Last 25.0 iterations took 12.70s\n",
            "SNR: 9.000 - Iter: 200 - Last 25.0 iterations took 14.68s\n",
            "SNR: 9.000 - Iter: 225 - Last 25.0 iterations took 16.48s\n",
            "SNR: 9.000 - Iter: 250 - Last 25.0 iterations took 18.41s\n",
            "SNR: 9.000 - Iter: 275 - Last 25.0 iterations took 20.32s\n",
            "SNR: 9.000 - Iter: 300 - Last 25.0 iterations took 22.26s\n",
            "SNR: 9.000 - Iter: 325 - Last 25.0 iterations took 24.12s\n",
            "SNR: 9.000 - Iter: 350 - Last 25.0 iterations took 25.97s\n",
            "SNR: 9.000 - Iter: 375 - Last 25.0 iterations took 27.81s\n",
            "SNR: 9.000 - Iter: 400 - Last 25.0 iterations took 29.66s\n",
            "SNR: 9.000 - Iter: 425 - Last 25.0 iterations took 31.52s\n",
            "SNR: 9.000 - Iter: 450 - Last 25.0 iterations took 33.35s\n",
            "SNR: 9.000 - Iter: 475 - Last 25.0 iterations took 35.36s\n",
            "SNR: 9.000 - Iter: 500 - Last 25.0 iterations took 37.18s\n",
            "SNR: 9.000 - Iter: 525 - Last 25.0 iterations took 39.01s\n",
            "SNR: 9.000 - Iter: 550 - Last 25.0 iterations took 40.84s\n",
            "SNR: 9.000 - Iter: 575 - Last 25.0 iterations took 42.71s\n",
            "SNR: 9.000 - Iter: 600 - Last 25.0 iterations took 44.54s\n",
            "SNR: 9.000 - Iter: 625 - Last 25.0 iterations took 46.43s\n",
            "SNR: 9.000 - Iter: 650 - Last 25.0 iterations took 48.29s\n",
            "SNR: 9.000 - Iter: 675 - Last 25.0 iterations took 50.11s\n",
            "SNR: 9.000 - Iter: 700 - Last 25.0 iterations took 52.00s\n",
            "SNR: 9.000 - Iter: 725 - Last 25.0 iterations took 53.82s\n",
            "SNR: 9.000 - Iter: 750 - Last 25.0 iterations took 55.79s\n",
            "SNR: 9.000 - Iter: 775 - Last 25.0 iterations took 57.61s\n",
            "SNR: 9.000 - Iter: 800 - Last 25.0 iterations took 59.41s\n",
            "SNR: 9.000 - Iter: 825 - Last 25.0 iterations took 61.19s\n",
            "SNR: 9.000 - Iter: 850 - Last 25.0 iterations took 63.02s\n",
            "SNR: 9.000 - Iter: 875 - Last 25.0 iterations took 64.90s\n",
            "SNR: 9.000 - Iter: 900 - Last 25.0 iterations took 66.71s\n",
            "SNR: 9.000 - Iter: 925 - Last 25.0 iterations took 68.52s\n",
            "SNR: 9.000 - Iter: 950 - Last 25.0 iterations took 70.36s\n",
            "SNR: 9.000 - Iter: 975 - Last 25.0 iterations took 72.18s\n",
            "SNR: 9.000 - Iter: 1000 - Last 25.0 iterations took 74.18s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1519.50s\n",
            "SNR: 9.500 - Iter: 25 - Last 25.0 iterations took 1.80s\n",
            "SNR: 9.500 - Iter: 50 - Last 25.0 iterations took 3.63s\n",
            "SNR: 9.500 - Iter: 75 - Last 25.0 iterations took 5.55s\n",
            "SNR: 9.500 - Iter: 100 - Last 25.0 iterations took 7.42s\n",
            "SNR: 9.500 - Iter: 125 - Last 25.0 iterations took 9.24s\n",
            "SNR: 9.500 - Iter: 150 - Last 25.0 iterations took 11.07s\n",
            "SNR: 9.500 - Iter: 175 - Last 25.0 iterations took 12.91s\n",
            "SNR: 9.500 - Iter: 200 - Last 25.0 iterations took 14.74s\n",
            "SNR: 9.500 - Iter: 225 - Last 25.0 iterations took 16.54s\n",
            "SNR: 9.500 - Iter: 250 - Last 25.0 iterations took 18.37s\n",
            "SNR: 9.500 - Iter: 275 - Last 25.0 iterations took 20.40s\n",
            "SNR: 9.500 - Iter: 300 - Last 25.0 iterations took 22.23s\n",
            "SNR: 9.500 - Iter: 325 - Last 25.0 iterations took 24.04s\n",
            "SNR: 9.500 - Iter: 350 - Last 25.0 iterations took 25.85s\n",
            "SNR: 9.500 - Iter: 375 - Last 25.0 iterations took 27.70s\n",
            "SNR: 9.500 - Iter: 400 - Last 25.0 iterations took 29.54s\n",
            "SNR: 9.500 - Iter: 425 - Last 25.0 iterations took 31.39s\n",
            "SNR: 9.500 - Iter: 450 - Last 25.0 iterations took 33.24s\n",
            "SNR: 9.500 - Iter: 475 - Last 25.0 iterations took 35.09s\n",
            "SNR: 9.500 - Iter: 500 - Last 25.0 iterations took 36.91s\n",
            "SNR: 9.500 - Iter: 525 - Last 25.0 iterations took 38.71s\n",
            "SNR: 9.500 - Iter: 550 - Last 25.0 iterations took 40.74s\n",
            "SNR: 9.500 - Iter: 575 - Last 25.0 iterations took 42.60s\n",
            "SNR: 9.500 - Iter: 600 - Last 25.0 iterations took 44.42s\n",
            "SNR: 9.500 - Iter: 625 - Last 25.0 iterations took 46.23s\n",
            "SNR: 9.500 - Iter: 650 - Last 25.0 iterations took 48.05s\n",
            "SNR: 9.500 - Iter: 675 - Last 25.0 iterations took 49.87s\n",
            "SNR: 9.500 - Iter: 700 - Last 25.0 iterations took 51.66s\n",
            "SNR: 9.500 - Iter: 725 - Last 25.0 iterations took 53.44s\n",
            "SNR: 9.500 - Iter: 750 - Last 25.0 iterations took 55.29s\n",
            "SNR: 9.500 - Iter: 775 - Last 25.0 iterations took 57.09s\n",
            "SNR: 9.500 - Iter: 800 - Last 25.0 iterations took 58.91s\n",
            "SNR: 9.500 - Iter: 825 - Last 25.0 iterations took 60.90s\n",
            "SNR: 9.500 - Iter: 850 - Last 25.0 iterations took 62.71s\n",
            "SNR: 9.500 - Iter: 875 - Last 25.0 iterations took 64.57s\n",
            "SNR: 9.500 - Iter: 900 - Last 25.0 iterations took 66.43s\n",
            "SNR: 9.500 - Iter: 925 - Last 25.0 iterations took 68.31s\n",
            "SNR: 9.500 - Iter: 950 - Last 25.0 iterations took 70.10s\n",
            "SNR: 9.500 - Iter: 975 - Last 25.0 iterations took 71.91s\n",
            "SNR: 9.500 - Iter: 1000 - Last 25.0 iterations took 73.77s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1513.38s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cALSMP2YvKvC",
        "outputId": "31b120f3-7ca4-429b-d012-c856b6d77d7f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(100-200-100)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f941H6lZvxF6"
      },
      "source": [
        "NUM_OF_TEST_MESSAGE  = 1000\n",
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_TEST_MESSAGE/40\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(channel_size,))\n",
        "\n",
        "\n",
        "#train_init = tf.global_variables_initializer ()\n",
        "#train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  for i in range (NUM_OF_TEST_MESSAGE):\n",
        "    input_message_xx = test_input_message [i:i+1]\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,2*channel_size])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,2*channel_size])\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    if abs(decoded_message-test_input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_TEST_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkx6sASfv9Uk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,bler_per_iter_ldpc_itpp_psk_4,'', label=\"itpp-ldpc(18,9)-qpsk(channel=9)\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl(100-200-100\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_2,'', label=\"commpy-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_commpy_psk_4,'', label=\"commpy-psk4-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_uncoded_itpp_psk_2,'', label=\"itpp-psk2-uncoded\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,bler_per_iter_ham_itpp_psk_4,'', label=\"itpp-ham(7,4)(input=8,channel=7)\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BLER')\n",
        "ax1.set_title('Arch-2 ({},{},{})'.format(input_message_length,2*input_message_length, channel_size))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(2*channel_size,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnVP37k_BSJp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "channel_in_array = numpy.transpose(channel_in)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.scatter(channel_in_array[i*2], channel_in_array[i*2+1])\n",
        "  plt.show()\n",
        "  plt.hist2d(channel_in_array[i*2], channel_in_array[i*2+1], cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beBR7QoLBUr-"
      },
      "source": [
        "channel_out_array = numpy.transpose(channel_out)\n",
        "\n",
        "for i in range (int(channel_size)):\n",
        "  plt.hist2d(channel_out_array[2*i], channel_out_array[2*i+1], (50, 50), cmap=plt.cm.jet)\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}