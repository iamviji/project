{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder-Based-Communication-System.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOR4iOhahGBG0RWt7RH7z9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/PostMidTerm/misc/AutoEncoder_Based_Communication_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwBnxyMZKyOa"
      },
      "source": [
        "\r\n",
        "# importing libs\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout\r\n",
        "from keras.models import Model\r\n",
        "from keras import regularizers\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.optimizers import Adam,SGD\r\n",
        "from keras import backend as K\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-eJC59ZLGyL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lUuaCv9LHNK",
        "outputId": "4a950c90-9336-4c97-a9da-528881e3d7f9"
      },
      "source": [
        "# defining parameters\r\n",
        "# define (n,k) here for (n,k) autoencoder\r\n",
        "# n = n_channel \r\n",
        "# k = log2(M)  ==> so for (7,4) autoencoder n_channel = 7 and M = 2^4 = 16 \r\n",
        "M = 4\r\n",
        "k = np.log2(M)\r\n",
        "k = int(k)\r\n",
        "n_channel = 2\r\n",
        "R = k/n_channel\r\n",
        "print ('M:',M,'k:',k,'n:',n_channel)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M: 4 k: 2 n: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OFNKp6sGLOKG",
        "outputId": "1b680ebe-ce73-43cc-8901-644c9b15ceeb"
      },
      "source": [
        "\r\n",
        "#generating data of size N\r\n",
        "N = 8000\r\n",
        "label = np.random.randint(M,size=N)\r\n",
        "\r\n",
        "# creating one hot encoded vectors\r\n",
        "data = []\r\n",
        "for i in label:\r\n",
        "    temp = np.zeros(M)\r\n",
        "    temp[i] = 1\r\n",
        "    data.append(temp)\r\n",
        "\r\n",
        "# checking data shape\r\n",
        "data = np.array(data)\r\n",
        "print (data.shape)\r\n",
        "\r\n",
        "\r\n",
        "# checking generated data with it's label\r\n",
        "temp_check = [17,23,45,67,89,96,72,250,350]\r\n",
        "for i in temp_check:\r\n",
        "    print(label[i],data[i])\r\n",
        "\r\n",
        "# defining autoencoder and it's layer\r\n",
        "input_signal = Input(shape=(M,))\r\n",
        "encoded = Dense(M, activation='relu')(input_signal)\r\n",
        "encoded1 = Dense(n_channel, activation='linear')(encoded)\r\n",
        "encoded2 = Lambda(lambda x: np.sqrt(n_channel)*K.l2_normalize(x,axis=1))(encoded1)\r\n",
        "\r\n",
        "EbNo_train = 5.01187 #  coverted 7 db of EbNo\r\n",
        "encoded3 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded2)\r\n",
        "\r\n",
        "decoded = Dense(M, activation='relu')(encoded3)\r\n",
        "decoded1 = Dense(M, activation='softmax')(decoded)\r\n",
        "autoencoder = Model(input_signal, decoded1)\r\n",
        "adam = Adam(lr=0.01)\r\n",
        "autoencoder.compile(optimizer=adam, loss='categorical_crossentropy')\r\n",
        "\r\n",
        "# printing summary of layers and it's trainable parameters \r\n",
        "print (autoencoder.summary())\r\n",
        "\r\n",
        "# for tensor board visualization\r\n",
        "#tbCallBack = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\r\n",
        "\r\n",
        "# traning auto encoder\r\n",
        "autoencoder.fit(data, data,\r\n",
        "                epochs=45,\r\n",
        "                batch_size=32)\r\n",
        "\r\n",
        "# saving keras model\r\n",
        "from keras.models import load_model\r\n",
        "# if you want to save model then remove below comment\r\n",
        "# autoencoder.save('autoencoder_v_best.model')\r\n",
        "\r\n",
        "# making encoder from full autoencoder\r\n",
        "encoder = Model(input_signal, encoded2)\r\n",
        "\r\n",
        "# making decoder from full autoencoder\r\n",
        "encoded_input = Input(shape=(n_channel,))\r\n",
        "\r\n",
        "deco = autoencoder.layers[-2](encoded_input)\r\n",
        "deco = autoencoder.layers[-1](deco)\r\n",
        "decoder = Model(encoded_input, deco)\r\n",
        "\r\n",
        "\r\n",
        "# generating data for checking BER\r\n",
        "# if you're not using t-sne for visulation than set N to 70,000 for better result \r\n",
        "# for t-sne use less N like N = 1500\r\n",
        "N = 50000\r\n",
        "test_label = np.random.randint(M,size=N)\r\n",
        "test_data = []\r\n",
        "\r\n",
        "for i in test_label:\r\n",
        "    temp = np.zeros(M)\r\n",
        "    temp[i] = 1\r\n",
        "    test_data.append(temp)\r\n",
        "    \r\n",
        "test_data = np.array(test_data)\r\n",
        "\r\n",
        "\r\n",
        "# checking generated data\r\n",
        "temp_test = 6\r\n",
        "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])\r\n",
        "\r\n",
        "# for plotting learned consteallation diagram\r\n",
        "\r\n",
        "scatter_plot = []\r\n",
        "for i in range(0,M):\r\n",
        "    temp = np.zeros(M)\r\n",
        "    temp[i] = 1\r\n",
        "    scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\r\n",
        "scatter_plot = np.array(scatter_plot)\r\n",
        "print (scatter_plot.shape)\r\n",
        "\r\n",
        "\r\n",
        "# use this function for ploting constellation for higher dimenson like 7-D for (7,4) autoencoder \r\n",
        "'''\r\n",
        "x_emb = encoder.predict(test_data)\r\n",
        "noise_std = np.sqrt(1/(2*R*EbNo_train))\r\n",
        "noise = noise_std * np.random.randn(N,n_channel)\r\n",
        "x_emb = x_emb + noise\r\n",
        "from sklearn.manifold import TSNE\r\n",
        "X_embedded = TSNE(learning_rate=700, n_components=2,n_iter=35000, random_state=0, perplexity=60).fit_transform(x_emb)\r\n",
        "print (X_embedded.shape)\r\n",
        "X_embedded = X_embedded / 7\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.scatter(X_embedded[:,0],X_embedded[:,1])\r\n",
        "#plt.axis((-2.5,2.5,-2.5,2.5)) \r\n",
        "plt.grid()\r\n",
        "plt.show()\r\n",
        "'''\r\n",
        "\r\n",
        "# ploting constellation diagram\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "scatter_plot = scatter_plot.reshape(M,2,1)\r\n",
        "plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\r\n",
        "plt.axis((-2.5,2.5,-2.5,2.5))\r\n",
        "plt.grid()\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "def frange(x, y, jump):\r\n",
        "  while x < y:\r\n",
        "    yield x\r\n",
        "    x += jump\r\n",
        "\r\n",
        "\r\n",
        "# calculating BER\r\n",
        "# this is optimized BER function so it can handle large number of N\r\n",
        "# previous code has another for loop which was making it slow\r\n",
        "EbNodB_range = list(frange(-4,8.5,0.5))\r\n",
        "ber = [None]*len(EbNodB_range)\r\n",
        "for n in range(0,len(EbNodB_range)):\r\n",
        "    EbNo=10.0**(EbNodB_range[n]/10.0)\r\n",
        "    noise_std = np.sqrt(1/(2*R*EbNo))\r\n",
        "    noise_mean = 0\r\n",
        "    no_errors = 0\r\n",
        "    nn = N\r\n",
        "    noise = noise_std * np.random.randn(nn,n_channel)\r\n",
        "    encoded_signal = encoder.predict(test_data) \r\n",
        "    final_signal = encoded_signal + noise\r\n",
        "    pred_final_signal =  decoder.predict(final_signal)\r\n",
        "    pred_output = np.argmax(pred_final_signal,axis=1)\r\n",
        "    no_errors = (pred_output != test_label)\r\n",
        "    no_errors =  no_errors.astype(int).sum()\r\n",
        "    ber[n] = no_errors / nn \r\n",
        "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])\r\n",
        "    # use below line for generating matlab like matrix which can be copy and paste for plotting ber graph in matlab\r\n",
        "    #print(ber[n], \" \",end='')\r\n",
        "\r\n",
        "# ploting ber curve\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy import interpolate\r\n",
        "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder(2,2)')\r\n",
        "plt.yscale('log')\r\n",
        "plt.xlabel('SNR Range')\r\n",
        "plt.ylabel('Block Error Rate')\r\n",
        "plt.grid()\r\n",
        "plt.legend(loc='upper right',ncol = 1)\r\n",
        "\r\n",
        "# for saving figure remove below comment\r\n",
        "#plt.savefig('AutoEncoder_2_2_constrained_BER_matplotlib')\r\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 4)\n",
            "1 [0. 1. 0. 0.]\n",
            "0 [1. 0. 0. 0.]\n",
            "1 [0. 1. 0. 0.]\n",
            "3 [0. 0. 0. 1.]\n",
            "1 [0. 1. 0. 0.]\n",
            "3 [0. 0. 0. 1.]\n",
            "0 [1. 0. 0. 0.]\n",
            "3 [0. 0. 0. 1.]\n",
            "0 [1. 0. 0. 0.]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 4)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 20        \n",
            "=================================================================\n",
            "Total params: 62\n",
            "Trainable params: 62\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/45\n",
            "250/250 [==============================] - 1s 884us/step - loss: 0.7008\n",
            "Epoch 2/45\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.0311\n",
            "Epoch 3/45\n",
            "250/250 [==============================] - 0s 893us/step - loss: 0.0175\n",
            "Epoch 4/45\n",
            "250/250 [==============================] - 0s 961us/step - loss: 0.0139\n",
            "Epoch 5/45\n",
            "250/250 [==============================] - 0s 911us/step - loss: 0.0097\n",
            "Epoch 6/45\n",
            "250/250 [==============================] - 0s 888us/step - loss: 0.0080\n",
            "Epoch 7/45\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.0049\n",
            "Epoch 8/45\n",
            "250/250 [==============================] - 0s 991us/step - loss: 0.0133\n",
            "Epoch 9/45\n",
            "250/250 [==============================] - 0s 921us/step - loss: 0.0067\n",
            "Epoch 10/45\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.0071\n",
            "Epoch 11/45\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.0077\n",
            "Epoch 12/45\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.0079\n",
            "Epoch 13/45\n",
            "250/250 [==============================] - 0s 949us/step - loss: 0.0140\n",
            "Epoch 14/45\n",
            "250/250 [==============================] - 0s 926us/step - loss: 0.0096\n",
            "Epoch 15/45\n",
            "250/250 [==============================] - 0s 888us/step - loss: 0.0057\n",
            "Epoch 16/45\n",
            "250/250 [==============================] - 0s 988us/step - loss: 0.0045\n",
            "Epoch 17/45\n",
            "250/250 [==============================] - 0s 892us/step - loss: 0.0048\n",
            "Epoch 18/45\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.0071\n",
            "Epoch 19/45\n",
            "250/250 [==============================] - 0s 880us/step - loss: 0.0039\n",
            "Epoch 20/45\n",
            "250/250 [==============================] - 0s 932us/step - loss: 0.0060\n",
            "Epoch 21/45\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.0069\n",
            "Epoch 22/45\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.0108\n",
            "Epoch 23/45\n",
            "250/250 [==============================] - 0s 916us/step - loss: 0.0102\n",
            "Epoch 24/45\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.0047\n",
            "Epoch 25/45\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.0110\n",
            "Epoch 26/45\n",
            "250/250 [==============================] - 0s 895us/step - loss: 0.0058\n",
            "Epoch 27/45\n",
            "250/250 [==============================] - 0s 887us/step - loss: 0.0071\n",
            "Epoch 28/45\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.0136\n",
            "Epoch 29/45\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.0059\n",
            "Epoch 30/45\n",
            "250/250 [==============================] - 0s 894us/step - loss: 0.0111\n",
            "Epoch 31/45\n",
            "250/250 [==============================] - 0s 901us/step - loss: 0.0065\n",
            "Epoch 32/45\n",
            "250/250 [==============================] - 0s 936us/step - loss: 0.0045\n",
            "Epoch 33/45\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.0073\n",
            "Epoch 34/45\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.0054\n",
            "Epoch 35/45\n",
            "250/250 [==============================] - 0s 919us/step - loss: 0.0067\n",
            "Epoch 36/45\n",
            "250/250 [==============================] - 0s 934us/step - loss: 0.0101\n",
            "Epoch 37/45\n",
            "250/250 [==============================] - 0s 998us/step - loss: 0.0069\n",
            "Epoch 38/45\n",
            "250/250 [==============================] - 0s 974us/step - loss: 0.0057\n",
            "Epoch 39/45\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.0084\n",
            "Epoch 40/45\n",
            "250/250 [==============================] - 0s 959us/step - loss: 0.0069\n",
            "Epoch 41/45\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.0044\n",
            "Epoch 42/45\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.0082\n",
            "Epoch 43/45\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.0057\n",
            "Epoch 44/45\n",
            "250/250 [==============================] - 0s 909us/step - loss: 0.0107\n",
            "Epoch 45/45\n",
            "250/250 [==============================] - 0s 935us/step - loss: 0.0069\n",
            "1.0 3\n",
            "(4, 1, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: -4 BER: 0.33484\n",
            "SNR: -3.5 BER: 0.31682\n",
            "SNR: -3.0 BER: 0.29492\n",
            "SNR: -2.5 BER: 0.27182\n",
            "SNR: -2.0 BER: 0.24132\n",
            "SNR: -1.5 BER: 0.22056\n",
            "SNR: -1.0 BER: 0.19876\n",
            "SNR: -0.5 BER: 0.17708\n",
            "SNR: 0.0 BER: 0.15156\n",
            "SNR: 0.5 BER: 0.13016\n",
            "SNR: 1.0 BER: 0.1083\n",
            "SNR: 1.5 BER: 0.09044\n",
            "SNR: 2.0 BER: 0.07236\n",
            "SNR: 2.5 BER: 0.06004\n",
            "SNR: 3.0 BER: 0.04464\n",
            "SNR: 3.5 BER: 0.03446\n",
            "SNR: 4.0 BER: 0.0252\n",
            "SNR: 4.5 BER: 0.01844\n",
            "SNR: 5.0 BER: 0.01244\n",
            "SNR: 5.5 BER: 0.00822\n",
            "SNR: 6.0 BER: 0.00512\n",
            "SNR: 6.5 BER: 0.00318\n",
            "SNR: 7.0 BER: 0.00172\n",
            "SNR: 7.5 BER: 0.0009\n",
            "SNR: 8.0 BER: 0.0004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}