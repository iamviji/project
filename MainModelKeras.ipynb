{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MainModelKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/MainModelKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku11kjUKaO8X"
      },
      "source": [
        "Note:To Checkin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDSPPMfZ9czi",
        "outputId": "86a95789-716e-4bba-bb96-e559b8cf7d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "!rm -rf project\n",
        "!git clone https://github.com/iamviji/project.git\n",
        "!ls\n",
        "!ls project\n",
        "!pip install pyldpc\n",
        "!pip install scikit-commpy\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'project'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 53 (delta 11), reused 8 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n",
            "project  sample_data\n",
            "MainModel.ipynb  MainModelWithSingleBERTraining.ipynb  README.md  util.py\n",
            "Collecting pyldpc\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/aa/fd5495869c7106a638ae71aa497d7d266cae7f2a343d1f6a9d0e3a986e1e/pyldpc-0.7.9.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyldpc) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyldpc) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from pyldpc) (0.48.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->pyldpc) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->pyldpc) (50.3.0)\n",
            "Building wheels for collected packages: pyldpc\n",
            "  Building wheel for pyldpc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyldpc: filename=pyldpc-0.7.9-cp36-none-any.whl size=14306 sha256=1d3b99a833677302be0cd37edbdf24e348cc7e02b3ca22dfa8bfbab9ec8f2fb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/7a/10/e94058ba8b0b6d98bf2719226d18d3dd6056525ad7b984c068\n",
            "Successfully built pyldpc\n",
            "Installing collected packages: pyldpc\n",
            "Successfully installed pyldpc-0.7.9\n",
            "Collecting scikit-commpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/b4/f7fa5bc8864e0ddbd3e7a2290b624b92690f53523474024915c33321802d/scikit_commpy-0.5.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (1.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->scikit-commpy) (1.15.0)\n",
            "Installing collected packages: scikit-commpy\n",
            "Successfully installed scikit-commpy-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QOuLqpdDgx2"
      },
      "source": [
        "import pyldpc\n",
        "import commpy\n",
        "import numpy \n",
        "import time\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior ()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YClXJbbr0lc7"
      },
      "source": [
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "SNR_STEP_SIZE = 0.5\n",
        "CHANEL_SIZE = 18\n",
        "NUM_OF_INPUT_MESSAGE = 1000\n",
        "LDPC_MAX_ITER = 100\n",
        "num_parity_check = 3\n",
        "num_bits_in_parity_check = 6 \n",
        "input_message_length =  0 # Caculated by channel encoder and initialized later"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvUzIMsB43i0"
      },
      "source": [
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = 10 ** (- snr / 20)\n",
        "  return sigma\n",
        "\n",
        "def pyldpc_encode (CodingMatrix, message):\n",
        "  rng = pyldpc.utils.check_random_state(seed=None)\n",
        "  d = pyldpc.utils.binaryproduct(CodingMatrix, message)\n",
        "  encoded_message = (-1) ** d\n",
        "  return encoded_message\n",
        "\n",
        "def pyldpc_decode (ParityCheckMatrix, CodingMatrix, message, snr, maxiter):\n",
        "  decoded_msg = pyldpc.decode(ParityCheckMatrix, message, snr, maxiter)\n",
        "  out_message = pyldpc.get_message(CodingMatrix, decoded_msg)\n",
        "  return out_message\n",
        "\n",
        "awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "init = tf.global_variables_initializer ()\n",
        "sess = tf.Session ()\n",
        "sess.run(init)\n",
        "\n",
        "def AWGNChannelOutput (xx, snr , s):\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  awgn_channel_output_message = s.run ([awgn_channel_output], feed_dict={noise_std_dev:sigma, channel_input:xx})\n",
        "  return awgn_channel_output_message"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jMQG-MZ_pXu",
        "outputId": "fe295c91-8abc-42db-81eb-e64235aca75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "\n",
        "ParityCheckMatrix, CodingMatrix = pyldpc.make_ldpc(CHANEL_SIZE, num_parity_check, num_bits_in_parity_check, systematic=True, sparse=True)\n",
        "input_message_length = CodingMatrix.shape[1]\n",
        "print (\"input_message_size=\", input_message_length, \"channel_size=\",CHANEL_SIZE)\n",
        "print (\"input_message_size=\", CodingMatrix.shape[1], \"channel_size=\",CodingMatrix.shape[0])\n",
        "input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE,input_message_length))\n",
        "print (input_message)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_message_size= 11 channel_size= 18\n",
            "input_message_size= 11 channel_size= 18\n",
            "[[0 1 0 ... 1 0 1]\n",
            " [1 0 1 ... 0 1 1]\n",
            " [0 1 1 ... 0 1 0]\n",
            " ...\n",
            " [0 1 0 ... 1 0 1]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [0 1 1 ... 1 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WKg2HU2adgZ"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fL8ptL4aeOY"
      },
      "source": [
        "This section tries to compare BER and Time performance of PYLDPC in following 3 cases\n",
        "1. SNR Noise function provided in encoder function of pyldpc library (pyldpc.encode)\n",
        "2. SNR Noise function provided by commpy library (commpy.channels.awgn) \n",
        "3. SNR Noise function implemented using tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma5zUqFv0TH2",
        "outputId": "f4ca2699-7935-4ad4-f67d-d0ea31045865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using tensor flow based AWGN, to make sure that effect of it is same as AWGN\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_tensor  = numpy.array(())\n",
        "times_per_iter_tensor = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc_encode (CodingMatrix, input_message[i])\n",
        "    sigma = Snr2Sigma (snr)\n",
        "    awgn_channel_output_message = sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message})[0]\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      #print (\"count=\",abs(decoded_message-input_message[i]).sum())\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_tensor=numpy.append(ber_per_iter_tensor ,ber)\n",
        "  times_per_iter_tensor=numpy.append(times_per_iter_tensor, total_time)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.87s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.83s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 5.72s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 7.64s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.61\n",
            " -> Total Time: 19.06s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.65s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 3.14s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 4.68s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 6.15s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.53\n",
            " -> Total Time: 15.62s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.33s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 2.49s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 3.93s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 5.15s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.45\n",
            " -> Total Time: 12.90s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 1.22s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 2.26s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 3.34s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 4.43s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.39\n",
            " -> Total Time: 11.25s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.88s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.80s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 2.72s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 3.67s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.32\n",
            " -> Total Time: 9.07s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.69s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.42s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 2.09s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.76s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.23\n",
            " -> Total Time: 6.96s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.58s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.21s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.76s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 2.33s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.15\n",
            " -> Total Time: 5.88s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.61s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 1.17s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.62s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 2.18s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.13\n",
            " -> Total Time: 5.57s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.41s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.82s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 1.21s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.66s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.08\n",
            " -> Total Time: 4.11s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.36s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.72s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 1.14s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 1.51s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 3.73s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.41s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.76s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 1.18s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 1.55s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 3.89s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.33s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.65s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.98s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 1.39s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 3.35s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.34s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.65s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.97s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 1.31s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 3.26s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.32s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.67s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 1.00s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 1.32s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.31s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.32s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.63s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.93s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 1.24s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.13s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.32s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.65s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.97s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 1.28s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.22s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.32s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.62s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.94s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 1.25s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.13s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.31s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.61s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.92s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 1.27s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.10s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.30s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.62s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.92s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 1.24s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.08s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.31s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.61s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.92s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 1.22s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.06s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8dIFLg76c7O",
        "outputId": "fb8c75e4-e470-42ee-c15b-9bac36f36dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using commpy based AWGN \n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_awgn  = numpy.array(())\n",
        "times_per_iter_awgn = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc_encode (CodingMatrix, input_message[i])\n",
        "    awgn_channel_output_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_awgn=numpy.append(ber_per_iter_awgn ,ber)\n",
        "  times_per_iter_awgn=numpy.append(times_per_iter_awgn, total_time)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.76s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.52s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 5.26s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 6.89s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.62\n",
            " -> Total Time: 17.42s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.47s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.86s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 4.40s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 5.81s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.54\n",
            " -> Total Time: 14.54s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.16s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 2.31s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 3.43s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 4.79s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.44\n",
            " -> Total Time: 11.69s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.85s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.82s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.64s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 3.53s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.34\n",
            " -> Total Time: 8.84s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.69s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.52s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 2.26s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.97s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.32\n",
            " -> Total Time: 7.44s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.69s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.24s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.86s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.46s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.23\n",
            " -> Total Time: 6.25s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.51s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.03s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.56s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 1.90s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.18\n",
            " -> Total Time: 5.00s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.42s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.71s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.13s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.53s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.12\n",
            " -> Total Time: 3.79s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.30s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.62s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 0.95s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.27s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.08\n",
            " -> Total Time: 3.14s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.24s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.50s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 0.81s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 1.08s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 2.62s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.27s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.51s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 0.73s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 0.99s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 2.50s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.22s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.47s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.73s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 0.96s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 2.38s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.21s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.44s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.67s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 0.86s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 2.18s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.38s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 0.58s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 0.77s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.94s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.38s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.57s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 0.75s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.91s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.39s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.58s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 0.77s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.94s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.22s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.42s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.60s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 0.80s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.04s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.37s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.56s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 0.76s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.89s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.38s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.57s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 0.75s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.89s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.38s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.57s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 0.76s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.92s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ihPKJJk7Jj9",
        "outputId": "5e240ae5-fb76-43be-b54d-716a65b13f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using tensor flow based AWGN, to make sure that effect of it is same as AWGN\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_pyldpc  = numpy.array(())\n",
        "times_per_iter_pyldpc = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc.encode (CodingMatrix, input_message[i], snr)\n",
        "    awgn_channel_output_message = encoded_message\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_pyldpc=numpy.append(ber_per_iter_pyldpc ,ber)\n",
        "  times_per_iter_pyldpc=numpy.append(times_per_iter_pyldpc, total_time)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.83s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.64s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 5.48s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 7.31s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.64\n",
            " -> Total Time: 18.26s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.37s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.90s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 4.51s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 5.92s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.55\n",
            " -> Total Time: 14.70s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.14s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 2.14s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 3.37s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 4.64s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.46\n",
            " -> Total Time: 11.29s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.95s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.72s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.76s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 3.54s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.35\n",
            " -> Total Time: 8.96s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.63s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.33s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 2.06s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.77s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.31\n",
            " -> Total Time: 6.79s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.69s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.38s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.91s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.50s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.22\n",
            " -> Total Time: 6.47s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.54s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 0.98s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.35s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 1.73s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.16\n",
            " -> Total Time: 4.60s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.30s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.71s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.11s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.59s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.14\n",
            " -> Total Time: 3.71s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.28s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.59s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 0.86s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.16s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.07\n",
            " -> Total Time: 2.88s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.31s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.55s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 0.84s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 1.08s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 2.78s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.23s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.46s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 0.69s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 0.92s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 2.30s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.43s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.69s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 0.96s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 2.27s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.22s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.42s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.62s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 0.84s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 2.10s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.21s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.40s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 0.61s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 0.86s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 2.07s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.43s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.63s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 0.81s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.06s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.38s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.57s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 0.76s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.89s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.37s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.56s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 0.74s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.86s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.39s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.57s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 0.80s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.96s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.39s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.56s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 0.75s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.89s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.37s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.55s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 0.74s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.84s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR4-FOJ-BkAG",
        "outputId": "7ce861d8-d49e-4fd8-e72f-53e01e7a56c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# Compare 3 AWGN(Tensorflow, CommPy, PYLDPC) Simulation on LDPC\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_pyldpc,'', label=\"pyldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"tensor\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_awgn,'', label=\"commpy-awgn\") # plot BER vs SNR\n",
        "\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "ax2.set_xlabel('$E_b/$N_0$')\n",
        "ax2.set_ylabel('Decoding Time [s]')\n",
        "ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "            xy=(1, 0.35), xycoords='axes fraction',\n",
        "            xytext=(-20, 20), textcoords='offset pixels',\n",
        "            horizontalalignment='right',\n",
        "            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBl0pWc1oF_r",
        "outputId": "61272fdf-a404-4b4f-8dff-3379ae612a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "training_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 ... 1 1 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " [1 1 1 ... 1 1 0]\n",
            " ...\n",
            " [0 1 0 ... 1 1 0]\n",
            " [0 0 1 ... 1 0 1]\n",
            " [0 1 0 ... 0 1 1]]\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggY5VwudaRwR"
      },
      "source": [
        "<B>Conclussion:</B>\n",
        "      It proved that tensorflow behaves similar to AWGN noise channel provided by pyldpc, commpy. But tensor flow based one takes adds little more time delay. This need to be offseted if we are comparing performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOeuNfeLCgfb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior ()\n",
        "\n",
        "input_message_x = Input(shape=(input_message_length,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "enc_layer1 = Dense(CHANEL_SIZE, activation='tanh')(input_message_x)\n",
        "enc_layer2 = Dense(CHANEL_SIZE, activation='sigmoid')(enc_layer1)\n",
        "#encoded2 = Dense(CHANEL_SIZE, activation='sigmoid')(encoded1)\n",
        "# this model maps an input to its encoded representation\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "#enc_layer2 = tf.round(enc_layer1)\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(7.0),input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(CHANEL_SIZE,))\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "dec_layer1 = Dense(CHANEL_SIZE, activation='tanh')(encoded_input)\n",
        "dec_layer2 = Dense(input_message_length, activation='sigmoid')(dec_layer1)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgXpqxjrnJ-F",
        "outputId": "72823659-dde6-4940-9bc7-bfe8eb29d174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 11)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 18)           216         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 18)           342         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square (TensorFlowO multiple             0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean (TensorFlowOpL multiple             0           tf_op_layer_Square[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt (TensorFlowOpL multiple             0           tf_op_layer_Mean[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv (TensorFlow multiple             0           dense_1[0][0]                    \n",
            "                                                                 tf_op_layer_Sqrt[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 558\n",
            "Trainable params: 558\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 18)]              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 18)                342       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 11)                209       \n",
            "=================================================================\n",
            "Total params: 551\n",
            "Trainable params: 551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 11)]              0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 18)                558       \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "functional_3 (Functional)    (None, 11)                551       \n",
            "=================================================================\n",
            "Total params: 1,109\n",
            "Trainable params: 1,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOXLOYLu8aML",
        "outputId": "b89aebe5-6e5f-4142-d03d-d247b0a6cbeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "\n",
        "#def custom_losff_fucntion (act, pred):\n",
        "#  return (tf.reduce_mean(-1*(act * tf.log(pred) + (1-act)*tf.log(1-pred))))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "#autoencoder.compile(optimizer=opt, loss=custom_losff_fucntion)\n",
        "#loss='mean_squared_error'\n",
        "#for snr in (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)):\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  autoencoder.fit(training_input_message, training_input_message,\n",
        "                #epochs=50, original\n",
        "                epochs=10,\n",
        "                batch_size=500,\n",
        "                shuffle=False,\n",
        "                validation_data=(input_message, input_message))\n",
        "  \n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for SNR= 0.0  sigma= 1.0\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.7878 - val_loss: 0.0017\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.7647 - val_loss: 0.0020\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.7361 - val_loss: 0.0025\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.7221 - val_loss: 0.0031\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.7005 - val_loss: 0.0040\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.6806 - val_loss: 0.0053\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.6457 - val_loss: 0.0070\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.6333 - val_loss: 0.0095\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.6110 - val_loss: 0.0134\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.5863 - val_loss: 0.0190\n",
            "Training for SNR= 0.5  sigma= 0.9440608762859234\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.5030 - val_loss: 0.0250\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.4889 - val_loss: 0.0329\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.4788 - val_loss: 0.0420\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.4645 - val_loss: 0.0505\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.4505 - val_loss: 0.0599\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.4412 - val_loss: 0.0672\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.4364 - val_loss: 0.0747\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.4304 - val_loss: 0.0785\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.4249 - val_loss: 0.0831\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.4198 - val_loss: 0.0877\n",
            "Training for SNR= 1.0  sigma= 0.8912509381337456\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 13us/sample - loss: 0.3853 - val_loss: 0.0839\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3802 - val_loss: 0.0837\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.3802 - val_loss: 0.0839\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.3790 - val_loss: 0.0857\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3737 - val_loss: 0.0866\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3746 - val_loss: 0.0884\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3707 - val_loss: 0.0906\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.3687 - val_loss: 0.0913\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.3641 - val_loss: 0.0924\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.3658 - val_loss: 0.0949\n",
            "Training for SNR= 1.5  sigma= 0.8413951416451951\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 15us/sample - loss: 0.3370 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3383 - val_loss: 0.0850\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.3332 - val_loss: 0.0832\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.3309 - val_loss: 0.0821\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3329 - val_loss: 0.0822\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.3320 - val_loss: 0.0819\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3310 - val_loss: 0.0821\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3372 - val_loss: 0.0834\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3320 - val_loss: 0.0842\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3320 - val_loss: 0.0843\n",
            "Training for SNR= 2.0  sigma= 0.7943282347242815\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 15us/sample - loss: 0.3049 - val_loss: 0.0772\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3057 - val_loss: 0.0739\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3054 - val_loss: 0.0719\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3011 - val_loss: 0.0709\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3032 - val_loss: 0.0698\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2997 - val_loss: 0.0693\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3050 - val_loss: 0.0688\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3039 - val_loss: 0.0691\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3037 - val_loss: 0.0697\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.3019 - val_loss: 0.0691\n",
            "Training for SNR= 2.5  sigma= 0.7498942093324559\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 17us/sample - loss: 0.2739 - val_loss: 0.0629\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2732 - val_loss: 0.0595\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2745 - val_loss: 0.0577\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2722 - val_loss: 0.0558\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2751 - val_loss: 0.0547\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2741 - val_loss: 0.0542\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2717 - val_loss: 0.0534\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2742 - val_loss: 0.0531\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2734 - val_loss: 0.0530\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 5us/sample - loss: 0.2762 - val_loss: 0.0530\n",
            "Training for SNR= 3.0  sigma= 0.7079457843841379\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 20us/sample - loss: 0.2467 - val_loss: 0.0487\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2479 - val_loss: 0.0462\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2476 - val_loss: 0.0446\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2449 - val_loss: 0.0431\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2473 - val_loss: 0.0421\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2452 - val_loss: 0.0413\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2463 - val_loss: 0.0406\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2461 - val_loss: 0.0404\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2466 - val_loss: 0.0400\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2473 - val_loss: 0.0398\n",
            "Training for SNR= 3.5  sigma= 0.6683439175686147\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 20us/sample - loss: 0.2218 - val_loss: 0.0372\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2190 - val_loss: 0.0348\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2207 - val_loss: 0.0334\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2214 - val_loss: 0.0324\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2169 - val_loss: 0.0312\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2200 - val_loss: 0.0305\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2156 - val_loss: 0.0298\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2163 - val_loss: 0.0292\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.2164 - val_loss: 0.0287\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2181 - val_loss: 0.0282\n",
            "Training for SNR= 4.0  sigma= 0.6309573444801932\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 22us/sample - loss: 0.1925 - val_loss: 0.0265\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1922 - val_loss: 0.0250\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1923 - val_loss: 0.0238\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1928 - val_loss: 0.0226\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1904 - val_loss: 0.0219\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1917 - val_loss: 0.0213\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1891 - val_loss: 0.0207\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1895 - val_loss: 0.0203\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1910 - val_loss: 0.0199\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1900 - val_loss: 0.0197\n",
            "Training for SNR= 4.5  sigma= 0.5956621435290105\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 24us/sample - loss: 0.1666 - val_loss: 0.0185\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1686 - val_loss: 0.0175\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1672 - val_loss: 0.0167\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1643 - val_loss: 0.0160\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1637 - val_loss: 0.0154\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1653 - val_loss: 0.0149\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1648 - val_loss: 0.0145\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1637 - val_loss: 0.0141\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1627 - val_loss: 0.0138\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1616 - val_loss: 0.0135\n",
            "Training for SNR= 5.0  sigma= 0.5623413251903491\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 26us/sample - loss: 0.1437 - val_loss: 0.0127\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1421 - val_loss: 0.0121\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1425 - val_loss: 0.0114\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1406 - val_loss: 0.0110\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1400 - val_loss: 0.0106\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1427 - val_loss: 0.0102\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1389 - val_loss: 0.0100\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1406 - val_loss: 0.0096\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1407 - val_loss: 0.0094\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1389 - val_loss: 0.0092\n",
            "Training for SNR= 5.5  sigma= 0.5308844442309884\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 28us/sample - loss: 0.1201 - val_loss: 0.0086\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1188 - val_loss: 0.0081\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1188 - val_loss: 0.0078\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1185 - val_loss: 0.0074\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1199 - val_loss: 0.0071\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1175 - val_loss: 0.0069\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1190 - val_loss: 0.0067\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1170 - val_loss: 0.0065\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1161 - val_loss: 0.0063\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.1182 - val_loss: 0.0061\n",
            "Training for SNR= 6.0  sigma= 0.5011872336272722\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0975 - val_loss: 0.0058\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0971 - val_loss: 0.0055\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0961 - val_loss: 0.0053\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0983 - val_loss: 0.0050\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0973 - val_loss: 0.0048\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0980 - val_loss: 0.0046\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0959 - val_loss: 0.0045\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0971 - val_loss: 0.0043\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0955 - val_loss: 0.0042\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0962 - val_loss: 0.0041\n",
            "Training for SNR= 6.5  sigma= 0.47315125896148047\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 29us/sample - loss: 0.0785 - val_loss: 0.0038\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0794 - val_loss: 0.0036\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0786 - val_loss: 0.0035\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0781 - val_loss: 0.0033\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0783 - val_loss: 0.0032\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0779 - val_loss: 0.0031\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0795 - val_loss: 0.0030\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0786 - val_loss: 0.0029\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0776 - val_loss: 0.0028\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0780 - val_loss: 0.0027\n",
            "Training for SNR= 7.0  sigma= 0.44668359215096315\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 35us/sample - loss: 0.0622 - val_loss: 0.0026\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0629 - val_loss: 0.0025\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0625 - val_loss: 0.0024\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0624 - val_loss: 0.0022\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0608 - val_loss: 0.0022\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0632 - val_loss: 0.0021\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0622 - val_loss: 0.0020\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0624 - val_loss: 0.0020\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0623 - val_loss: 0.0019\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0622 - val_loss: 0.0018\n",
            "Training for SNR= 7.5  sigma= 0.4216965034285822\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0487 - val_loss: 0.0018\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0483 - val_loss: 0.0017\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0483 - val_loss: 0.0016\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0482 - val_loss: 0.0015\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0474 - val_loss: 0.0015\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0489 - val_loss: 0.0014\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0477 - val_loss: 0.0014\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0480 - val_loss: 0.0014\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0485 - val_loss: 0.0013\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0475 - val_loss: 0.0013\n",
            "Training for SNR= 8.0  sigma= 0.3981071705534972\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 36us/sample - loss: 0.0372 - val_loss: 0.0012\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0362 - val_loss: 0.0012\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0365 - val_loss: 0.0011\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0361 - val_loss: 0.0011\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0372 - val_loss: 0.0010\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0368 - val_loss: 0.0010\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0362 - val_loss: 9.7461e-04\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0364 - val_loss: 9.4118e-04\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0360 - val_loss: 9.0784e-04\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0356 - val_loss: 8.8673e-04\n",
            "Training for SNR= 8.5  sigma= 0.3758374042884442\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 37us/sample - loss: 0.0270 - val_loss: 8.5358e-04\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0275 - val_loss: 8.2342e-04\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0279 - val_loss: 7.8443e-04\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0267 - val_loss: 7.6262e-04\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0258 - val_loss: 7.3845e-04\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0265 - val_loss: 7.1466e-04\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0262 - val_loss: 6.8889e-04\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0260 - val_loss: 6.7121e-04\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0267 - val_loss: 6.5381e-04\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0259 - val_loss: 6.2647e-04\n",
            "Training for SNR= 9.0  sigma= 0.35481338923357547\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 40us/sample - loss: 0.0190 - val_loss: 6.0426e-04\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0191 - val_loss: 5.8012e-04\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0191 - val_loss: 5.6156e-04\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0199 - val_loss: 5.4351e-04\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0198 - val_loss: 5.2987e-04\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0193 - val_loss: 5.1500e-04\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0189 - val_loss: 5.0094e-04\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0189 - val_loss: 4.9288e-04\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0188 - val_loss: 4.7634e-04\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0192 - val_loss: 4.6418e-04\n",
            "Training for SNR= 9.5  sigma= 0.33496543915782767\n",
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 0s 42us/sample - loss: 0.0138 - val_loss: 4.4804e-04\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0139 - val_loss: 4.3603e-04\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0144 - val_loss: 4.2194e-04\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0134 - val_loss: 4.0370e-04\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0141 - val_loss: 3.9197e-04\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 0s 6us/sample - loss: 0.0141 - val_loss: 3.8190e-04\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0137 - val_loss: 3.7226e-04\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0134 - val_loss: 3.6679e-04\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0136 - val_loss: 3.5668e-04\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0133 - val_loss: 3.4257e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHByzQbTUqbv",
        "outputId": "2b4e95c5-1edf-42cd-e6ba-bde53a299953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)\n",
        "    #awgn_channel_output_message = sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:0.5, awgn_channel_input:encoded_message[0]})\n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 0.60s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 1.20s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 1.79s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 2.40s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.76\n",
            " -> Total Time: 5.99s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 1.26s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 1.86s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 2.45s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.75\n",
            " -> Total Time: 6.22s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 0.60s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 1.21s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 1.83s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 2.43s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.72\n",
            " -> Total Time: 6.07s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.60s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.20s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 1.81s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 2.41s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.73\n",
            " -> Total Time: 6.02s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.60s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.20s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.80s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.42s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.67\n",
            " -> Total Time: 6.02s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.59s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.19s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.79s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.40s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.70\n",
            " -> Total Time: 5.97s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.61s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.21s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.83s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 2.48s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.65\n",
            " -> Total Time: 6.13s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.60s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 1.21s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.79s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 2.41s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.63\n",
            " -> Total Time: 6.00s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.60s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 1.18s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 1.78s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 2.36s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.60\n",
            " -> Total Time: 5.91s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.61s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 1.24s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 1.84s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 2.45s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.61\n",
            " -> Total Time: 6.14s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.61s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 1.22s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 1.82s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 2.44s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.60\n",
            " -> Total Time: 6.09s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.62s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 1.22s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 1.82s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 2.42s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.56\n",
            " -> Total Time: 6.07s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.58s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 1.19s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 1.80s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 2.41s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.55\n",
            " -> Total Time: 5.98s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.60s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 1.19s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 1.80s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 2.43s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.51\n",
            " -> Total Time: 6.03s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.59s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 1.20s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 1.81s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 2.43s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.50\n",
            " -> Total Time: 6.03s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.61s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 1.21s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 1.84s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 2.46s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.47\n",
            " -> Total Time: 6.11s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.62s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 1.23s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 1.83s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 2.43s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.44\n",
            " -> Total Time: 6.11s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.59s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 1.23s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 1.83s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 2.43s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.42\n",
            " -> Total Time: 6.07s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.61s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 1.20s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 1.80s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 2.40s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.40\n",
            " -> Total Time: 6.01s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.59s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 1.20s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 1.80s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 2.42s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.36\n",
            " -> Total Time: 6.01s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUQij3fuxRm",
        "outputId": "7aecf189-c5d3-473f-d7aa-32befadb56d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"ldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}