{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MainModelKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/MainModelKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku11kjUKaO8X"
      },
      "source": [
        "Note:To Checkin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDSPPMfZ9czi",
        "outputId": "cfeb8726-d11f-4162-a4e0-f1da441977fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "!rm -rf project\n",
        "!git clone https://github.com/iamviji/project.git\n",
        "!ls\n",
        "!ls project\n",
        "!pip install pyldpc\n",
        "!pip install scikit-commpy\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'project'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 110 (delta 41), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 1.61 MiB | 539.00 KiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "project  sample_data\n",
            "MainModel.ipynb\t\t     MainModelOneHotMethodSoftMax.ipynb    util.py\n",
            "MainModelKeras.ipynb\t     MainModelWithSingleBERTraining.ipynb\n",
            "MainModelOneHotMethod.ipynb  README.md\n",
            "Collecting pyldpc\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/aa/fd5495869c7106a638ae71aa497d7d266cae7f2a343d1f6a9d0e3a986e1e/pyldpc-0.7.9.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyldpc) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyldpc) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from pyldpc) (0.48.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->pyldpc) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->pyldpc) (50.3.0)\n",
            "Building wheels for collected packages: pyldpc\n",
            "  Building wheel for pyldpc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyldpc: filename=pyldpc-0.7.9-cp36-none-any.whl size=14306 sha256=c1f0d4932c0217d97132284ef9941b84802bd5073b09f4ee24617ca9717a198c\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/7a/10/e94058ba8b0b6d98bf2719226d18d3dd6056525ad7b984c068\n",
            "Successfully built pyldpc\n",
            "Installing collected packages: pyldpc\n",
            "Successfully installed pyldpc-0.7.9\n",
            "Collecting scikit-commpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/b4/f7fa5bc8864e0ddbd3e7a2290b624b92690f53523474024915c33321802d/scikit_commpy-0.5.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->scikit-commpy) (1.15.0)\n",
            "Installing collected packages: scikit-commpy\n",
            "Successfully installed scikit-commpy-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QOuLqpdDgx2",
        "outputId": "0b105c5c-6151-4213-c4f1-45c77c543e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pyldpc\n",
        "import commpy\n",
        "import numpy \n",
        "import time\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior ()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YClXJbbr0lc7"
      },
      "source": [
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "SNR_STEP_SIZE = 0.5\n",
        "CHANEL_SIZE = 18\n",
        "NUM_OF_INPUT_MESSAGE = 1000\n",
        "LDPC_MAX_ITER = 100\n",
        "num_parity_check = 3\n",
        "num_bits_in_parity_check = 6 \n",
        "input_message_length =  0 # Caculated by channel encoder and initialized later"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvUzIMsB43i0"
      },
      "source": [
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = 10 ** (- snr / 20)\n",
        "  return sigma\n",
        "\n",
        "def pyldpc_encode (CodingMatrix, message):\n",
        "  rng = pyldpc.utils.check_random_state(seed=None)\n",
        "  d = pyldpc.utils.binaryproduct(CodingMatrix, message)\n",
        "  encoded_message = (-1) ** d\n",
        "  return encoded_message\n",
        "\n",
        "def pyldpc_decode (ParityCheckMatrix, CodingMatrix, message, snr, maxiter):\n",
        "  decoded_msg = pyldpc.decode(ParityCheckMatrix, message, snr, maxiter)\n",
        "  out_message = pyldpc.get_message(CodingMatrix, decoded_msg)\n",
        "  return out_message\n",
        "\n",
        "awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "init = tf.global_variables_initializer ()\n",
        "sess = tf.Session ()\n",
        "sess.run(init)\n",
        "\n",
        "def AWGNChannelOutput (xx, snr , s):\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  awgn_channel_output_message = s.run ([awgn_channel_output], feed_dict={noise_std_dev:sigma, channel_input:xx})\n",
        "  return awgn_channel_output_message"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jMQG-MZ_pXu",
        "outputId": "d530f589-7727-4c2e-b3f2-8d65f6128bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "ParityCheckMatrix, CodingMatrix = pyldpc.make_ldpc(CHANEL_SIZE, num_parity_check, num_bits_in_parity_check, systematic=True, sparse=True)\n",
        "input_message_length = CodingMatrix.shape[1]\n",
        "print (\"input_message_size=\", input_message_length, \"channel_size=\",CHANEL_SIZE)\n",
        "print (\"input_message_size=\", CodingMatrix.shape[1], \"channel_size=\",CodingMatrix.shape[0])\n",
        "input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE,input_message_length))\n",
        "print (input_message)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_message_size= 11 channel_size= 18\n",
            "input_message_size= 11 channel_size= 18\n",
            "[[1 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 1 0 1]\n",
            " [1 1 0 ... 0 0 1]\n",
            " ...\n",
            " [1 1 1 ... 1 1 1]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WKg2HU2adgZ"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fL8ptL4aeOY"
      },
      "source": [
        "This section tries to compare BER and Time performance of PYLDPC in following 3 cases\n",
        "1. SNR Noise function provided in encoder function of pyldpc library (pyldpc.encode)\n",
        "2. SNR Noise function provided by commpy library (commpy.channels.awgn) \n",
        "3. SNR Noise function implemented using tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma5zUqFv0TH2",
        "outputId": "b7a9da54-93e5-4128-81d8-8588fb86b3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using tensor flow based AWGN, to make sure that effect of it is same as AWGN\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_tensor  = numpy.array(())\n",
        "times_per_iter_tensor = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc_encode (CodingMatrix, input_message[i])\n",
        "    sigma = Snr2Sigma (snr)\n",
        "    awgn_channel_output_message = sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message})[0]\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      #print (\"count=\",abs(decoded_message-input_message[i]).sum())\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_tensor=numpy.append(ber_per_iter_tensor ,ber)\n",
        "  times_per_iter_tensor=numpy.append(times_per_iter_tensor, total_time)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.93s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.68s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 5.60s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 7.53s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.59\n",
            " -> Total Time: 18.74s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.55s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.82s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 4.42s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 5.92s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.52\n",
            " -> Total Time: 14.71s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.42s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 2.76s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 3.98s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 5.25s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.47\n",
            " -> Total Time: 13.41s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 1.11s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 2.12s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 3.11s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 4.09s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.36\n",
            " -> Total Time: 10.44s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.87s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.83s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 2.66s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 3.34s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.25\n",
            " -> Total Time: 8.70s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.59s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.34s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.99s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.69s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.21\n",
            " -> Total Time: 6.61s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.47s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.03s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.59s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 2.17s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.17\n",
            " -> Total Time: 5.25s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.51s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.96s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.43s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.96s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.12\n",
            " -> Total Time: 4.85s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.43s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.92s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 1.41s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.91s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.07\n",
            " -> Total Time: 4.67s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.42s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.86s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 1.34s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 1.82s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 4.44s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.38s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.75s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 1.13s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 1.49s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 3.75s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.35s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.78s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 1.18s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 1.53s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 3.83s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.39s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.73s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 1.09s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 1.46s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 3.66s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.35s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.69s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 1.06s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 1.39s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 3.49s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.35s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.65s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.94s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 1.23s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.16s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.30s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.60s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.90s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 1.21s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.01s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.31s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.60s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.90s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 1.20s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.01s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.29s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.58s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.88s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 1.18s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.93s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.29s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.59s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.88s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 1.17s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.93s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.30s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.62s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.91s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 1.20s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 3.03s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8dIFLg76c7O",
        "outputId": "fa6f9bf1-cd51-486e-c647-3359d0052bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using commpy based AWGN \n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_awgn  = numpy.array(())\n",
        "times_per_iter_awgn = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc_encode (CodingMatrix, input_message[i])\n",
        "    awgn_channel_output_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_awgn=numpy.append(ber_per_iter_awgn ,ber)\n",
        "  times_per_iter_awgn=numpy.append(times_per_iter_awgn, total_time)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.74s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.40s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 4.98s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 6.70s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.63\n",
            " -> Total Time: 16.81s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.41s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.55s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 3.96s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 5.44s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.53\n",
            " -> Total Time: 13.37s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.14s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 2.41s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 3.45s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 4.66s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.45\n",
            " -> Total Time: 11.66s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.93s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.76s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.72s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 3.63s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.37\n",
            " -> Total Time: 9.04s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.78s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.35s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.94s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.73s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.28\n",
            " -> Total Time: 6.81s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.53s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.03s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.70s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.25s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.21\n",
            " -> Total Time: 5.51s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.42s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 0.80s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.31s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 1.81s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.17\n",
            " -> Total Time: 4.34s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.41s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.77s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.11s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.51s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.11\n",
            " -> Total Time: 3.80s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.27s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.49s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 0.80s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.04s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.07\n",
            " -> Total Time: 2.60s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.23s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.50s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 0.72s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 0.94s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 2.40s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.21s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.44s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 0.67s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 0.88s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 2.20s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.40s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.59s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 0.77s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 1.96s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.17s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.37s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.56s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 0.75s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.85s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.37s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 0.55s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 0.74s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.85s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.39s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.58s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 0.76s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.93s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.38s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.59s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 0.76s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.92s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.36s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.55s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 0.72s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.80s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.36s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.54s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 0.72s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.80s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.36s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.55s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 0.73s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.84s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.39s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.57s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 0.75s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.91s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ihPKJJk7Jj9",
        "outputId": "5e25ed50-fdb9-4f16-8965-4119e8fbf6bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using tensor flow based AWGN, to make sure that effect of it is same as AWGN\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_pyldpc  = numpy.array(())\n",
        "times_per_iter_pyldpc = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc.encode (CodingMatrix, input_message[i], snr)\n",
        "    awgn_channel_output_message = encoded_message\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_pyldpc=numpy.append(ber_per_iter_pyldpc ,ber)\n",
        "  times_per_iter_pyldpc=numpy.append(times_per_iter_pyldpc, total_time)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.63s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.29s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 5.07s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 6.64s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.57\n",
            " -> Total Time: 16.63s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.26s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.40s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 3.76s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 5.02s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.50\n",
            " -> Total Time: 12.44s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.19s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 2.24s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 3.44s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 4.47s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.45\n",
            " -> Total Time: 11.34s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.79s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.65s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.50s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 3.46s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.34\n",
            " -> Total Time: 8.40s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.63s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.22s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.85s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.59s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.27\n",
            " -> Total Time: 6.29s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.49s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 0.99s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.43s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.02s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.21\n",
            " -> Total Time: 4.94s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.40s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 0.78s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.16s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 1.58s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.15\n",
            " -> Total Time: 3.91s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.40s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.67s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 0.95s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.33s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.11\n",
            " -> Total Time: 3.35s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.27s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.55s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 0.82s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.07s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.07\n",
            " -> Total Time: 2.71s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.24s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.45s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 0.72s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 0.94s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 2.35s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.39s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 0.61s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 0.80s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 1.99s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.42s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.62s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 0.82s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 2.07s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.38s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.58s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 0.76s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.89s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.36s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 0.54s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 0.72s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.80s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.17s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.34s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.52s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 0.71s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.75s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.17s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.34s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.51s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 0.68s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.69s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.36s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.52s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 0.69s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.76s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.34s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.51s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 0.70s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.71s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.17s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.34s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.53s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 0.71s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.75s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.17s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.36s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.54s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 0.72s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.78s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR4-FOJ-BkAG",
        "outputId": "0ed25f0c-ca54-46c8-9612-d01ba3cb1689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# Compare 3 AWGN(Tensorflow, CommPy, PYLDPC) Simulation on LDPC\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_pyldpc,'', label=\"pyldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"tensor\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_awgn,'', label=\"commpy-awgn\") # plot BER vs SNR\n",
        "\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "ax2.set_xlabel('$E_b/$N_0$')\n",
        "ax2.set_ylabel('Decoding Time [s]')\n",
        "ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "            xy=(1, 0.35), xycoords='axes fraction',\n",
        "            xytext=(-20, 20), textcoords='offset pixels',\n",
        "            horizontalalignment='right',\n",
        "            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggY5VwudaRwR"
      },
      "source": [
        "<B>Conclussion:</B>\n",
        "      It proved that tensorflow behaves similar to AWGN noise channel provided by pyldpc, commpy. But tensor flow based one takes adds little more time delay. This need to be offseted if we are comparing performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOeuNfeLCgfb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior ()\n",
        "decoder_input_x = tf.placeholder(\"float32\", [None, input_message_length], name=\"decoder_input_x\")\n",
        "\n",
        "snr_std = 7.0\n",
        "\n",
        "input_message_x = Input(shape=(input_message_length,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "enc_layer1 = Dense(CHANEL_SIZE, activation='tanh')(input_message_x)\n",
        "#enc_layer2 = Dense(CHANEL_SIZE, activation='sigmoid')(enc_layer1)\n",
        "enc_layer2=enc_layer1\n",
        "#encoded2 = Dense(CHANEL_SIZE, activation='sigmoid')(encoded1)\n",
        "# this model maps an input to its encoded representation\n",
        "#enc_layer2 = BatchNormalization() (enc_layer2)\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "#enc_layer2 = tf.round(enc_layer1)\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(CHANEL_SIZE,))\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "dec_layer1 = Dense(CHANEL_SIZE, activation='tanh')(encoded_input)\n",
        "dec_layer2 = Dense(input_message_length, activation='sigmoid')(dec_layer1)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "\n",
        "decoder_output = (tf.nn.sigmoid(decoder_input_x))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgXpqxjrnJ-F",
        "outputId": "c88ff844-4bdd-4218-e8b8-fce243b25050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 11)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 18)           216         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square (TensorFlowO multiple             0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean (TensorFlowOpL multiple             0           tf_op_layer_Square[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt (TensorFlowOpL multiple             0           tf_op_layer_Mean[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv (TensorFlow multiple             0           dense[0][0]                      \n",
            "                                                                 tf_op_layer_Sqrt[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 216\n",
            "Trainable params: 216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 18)]              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 18)                342       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11)                209       \n",
            "=================================================================\n",
            "Total params: 551\n",
            "Trainable params: 551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 11)]              0         \n",
            "_________________________________________________________________\n",
            "functional_1 (Functional)    (None, 18)                216       \n",
            "_________________________________________________________________\n",
            "gaussian_noise (GaussianNois (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "functional_3 (Functional)    (None, 11)                551       \n",
            "=================================================================\n",
            "Total params: 767\n",
            "Trainable params: 767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBl0pWc1oF_r",
        "outputId": "4f6371a1-c84b-437b-8e95-31232ae6d643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "training_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))\n",
        "test_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (test_input_message)\n",
        "print (len(test_input_message))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 0 ... 1 1 0]\n",
            " [0 1 0 ... 1 1 0]\n",
            " [0 1 0 ... 1 0 0]\n",
            " ...\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 1 1 0]\n",
            " [1 1 1 ... 0 0 1]]\n",
            "10000\n",
            "[[0 0 1 ... 0 0 1]\n",
            " [0 0 1 ... 0 1 1]\n",
            " [1 1 1 ... 0 0 1]\n",
            " ...\n",
            " [1 1 1 ... 1 0 1]\n",
            " [1 0 1 ... 0 0 0]\n",
            " [1 0 1 ... 1 0 0]]\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOXLOYLu8aML",
        "outputId": "a1fc62a4-8f00-49c0-c6a1-496c4c10875b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "\n",
        "#def custom_losff_fucntion (act, pred):\n",
        "#  return (tf.reduce_mean(-1*(act * tf.log(pred) + (1-act)*tf.log(1-pred))))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "#autoencoder.compile(optimizer=opt, loss=custom_losff_fucntion)\n",
        "#loss='mean_squared_error'\n",
        "#for snr in (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)):\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  snr_std = sigma\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  autoencoder.fit(training_input_message, training_input_message,\n",
        "                #epochs=50, original\n",
        "                epochs=20,\n",
        "                batch_size=500,\n",
        "                shuffle=False,\n",
        "                validation_data=(test_input_message, test_input_message))\n",
        "  \n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for SNR= 0.0  sigma= 1.0\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "  500/10000 [>.............................] - ETA: 0s - loss: 0.8006WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.7153 - val_loss: 0.6069\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.6055 - val_loss: 0.5074\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.5322 - val_loss: 0.4360\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.4835 - val_loss: 0.3855\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.4506 - val_loss: 0.3452\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.4248 - val_loss: 0.3094\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.4033 - val_loss: 0.2759\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3825 - val_loss: 0.2479\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.3692 - val_loss: 0.2263\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.3576 - val_loss: 0.2088\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3497 - val_loss: 0.1948\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.3432 - val_loss: 0.1840\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.3367 - val_loss: 0.1752\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3330 - val_loss: 0.1673\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3290 - val_loss: 0.1613\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3252 - val_loss: 0.1554\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3227 - val_loss: 0.1498\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3197 - val_loss: 0.1445\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3160 - val_loss: 0.1391\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3114 - val_loss: 0.1323\n",
            "Training for SNR= 0.5  sigma= 0.9440608762859234\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.2873 - val_loss: 0.1191\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2793 - val_loss: 0.1069\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2723 - val_loss: 0.0968\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2672 - val_loss: 0.0891\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2626 - val_loss: 0.0834\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2564 - val_loss: 0.0783\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2564 - val_loss: 0.0743\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2537 - val_loss: 0.0717\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2519 - val_loss: 0.0691\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.2480 - val_loss: 0.0665\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2468 - val_loss: 0.0645\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2441 - val_loss: 0.0624\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2418 - val_loss: 0.0606\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2428 - val_loss: 0.0590\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2419 - val_loss: 0.0574\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2390 - val_loss: 0.0561\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.2408 - val_loss: 0.0548\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2397 - val_loss: 0.0539\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2370 - val_loss: 0.0523\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2367 - val_loss: 0.0516\n",
            "Training for SNR= 1.0  sigma= 0.8912509381337456\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.2135 - val_loss: 0.0474\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2114 - val_loss: 0.0443\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2094 - val_loss: 0.0420\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2096 - val_loss: 0.0405\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2083 - val_loss: 0.0389\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2066 - val_loss: 0.0377\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2082 - val_loss: 0.0368\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2070 - val_loss: 0.0357\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2056 - val_loss: 0.0347\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.2039 - val_loss: 0.0343\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2049 - val_loss: 0.0338\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2019 - val_loss: 0.0329\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2004 - val_loss: 0.0319\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2022 - val_loss: 0.0313\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1993 - val_loss: 0.0307\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2018 - val_loss: 0.0303\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2012 - val_loss: 0.0299\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2022 - val_loss: 0.0295\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2008 - val_loss: 0.0292\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2010 - val_loss: 0.0290\n",
            "Training for SNR= 1.5  sigma= 0.8413951416451951\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 12us/sample - loss: 0.1769 - val_loss: 0.0265\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1747 - val_loss: 0.0245\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1769 - val_loss: 0.0234\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1719 - val_loss: 0.0222\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1747 - val_loss: 0.0216\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1751 - val_loss: 0.0209\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1725 - val_loss: 0.0205\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1745 - val_loss: 0.0202\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1719 - val_loss: 0.0198\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1747 - val_loss: 0.0196\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.1718 - val_loss: 0.0193\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1695 - val_loss: 0.0189\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1697 - val_loss: 0.0188\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1727 - val_loss: 0.0183\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1704 - val_loss: 0.0181\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1715 - val_loss: 0.0179\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1721 - val_loss: 0.0178\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1701 - val_loss: 0.0176\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1709 - val_loss: 0.0174\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1710 - val_loss: 0.0174\n",
            "Training for SNR= 2.0  sigma= 0.7943282347242815\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 14us/sample - loss: 0.1447 - val_loss: 0.0155\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1441 - val_loss: 0.0144\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1486 - val_loss: 0.0138\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1465 - val_loss: 0.0131\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1447 - val_loss: 0.0130\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1472 - val_loss: 0.0126\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1466 - val_loss: 0.0124\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1472 - val_loss: 0.0123\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1458 - val_loss: 0.0122\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1443 - val_loss: 0.0119\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1471 - val_loss: 0.0117\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1448 - val_loss: 0.0116\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1434 - val_loss: 0.0114\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1438 - val_loss: 0.0114\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1441 - val_loss: 0.0111\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1458 - val_loss: 0.0111\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1425 - val_loss: 0.0110\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1459 - val_loss: 0.0109\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.1457 - val_loss: 0.0109\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1463 - val_loss: 0.0109\n",
            "Training for SNR= 2.5  sigma= 0.7498942093324559\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 17us/sample - loss: 0.1225 - val_loss: 0.0097\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1228 - val_loss: 0.0090\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1213 - val_loss: 0.0085\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1208 - val_loss: 0.0081\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1236 - val_loss: 0.0079\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1216 - val_loss: 0.0076\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1214 - val_loss: 0.0076\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1203 - val_loss: 0.0074\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1199 - val_loss: 0.0073\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1201 - val_loss: 0.0071\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1209 - val_loss: 0.0071\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1195 - val_loss: 0.0070\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1200 - val_loss: 0.0068\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1214 - val_loss: 0.0069\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1204 - val_loss: 0.0068\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1198 - val_loss: 0.0068\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1195 - val_loss: 0.0067\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1166 - val_loss: 0.0065\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1213 - val_loss: 0.0064\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1212 - val_loss: 0.0064\n",
            "Training for SNR= 3.0  sigma= 0.7079457843841379\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 17us/sample - loss: 0.1017 - val_loss: 0.0059\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0990 - val_loss: 0.0054\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0973 - val_loss: 0.0051\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0960 - val_loss: 0.0048\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0988 - val_loss: 0.0046\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0985 - val_loss: 0.0045\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0974 - val_loss: 0.0045\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0972 - val_loss: 0.0043\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0990 - val_loss: 0.0043\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0987 - val_loss: 0.0043\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0981 - val_loss: 0.0042\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0954 - val_loss: 0.0041\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0974 - val_loss: 0.0040\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0981 - val_loss: 0.0040\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0989 - val_loss: 0.0040\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0978 - val_loss: 0.0040\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0990 - val_loss: 0.0040\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0988 - val_loss: 0.0040\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0969 - val_loss: 0.0039\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0973 - val_loss: 0.0038\n",
            "Training for SNR= 3.5  sigma= 0.6683439175686147\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 20us/sample - loss: 0.0805 - val_loss: 0.0035\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0787 - val_loss: 0.0033\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0803 - val_loss: 0.0031\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0776 - val_loss: 0.0030\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0792 - val_loss: 0.0029\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0758 - val_loss: 0.0028\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0792 - val_loss: 0.0027\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0774 - val_loss: 0.0027\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0778 - val_loss: 0.0026\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0786 - val_loss: 0.0025\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0786 - val_loss: 0.0025\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0799 - val_loss: 0.0025\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0770 - val_loss: 0.0025\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0776 - val_loss: 0.0024\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0781 - val_loss: 0.0024\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0775 - val_loss: 0.0024\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0792 - val_loss: 0.0024\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0781 - val_loss: 0.0023\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0798 - val_loss: 0.0023\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0777 - val_loss: 0.0023\n",
            "Training for SNR= 4.0  sigma= 0.6309573444801932\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 21us/sample - loss: 0.0608 - val_loss: 0.0021\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0614 - val_loss: 0.0019\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0625 - val_loss: 0.0019\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0628 - val_loss: 0.0018\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0605 - val_loss: 0.0017\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0620 - val_loss: 0.0017\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0610 - val_loss: 0.0016\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0612 - val_loss: 0.0016\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0618 - val_loss: 0.0016\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0611 - val_loss: 0.0016\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0598 - val_loss: 0.0015\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0619 - val_loss: 0.0015\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0598 - val_loss: 0.0015\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0606 - val_loss: 0.0015\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0605 - val_loss: 0.0014\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0626 - val_loss: 0.0014\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0598 - val_loss: 0.0014\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0602 - val_loss: 0.0014\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0629 - val_loss: 0.0014\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0616 - val_loss: 0.0014\n",
            "Training for SNR= 4.5  sigma= 0.5956621435290105\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 25us/sample - loss: 0.0482 - val_loss: 0.0013\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0460 - val_loss: 0.0012\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0450 - val_loss: 0.0012\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0478 - val_loss: 0.0011\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0470 - val_loss: 0.0010\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0450 - val_loss: 0.0010\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0449 - val_loss: 9.8799e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0478 - val_loss: 9.5657e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0472 - val_loss: 9.2035e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0454 - val_loss: 9.1522e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0480 - val_loss: 9.0185e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0482 - val_loss: 8.9940e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0461 - val_loss: 8.5612e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0467 - val_loss: 8.8402e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0463 - val_loss: 8.4974e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0473 - val_loss: 8.7768e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0460 - val_loss: 8.3855e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0452 - val_loss: 8.2311e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0449 - val_loss: 8.3463e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0459 - val_loss: 8.1580e-04\n",
            "Training for SNR= 5.0  sigma= 0.5623413251903491\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 24us/sample - loss: 0.0352 - val_loss: 7.6790e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0351 - val_loss: 7.3020e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0342 - val_loss: 7.0482e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0344 - val_loss: 6.6005e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0335 - val_loss: 6.4306e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0347 - val_loss: 6.2619e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0343 - val_loss: 5.9353e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0342 - val_loss: 5.9324e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0340 - val_loss: 5.8554e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0345 - val_loss: 5.5976e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0343 - val_loss: 5.5154e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0352 - val_loss: 5.4023e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0334 - val_loss: 5.3618e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0331 - val_loss: 5.1757e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0337 - val_loss: 5.0968e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0352 - val_loss: 5.0879e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0344 - val_loss: 5.1473e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0334 - val_loss: 4.9640e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0326 - val_loss: 5.1032e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0338 - val_loss: 4.8582e-04\n",
            "Training for SNR= 5.5  sigma= 0.5308844442309884\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 24us/sample - loss: 0.0247 - val_loss: 4.6855e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0241 - val_loss: 4.3373e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0250 - val_loss: 4.1633e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0257 - val_loss: 3.9642e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0239 - val_loss: 3.8369e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0250 - val_loss: 3.7851e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0251 - val_loss: 3.7681e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0248 - val_loss: 3.5803e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0247 - val_loss: 3.4271e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0254 - val_loss: 3.4289e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0237 - val_loss: 3.3478e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0244 - val_loss: 3.3389e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0245 - val_loss: 3.2230e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0243 - val_loss: 3.2888e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0245 - val_loss: 3.1445e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0240 - val_loss: 3.0420e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0250 - val_loss: 3.0946e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0256 - val_loss: 3.0394e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0228 - val_loss: 2.9254e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0261 - val_loss: 3.0295e-04\n",
            "Training for SNR= 6.0  sigma= 0.5011872336272722\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 28us/sample - loss: 0.0175 - val_loss: 2.8789e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0175 - val_loss: 2.7276e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0174 - val_loss: 2.5767e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0165 - val_loss: 2.5446e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0164 - val_loss: 2.4147e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0169 - val_loss: 2.3851e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0176 - val_loss: 2.2172e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0167 - val_loss: 2.2236e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0170 - val_loss: 2.1811e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0167 - val_loss: 2.1249e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0173 - val_loss: 2.0455e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0169 - val_loss: 2.0174e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0167 - val_loss: 1.9786e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0164 - val_loss: 1.8835e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0171 - val_loss: 1.8983e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0178 - val_loss: 1.8889e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0170 - val_loss: 1.8532e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0163 - val_loss: 1.8823e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0181 - val_loss: 1.8228e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0177 - val_loss: 1.8229e-04\n",
            "Training for SNR= 6.5  sigma= 0.47315125896148047\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 31us/sample - loss: 0.0113 - val_loss: 1.7419e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0117 - val_loss: 1.7428e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0115 - val_loss: 1.5845e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0112 - val_loss: 1.4937e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0111 - val_loss: 1.4895e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0120 - val_loss: 1.4276e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0113 - val_loss: 1.4280e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0114 - val_loss: 1.3604e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0116 - val_loss: 1.3323e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0110 - val_loss: 1.2617e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0114 - val_loss: 1.2660e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0113 - val_loss: 1.2365e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0116 - val_loss: 1.2421e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0110 - val_loss: 1.1838e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0117 - val_loss: 1.1576e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0111 - val_loss: 1.1393e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0111 - val_loss: 1.1190e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0114 - val_loss: 1.0942e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0121 - val_loss: 1.0796e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0121 - val_loss: 1.1119e-04\n",
            "Training for SNR= 7.0  sigma= 0.44668359215096315\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0078 - val_loss: 1.0683e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0081 - val_loss: 1.0478e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0079 - val_loss: 9.9147e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0073 - val_loss: 9.5811e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0074 - val_loss: 9.5371e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0073 - val_loss: 8.8879e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0070 - val_loss: 8.7081e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0070 - val_loss: 8.7090e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0073 - val_loss: 8.5692e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0074 - val_loss: 8.2700e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0069 - val_loss: 7.8942e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0071 - val_loss: 7.7266e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0068 - val_loss: 7.5414e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0073 - val_loss: 7.3511e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0072 - val_loss: 7.0264e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0076 - val_loss: 7.1034e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0080 - val_loss: 7.0333e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0071 - val_loss: 7.2864e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0076 - val_loss: 6.9952e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0075 - val_loss: 6.8416e-05\n",
            "Training for SNR= 7.5  sigma= 0.4216965034285822\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 30us/sample - loss: 0.0049 - val_loss: 6.6753e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0046 - val_loss: 6.4334e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0047 - val_loss: 6.1243e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0043 - val_loss: 6.0743e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0049 - val_loss: 5.6302e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0045 - val_loss: 5.4827e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0047 - val_loss: 5.4136e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0045 - val_loss: 5.2143e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0046 - val_loss: 5.2090e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0045 - val_loss: 5.1725e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0040 - val_loss: 4.7973e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0049 - val_loss: 4.8055e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0042 - val_loss: 4.7572e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0044 - val_loss: 4.6339e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0043 - val_loss: 4.5161e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0050 - val_loss: 4.4630e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0041 - val_loss: 4.3905e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0043 - val_loss: 4.2263e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0045 - val_loss: 4.2662e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0044 - val_loss: 4.2522e-05\n",
            "Training for SNR= 8.0  sigma= 0.3981071705534972\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0031 - val_loss: 4.1355e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0029 - val_loss: 4.0976e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0029 - val_loss: 4.0063e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0023 - val_loss: 3.8733e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0031 - val_loss: 3.7051e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0031 - val_loss: 3.6207e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0030 - val_loss: 3.5880e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0024 - val_loss: 3.4531e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0026 - val_loss: 3.3743e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0025 - val_loss: 3.3338e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0026 - val_loss: 3.3417e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0028 - val_loss: 3.2079e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0026 - val_loss: 3.0470e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 12us/sample - loss: 0.0026 - val_loss: 3.0079e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0028 - val_loss: 3.0435e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0026 - val_loss: 2.8917e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0027 - val_loss: 2.8914e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0033 - val_loss: 2.9738e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0021 - val_loss: 2.9185e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0030 - val_loss: 2.8528e-05\n",
            "Training for SNR= 8.5  sigma= 0.3758374042884442\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 38us/sample - loss: 0.0018 - val_loss: 2.8376e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0019 - val_loss: 2.8152e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0014 - val_loss: 2.7884e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0017 - val_loss: 2.6649e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0014 - val_loss: 2.5701e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0016 - val_loss: 2.4807e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0015 - val_loss: 2.4241e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0017 - val_loss: 2.2839e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0016 - val_loss: 2.2426e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0015 - val_loss: 2.2738e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0015 - val_loss: 2.1998e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0015 - val_loss: 2.1214e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0015 - val_loss: 2.1045e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0018 - val_loss: 2.1560e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0016 - val_loss: 2.0709e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0019 - val_loss: 1.9755e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0012 - val_loss: 1.8714e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0015 - val_loss: 1.9263e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0014 - val_loss: 1.8909e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0013 - val_loss: 1.9087e-05\n",
            "Training for SNR= 9.0  sigma= 0.35481338923357547\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 37us/sample - loss: 8.7124e-04 - val_loss: 1.8599e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 8.4440e-04 - val_loss: 1.6258e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 8.8003e-04 - val_loss: 1.5616e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 7.0239e-04 - val_loss: 1.6010e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 8.2462e-04 - val_loss: 1.5569e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 8.6709e-04 - val_loss: 1.5096e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 8.5064e-04 - val_loss: 1.4327e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0011 - val_loss: 1.4179e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0010 - val_loss: 1.4044e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 9.0600e-04 - val_loss: 1.3487e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 7.1932e-04 - val_loss: 1.3474e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 9.3234e-04 - val_loss: 1.3633e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 8.6286e-04 - val_loss: 1.2870e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 8.2107e-04 - val_loss: 1.2416e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 9.2178e-04 - val_loss: 1.2603e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0011 - val_loss: 1.2353e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 8.0148e-04 - val_loss: 1.3166e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0010 - val_loss: 1.1753e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 9.3651e-04 - val_loss: 1.1565e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 7.9366e-04 - val_loss: 1.1489e-05\n",
            "Training for SNR= 9.5  sigma= 0.33496543915782767\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 44us/sample - loss: 4.8878e-04 - val_loss: 1.1501e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 7.4012e-04 - val_loss: 1.1034e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 5.1340e-04 - val_loss: 1.0926e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 3.6154e-04 - val_loss: 1.0073e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 2.4448e-04 - val_loss: 9.6954e-06\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 6.0967e-04 - val_loss: 9.6127e-06\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 4.1559e-04 - val_loss: 9.3737e-06\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 3.3464e-04 - val_loss: 9.0515e-06\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 3.1953e-04 - val_loss: 8.8041e-06\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 4.3907e-04 - val_loss: 8.5969e-06\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 7.5864e-04 - val_loss: 8.6827e-06\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 6.0110e-04 - val_loss: 8.7865e-06\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 6.6342e-04 - val_loss: 8.7214e-06\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 12us/sample - loss: 5.7749e-04 - val_loss: 8.6671e-06\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 4.5871e-04 - val_loss: 8.2630e-06\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 7.1084e-04 - val_loss: 7.8121e-06\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 12us/sample - loss: 6.7019e-04 - val_loss: 7.8747e-06\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 4.1971e-04 - val_loss: 8.0119e-06\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 5.1536e-04 - val_loss: 7.6307e-06\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 6.6570e-04 - val_loss: 7.5129e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p6QVY1BDnnL",
        "outputId": "e0685819-d2b1-4735-a504-5557db64d2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "awgn_channel = GaussianNoise(Snr2Sigma(10),input_shape=(CHANEL_SIZE,))\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "autoencoder.evaluate(input_message, input_message, batch_size=128)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.59240506158676e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHByzQbTUqbv",
        "outputId": "1eb01392-53e4-4bab-8df1-80f1f3f5b041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "train_init = tf.global_variables_initializer ()\n",
        "train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,CHANEL_SIZE])\n",
        "    #noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,CHANEL_SIZE])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.81s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 2.47s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 3.14s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 3.81s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.70\n",
            " -> Total Time: 11.22s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 1.30s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 1.97s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 2.64s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.66\n",
            " -> Total Time: 6.56s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 0.67s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 1.33s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 2.63s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.59\n",
            " -> Total Time: 6.62s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.34s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 2.66s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.55\n",
            " -> Total Time: 6.62s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.67s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.33s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.99s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.66s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.50\n",
            " -> Total Time: 6.66s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.32s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.65s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.44\n",
            " -> Total Time: 6.61s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.33s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 2.65s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.35\n",
            " -> Total Time: 6.61s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.68s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 1.34s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 2.05s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 2.78s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.30\n",
            " -> Total Time: 6.85s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.68s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 1.35s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 2.04s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 2.70s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.25\n",
            " -> Total Time: 6.77s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.67s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 1.36s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 2.03s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 2.77s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.19\n",
            " -> Total Time: 6.83s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 1.32s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 1.99s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 2.66s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.13\n",
            " -> Total Time: 6.62s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 1.34s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 2.06s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 2.76s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.11\n",
            " -> Total Time: 6.81s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.68s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 1.35s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 2.02s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 2.71s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.08\n",
            " -> Total Time: 6.76s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.69s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 1.39s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 2.05s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 2.72s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.06\n",
            " -> Total Time: 6.86s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.68s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 1.37s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 2.03s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 2.71s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 6.79s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.69s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 1.41s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 2.08s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 2.73s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 6.91s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.67s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 1.34s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 2.01s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 2.68s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 6.69s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 1.36s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 2.03s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 2.68s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 6.72s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 1.99s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 2.73s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 6.69s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.69s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 1.37s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 2.08s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 2.74s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 6.88s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUQij3fuxRm",
        "outputId": "d9509801-080d-43eb-8e91-59defc56db31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"ldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLfbkfh4NvTj",
        "outputId": "fe8a7dfc-d9e8-400e-c740-fc044623910c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 0 ... 1 1 0]\n",
            " [0 1 0 ... 1 1 0]\n",
            " [0 1 0 ... 1 0 0]\n",
            " ...\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 1 1 0]\n",
            " [1 1 1 ... 0 0 1]]\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGOH9hSKVvXI",
        "outputId": "eb062d72-f7d2-4145-dd46-4f03026c71d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "train_init = tf.global_variables_initializer ()\n",
        "train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,CHANEL_SIZE])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,CHANEL_SIZE])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 0.57s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 1.13s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 1.70s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 2.28s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.70\n",
            " -> Total Time: 5.67s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 1.14s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 1.70s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 2.26s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.69\n",
            " -> Total Time: 5.66s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 1.11s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 1.66s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 2.22s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.63\n",
            " -> Total Time: 5.54s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.57s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.13s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 1.70s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 2.25s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.51\n",
            " -> Total Time: 5.66s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.56s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.12s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.67s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.23s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.47\n",
            " -> Total Time: 5.58s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.58s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.16s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.72s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.30s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.43\n",
            " -> Total Time: 5.76s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.56s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.14s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.72s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 2.28s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.37\n",
            " -> Total Time: 5.70s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 1.12s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.69s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 2.25s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.28\n",
            " -> Total Time: 5.61s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 1.10s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 1.66s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 2.21s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.24\n",
            " -> Total Time: 5.51s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 1.13s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 1.71s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 2.27s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.18\n",
            " -> Total Time: 5.66s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 1.11s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 1.67s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 2.25s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.13\n",
            " -> Total Time: 5.59s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.57s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 1.12s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 1.68s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 2.25s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.11\n",
            " -> Total Time: 5.62s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.57s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 1.13s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 1.69s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 2.25s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.08\n",
            " -> Total Time: 5.63s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.57s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 1.13s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 1.68s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 2.24s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.06\n",
            " -> Total Time: 5.62s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.56s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 1.12s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 1.68s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 2.24s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 5.60s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 1.15s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 1.70s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 2.26s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 5.66s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.56s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 1.11s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 1.69s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 2.26s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 5.62s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 1.12s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 1.67s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 2.24s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 5.58s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.56s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 1.12s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 1.68s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 2.24s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 5.61s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.56s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 1.11s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 1.69s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 2.25s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 5.60s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k01LEr1TV14X",
        "outputId": "e72b129a-b36f-43e3-d13e-f0cc882647e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"ldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAF1CAYAAAAA8yhEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xUVcLG8d9JT0hP6AESCL23AIoUsaCCHRV7A1Hsrq7ruuqurrq7r7trQRQboouKCAoCFpSm1ADSW+ihBQKEmpBy3j9uIhFDz+ROZp7v5zOfJDOTmSe47/vMOffcc421FhEREfFNAW4HEBEREc9R0YuIiPgwFb2IiIgPU9GLiIj4MBW9iIiID1PRi4iI+DAVvUglY4x5zhjzsds5PMUY08wYk26MMW5nOVPGmOrGmBXGmFC3s4io6EXOkDFmgzHmsDHmgDFmuzFmuDEm0u1cp8sYM9UYc3cZ9ycbY2zx33fAGLPDGPO1MebCY55X+t9hx7H/DsaYi40x040x+40xO40x04wxl58g0vPA/9niTT6MMfcXF3+eMWZ4GTmvKy7V/caY5caYK0/wt15njJlpjDlkjJlaxuPDjDGrjDFFxpjbT5ARY8yyUv82B4wxBcaY8QDW2h3AFGDgiV5DpCKo6EXOTl9rbSTQBmgL/MnlPCdkjAk8g1+LLf4bWwPfA2PLKMGSf4d2QAfg6eL3uxb4HBgBJAHVgWeAvsfJVxPoCXxZ6u6twAvA+2U8vzbwMfAoEA08Dow0xlQ7zt+yG/gv8PJxHl8E3AcsOM7jv7LWNrfWRhb/3VHAZpy/tcT/gHtO9joinqaiFykH1trtwLc4hQ+AMaZz8ehxrzFmkTGmR6nHUkqNcicbY4aUTMcbY3oYYzJLv37xqPmCst7bGPN58YxCTvFrNi/12HBjzFBjzERjzEGcEj3jv9Fa+yrwHPAPY8zv/v+HtXYLMAloUTz1/m/geWvtu9baHGttkbV2mrV2wHHe5kJggbU2t9RrjrHWfglkl/H8JGCvtXaSdUwADgINjvM3TLbWjsL58FDW40OstT8AuWU9fgLdgETgi1L3zQHqG2PqneZriZQrFb1IOTDGJAGXABnFP9cGJuCMROOBPwBfGGOqFv/KSGAukIBTnLecxdtPAhoC1XBGov875vEbgb/jjDp/Oov3KTGm+L0aH/uAMaYOcCmwsPjxOsDo03jtlsCq03h+OrDCGHO5MSaweNo+D1h8Gq9RHm4DvrDWHiy5w1pbgPO/h9YVnEXkN4LcDiBSyX1pjLFAJPAj8Gzx/TcDE621E4t//t4Ykw5caoyZAnQEellrjwA/GWPGnWkAa+2vU9rGmOeAPcaYGGttTvHdX1lrfy7+/nRHqmUpGQ3Hl7rvS2NMAZCD8wHnRZxpfIBtp/HasZQ9ci+TtbbQGDMC54NTGHAE6Fe6cD3NGBMBXAuUte5gP87fJOIajehFzs6V1toooAfQBGf6FqAe0K942n6vMWYv0BWoCdQCdltrD5V6nc1n8ubFo9iXjTFrjTH7gA3FDyWWetoZvfYJ1C7+urvUfVdaa2OttfWstfdZaw9ztLBrnsZr78GZeTglxYcz/onz7x8CdAfeNca0OdHvlbOrcf4tppXxWBSwtwKziPyOil6kHFhrpwHDgf8rvmsz8FFx+ZXcqlhrX8YZ4cYXjwRL1Cn1/UHg18eKF9BVpWw3AlcAFwAxQHLJr5WOd0Z/1PFdBWRx8in2VTj/DtecxmsvBhqdxvPbANOttenFx//n4RwbL3M9g4fcBowoOUughDEmCEjFWeAn4hoVvUj5+S9woTGmNc5K8L7Fp5YFGmPCihfZJVlrN+IcW37OGBNijOnCb1ehrwbCjDGXGWOCcVawH+987CicY9LZOB8OXjzD7EHFGUtuwcc+wTjnht+Pc3jiT9baohO9YHHxPQr8xRhzhzEm2hgTYIzpaowZdpxf+x5oZ4wJK/W+QcU/BwIl/5Ylhx3nAeeVjOCNMW2B8yg+Rl/8b25LvVZg8WsFAQHH/q3F/z3CcD4oBRc/HlDWaxXfl4SzwPHDMv6WNGBD8X9vEdeo6EXKibV2J85pZM9YazfjjLSfAnbijGwf5+j/zd0EdMEp6BeAz3AKm+Jj6/cB7wJbcEb4v1mFX8oIYGPx85YDs88w/lDgcKnbB6Ue21u8Yn8JzkK7fqXXBZyItXY0cD1wJ86x/R04f+9Xx3n+Dpy1DleUuvvp4kxP4qx9OFx8X8lMynPAaGPMfpxV7y9aa78r/t06wMxSr3VL8e8PxflAcBh4p9Tj3xXfdw4wrPj7bsd5rZLXm2WtXVvGn3MT8FZZf6dIRTLHzDaJiAuMMZ8BK621z570yT7OGNMMZ4Scdux0+Bm81rvA59bab8sh1ym/VvF5/NOAtqVPFRRxg4pexAXGmI44C7jWAxfhbBDTxVq70NVgIuJzdHqdiDtq4JyPnoAzLX+vSl5EPEEjehERER+mxXgiIiI+TEUvIiLiw3zyGH1iYqJNTk52O4aIiEiFmD9//i5rbZkba/lk0ScnJ5Oenu52DBERkQphjDnuxkyauhcREfFhPlX0xpi+xphhOTk5J3+yiIiIH/CporfWjrfWDoyJiXE7ioiIiFfwyWP0IiLif/Lz88nMzCQ313d3HQ4LCyMpKYng4N9dd+q4VPQiIuITMjMziYqKIjk5GWPMyX+hkrHWkp2dTWZmJikpKaf8ez41dS8iIv4rNzeXhIQEnyx5AGMMCQkJpz1joaIXERGf4aslX+JM/j6fKnqtuhcRETdFRkaWef/tt9/O6NGjKziNw6eKXqvuRUREfsunil5ERMQbWGu5//77ady4MRdccAFZWVm/PpacnMwTTzxBy5YtSUtLIyMjA4AdO3Zw1VVX0bp1a1q3bs3MmTPLJYtW3YuIiM/56/hlLN+6r1xfs1mtaJ7t2/yUnjt27FhWrVrF8uXL2bFjB82aNePOO+/89fGYmBiWLFnCiBEjePjhh/n666958MEH6d69O2PHjqWwsJADBw6US24V/clsWwSHsiE0BsKiITTa+RoUBj6+6ENERM7M9OnT6d+/P4GBgdSqVYvzzz//N4/379//16+PPPIIAD/++CMjRowAIDAwkPI6DK2iP5mfX4OlZSygCAiG0KhS5R9z9ENAaFSp70u+xvz2+eFxEBJR8X+PiIgfONWRt1tKr5739JkCPlX0xpi+QN/U1NTye9Hzn4aOd0HuPsjbB7k5xV/3Qd7+Ut/vgz0bnK95xY/ZohO/dkwdqN4cqjVzvlZvDgmpEHjqOx6JiIj36datG2+//Ta33XYbWVlZTJkyhRtvvPHXxz/77DOefPJJPvvsM7p06QJAr169GDp0KA8//PCvU/flMar3qaK31o4Hxnfo0GFAub1ofIpzO/0wcOTA0Q8BefuLv89xvh7aBVkrIWs5ZEyGogLn9wJDILFRqQ8ALaB6M4iqqUMFIiKVxFVXXcWPP/5Is2bNqFu37q9lXmLPnj20atWK0NBQPvnkEwBeffVVBg4cyHvvvUdgYCBDhw793e+dCWOtPesX8TYdOnSwlep69AVHYNdqp/R3LIUdy53v9205+pyw2KOlX/IBoFpTCC37nE0REX+zYsUKmjZt6naMk0pOTiY9PZ3ExMQz+v2y/k5jzHxrbYeynu9TI/pKKygEarRwblx39P7De46WfskHgF9GOjMFJWLrHf0AUL05pHSHiPgK/xNERMQ7qei9WXgcJJ/r3EoUFUHOJqf0dyyDrGXO96snOWsCgsKgdX/ofB9UbeRedhERKdOGDRsq9P1U9JVNQADEJTu3JpcevT8/1xn1L/jQGfXP/wAaXgRdBjujfB3fFxHxS9oZ7yQO5hVQKdYxBIdBUge4/HV4ZBn0eAq2LoQRV8BbXWHh/6Agz+2UIiJSwXyq6D1xUZsXJiyn499/4OFPFzJ6fibbc07v8oCuiKwKPf4IDy+FK4Y4U/pf3Qf/aQHT/gkHd7mdUEREKohW3Z/Et8u2M3HJNn7O2MWuA0cAaFgtkq4NE+mamkjn+glUCfXyIyDWwrqpMGsIZHzvHMdvdb1zHL9aE7fTiYiUi8qy6v5sadV9Obu4eQ0ubl6DoiLLyu37+SljJzPW7GLknE188PMGggIM7erGOcXfMJFWtWMICvSyiRJjoEFP57ZzFcx+ExZ96hzPb9DLOY7f4HwdxxcR8ZBLL72UkSNHEhsbe8LnlT71LjIyslz2u9eI/gzl5hcyf+MeZqzZxU8ZO1m2dR/WQlRYEOc0SKBrw6qcl5pIvYQIj29veEYOZkP6+zDvHTiwA6o2hS73QcvrnOP9IiKVjC+M6E+l6DWiryBhwYGcm5rIuamJQBN2HzzCzLW7+GnNLmas2cW3y3YAkBQXznkNE+maWpVzUxOIjQhxN3iJKgnQ/XE490FY+gXMehPGPQCT/wod73a2/Y2s5nZKEZFK58orr2Tz5s3k5uby0EMPMXDgwONukpOdnU3//v3ZsmULXbp08cjib43oPcBay4bsQ/y0xpnmn7U2m/15BRgDLWvH0DXVOb7fqk4skd5yfN9aWD/dmdZf/Q0EhkKrftB5sLMZj4iIl/vNSHfSk7B9Sfm+QY2WcMnLJ33a7t27iY+P5/Dhw3Ts2JFp06bRvn37Mov+wQcfJDExkWeeeYYJEybQp08fdu7cqRG9tzPGkJJYhZTEKtzSJZmCwiIWZebwU/E0/7Dp63hz6lqMgfqJVWiVFEuL2jG0Soqhea1oIkJc+M9iDNTv7tx2rYHZQ53z8Rd+DEkdnf+BJzaGqo2hahOIqqFj+iIiZXjttdcYO3YsAJs3b2bNmjXHfe706dMZM2YMAJdddhlxcXHlnkdFXwGCAgNoXy+O9vXieOiChuzPzSd94x6WZOawODOHmWt3MXahs699gIHUapFO8deOoWVSLM1qRhMeElhxgRMbQp9/O1fum/8BrP7Wmd7PLXXaYmhMcekXF3/VJs73MUn6ACAi7juFkbcnTJ06lcmTJzNr1iwiIiLo0aMHublHT8seMmQI77zzDgATJ06skEw+VfQeuUytB0SFBdOzcTV6Nj56DDxrXy5LtjjFv2RLDtNX72LMAqf8AwMMDatF0rJ41N8yKZYmNaIIC/Zw+UfEw3mPOTdr4UAW7FzpXIBn50pnBf/qb2DhR0d/JyTS+aBQUvwlX2PrQUAFflgREXFBTk4OcXFxREREsHLlSmbPnv2bxwcPHszgwYN//blbt26MHDmSp59+mkmTJrFnz55yz+RTRe+Ry9RWkGrRYfSKDqNX0+qAc5x/x748FmfuZckWp/x/WJnF5/MzAQgKMDSqHlVc/DG0rB1D4xpRhAZ5qEyNgajqzq1+998+djAbdq0qLv/iDwHrpsGiT44+Jyjs6AeAkkMANVpAbLKzra+IiA/o3bs3b731Fk2bNqVx48Z07tz5hM9/9tln6d+/P82bN+ecc86hbt265Z5Ji/EqEWstW3NyWVJc/iWj/72H8gEIDjT0blGTxy9qTN2ECJfT4kz1lxR/yQzAzlXORXlKhEQVX7mv5dFb1aY6xU9ETpsvnF53KrQYz4cZY6gdG07t2HB6t6gJOOWfuecwS7bkMHf9bj6dt4lvlm7jls7JPHB+KnFVXDydLywG6nR0bqXlHXBmALYvdVbF7lj628vvmkBIbPTb8q/REqqc2bWbRUT8mYq+kjPGUCc+gjrxEVzasib39mjAf75fzfCZ6/l8/mYG90zl9nOSPX88/3SERkLt9s6tRFER7N3gFH/JbePPsGTU0edE1Sou/ZIZgFYQl6KpfxGRE9DUvY9atX0///hmJT+uzKJWTBh/uLgxV7apTUBAJVsRfzAbdiw5OvrfvsQ5DGALnceDq/x26j/5PEho4G5mEXGFpu7LnrpX0fu4mWt38dLElSzZkkOzmtH86dImnNewqtuxzk5+rlP2pUf/25fAkf3O4zVaQvOroflVEJ/iblYRqTArVqygSZMm3rnteDmx1rJy5UoVvYr+t4qKLOMXb+Vf364ic89hujWqyp8uaULTmtFuRys/RUWwZ71zzv+yMZA5z7m/VtujpR9bx92MIuJR69evJyoqioSEBJ8se2st2dnZ7N+/n5SU3w5iVPQCQF5BIR/N2sjrP2awLzefa9ol8dhFjagZE+52tPK3dxMsG+vcti507kvqWFz6V0J0LXfziUi5y8/PJzMz8zcb1PiasLAwkpKSCA4O/s39Knr5jZxD+bw5NYMPZm7AAHd1TWFQjwZEhwWf9Hcrpd3rjpZ+yd7Xdbs4pd/sCmdvABGRSsxvir7UzngDTrS3sDgy9xzile9WM3bhFuIignmwV0Nu6lSPkCAfXsW+a83R0s9aDiYA6p3rTO03u0Kn8IlIpeQ3RV9CI/rTs3RLDi9NWsHPGdnUS4jgiYubcGnLGj55jOs3slY4hb90DGSvcc7fT+kGLa6GJn2cLYBFRCoBFb2clLWWaat38vKklazcvp82dWJ56tKmpKX4QdlZ62zaU1L6e9ZDQBDU7+mUfuNLITzW7ZQiIselopdTVlhk+WJBJq98t4od+/K4sFl1/ti7CanVIt2OVjGshW2/FJf+WGe73pBI6PEkdBoEgT66jkFEKjUVvZy2w0cKef/n9QydupYjhUU806cZN3Wq6/vT+aVZC1vmw7R/wppvoVozuOwVqHeO28lERH7jREXvw6uu5GyEhwQyuGcqUx/vQZf6CTz95VIe+GQh+3Pz3Y5WcYyBpA5w42dww0jI2w8fXAJjBzmX7BURqQRU9HJCiZGhfHB7R57o3ZhJS7fT9/WfWLY1x+1YFcsYaHIZDJ4DXR+FJaPh9Q4w9x0oKnQ7nYjICano5aQCAgz39UjlkwGdyc0v4qo3Z/Lx7I344mGfEwqpAhc8C/fOhFqtYeIf4J3znel9EREvpaKXU5aWEs+EB7v671R+iaqN4NZxcM17sH87vNMLvn4EDu12O5mIyO+o6OW0JGgq32EMtLwW7p8Hne+F+cPhjQ6w8GNn330RES+hopfTpqn8UsKiofdLcM90SEiFrwY7C/a2L3U7mYgIoKKXs6Cp/FJqtIQ7voHL34Bdq+HtbvDNU5C7z+1kIuLnVPRyVjSVX0pAALS7BR6Y73yd/Sa80dFZpe+Psx0i4hV8quiNMX2NMcNycvy0aFyiqfxjRMRD31fh7h+cK+N9cReMuMK5oI6ISAXTznhSrrIP5PHoqEVMW72TPq1q8tLVLYny1cvfnoqiQkh/H354HvIPwbkPwnl/gJAIt5OJiA/RznhSYTSVf4yAQEgbAA+kQ4trYMYrMKQTrJyg6XwRqRAa0YvHzF2/mwc+WcCeQ/n+uVd+WTb8DBMeg50rIKom1O/hXCWvfg9nml9E5AzoojbimuwDeTwyahHTNZV/VGE+LB4FGd/DumlwuHijnWrNnNJv0NO5cE5IFXdzikiloaIXVxUVWYZOW8sr362ibnwEQ25qR/NaMW7H8g5FRbB9MaybAmunwKbZUJgHgSFQpxPU7w71z4dabZzDACIiZVDRi1coPZX/lz7NuCmtLgEBfj6Vf6z8w7BpllP666bA9iXO/WGxkNLNGe3X7wHx9d1MKSJeRkUvXqP0VH5SXDj92tfh2g5J1I4NdzuadzqwE9ZPKx7xT4V9mc79sfWKS7+n8wEgIt7VmCLiLhW9eJWiIsv4xVsZlb6ZnzOyMQa6pibSr0MdLmpWnbBgTVGXyVrIzoB1U50R/4YZkLcPMM7Ufv2e0LIfVG/mdlIRqWAqevFam3cfYvT8TEbPz2TL3sPEhAdzZZta9OtQhxa1dRz/hAoLnEvkrpvqjPgz5zn393gSzn0EAoNcjSciFUdFL16vqMgyc202o9I3882y7RwpKKJpzWiu65DElW1qE1clxO2I3u9gNkz8AywbA0lpcNVbkNDA7VQiUgFU9FKp5BzKZ9yiLYxKz2TJlhxCAgO4sFl1+nVI4ryGVQnUAr4TWzIaJjzqnMZ38d+h/R3OZXVFxGep6KXSWr51H5/P38yXC7ew51A+NWPCuKZdEv06JFEvQeeZH1fOFueSueumQOqFcMUbEFXD7VQi4iEqeqn08goK+WFFFqPSNzN99U6KLHRKiee6DnW4pGUNIkJ0PPp3iopg3rvw/TMQHAZ9/gPNr3I7lYh4gIpefMq2nMOMWbCFUemb2Zh9iMjQIPq2rkm/DnVoWydW2+wea9caGDMQti6AltfBpf+C8Fi3U4lIOVLRi0+y1jJ3/W4+n5/JhMXbOJxfSPNa0QzumUrv5jW0GU9phfnOBXWm/dOZwr/yTWfjHRHxCSp68XkH8goY98tW3pmxjvW7DtKgahXu65HK5W1qERyoizT+ast8GHMPZK+BTvfCBc9CsDYrEqnsVPTiNwqLLBOXbGPIlAxWbt9PUlw4g7o34Nr2SdqIp8SRQzD5WZg7DBIbw9VvQ622bqcSkbPgN0VvjOkL9E1NTR2wZs0at+OIi6y1/LAiizemZPDL5r1UiwplYLf69E+rS5VQLdwDYO2P8OVgOJgF3f8IXR/VJjsilZTfFH0JjeilhLXORjxDpmQwc202cRHB3HFuCredk0xMuJ9fLhfg8B6Y8AdYOhpqd4Cr3obEVLdTichpUtGLAAs27WHIjxn8sDKLyNAgbulSj7u6ppAYGep2NPct/QK+fhQKj8BFz0OHu7TJjkgloqIXKWX51n0MmZrBxCXbCA0K4IaOdRnYrT61/P0Kevu2wlf3w9ofIPUCuPwNiK7pdioROQUqepEyrN15gKFT1/Llwi0YA1e3TeLeHg1ITvTjHfesdTbZ+e4vziY7l/0bWlztdioROQkVvcgJZO45xLDp6/h03mYKCovo06oWg3um0rhGlNvR3LMrA8YOdE7Ha3Et9H4ZIqu6nUpEjkNFL3IKsvbn8t6M9Xw8eyMHjxRyYbPq3N8zldZ1/HQXucIC+OnfziY7IRHQ61lofzsE6DRFEW+johc5DXsPHeGDnzcwfOYGcg7n06NxVV6+uhU1YsLcjuaOnatgwmOwYQbUagd9/q3z7kW8jIpe5AwcyCvg49kbee2HNYQFB/LKda3p2bia27HcYa1z+dtvn4KDO6Hj3XD+09ozX8RLnKjotTeoyHFEhgYxqHsDxt3flWpRodzxwTxemrSC/MIit6NVPGOgVT94IB3SBkL6e/BGB1j0mfMhQES8lope5CRSq0Xy5eBzualTXd6eto7r3p5F5p5DbsdyR1gMXPpPGDgVYus5C/aG94GslW4nE5HjUNGLnIKw4ED+flVL3rixLRk7DnDpqzP4dtl2t2O5p2ZruOt76Psq7FgKb50L3z8LRw66nUxEjqGiFzkNfVrV4usHu1IvoQr3fDSfv45fRl5Bodux3BEQ4KzCf2A+tL4Bfv4vvJEGK8ZrOl/Ei6joRU5TvYQqjL63C3eem8IHP2/gmqEz2bDLj0eyVRLhiiFw57fO1P5nN8PI62D3ereTiQgqepEzEhoUyDN9mzHslvZs3n2YPq//xNeLt7ody111O8M90+HiF2HjTHizs3MOfkGe28lE/JqKXuQsXNS8BhMfOo9G1SO5f+RCnhq7hNx8P53KB+cyt10Gw/3zoPElMOXv8GYXyPjB7WQifktFL3KWaseG89k9XRjUvQEj52ziyiE/k5F1wO1Y7oquBf2Gw81jnJ8/vho+v925cI6IVCgVvUg5CA4M4MlLmjD8jo5k7c+j7+s/8cX8TLdjuS+1F9w3C3o+DasmwRsdYeYbUJjvdjIRv6GiFylHPRpXY9JD59EqKYbHPl/EY6MWcehIgdux3BUUCt0fh/tmQ71z4Ls/w9vdYfk4Fb5IBdAWuCIeUFhkefWHNbz+4xrqJ1ZhyE3taFIj2u1Y7rMWVn7tbKW7dxNE1oB2tzq32DpupxOptLTXvYhLZmbs4qHPfmHf4Xyeu7w5N3SsgzHG7VjuKyyAjO8h/QNY852zxW7Di6DDnZB6ga6QJ3KaVPQiLtq5P49HR/3CjDW76Nu6Fi9e1YKosGC3Y3mPvZtg/oewYAQczIKYOtD+Nmh7C0TVcDudSKWgohdxWVGRZei0tfz7+9UkxYUz5MZ2tKgd43Ys71KYDysnwPwPYN1UCAiCxpc6o/yU7s5OfCJSJhW9iJeYt2E3D36ykOwDR3itf1t6t9CItUzZa53CX/g/OLwb4us72+22ucnZiU9EfkNFL+JF9hw8wp0fzmPZ1n387+5OdEyOdzuS98rPdfbOT38fNs2EwBBodoUzyq/bxTm2LyIqehFvs/vgEa4dOpPsg0f44t4upFaLcjuS98ta4SzeW/Qp5OVA1SbQ/g7ngjrhsW6nE3GVil7EC23efYir3pxJaFAAY+47h+rRYW5HqhyOHIJlY5xR/pb5EBQOLa5xRvm122mUL37pREWv1S0iLqkTH8HwOzqy99ARbnt/LvtytXnMKQmJgLY3w4AfYeA0aH09LBsL754Pw/vA3s1uJxTxKl5f9MaY+saY94wxo93OIlLeWtSOYejN7cnIOsCgj+ZzpKDI7UiVS6020PdVeGwlXPJP2LYI3uoKK752O5mI1/Bo0Rtj3jfGZBljlh5zf29jzCpjTIYx5skTvYa1dp219i5P5hRxU7dGVfnHNa2YuTabx0cvoqjI9w6neVxYNHS6B+6ZBnHJ8NlNMPFxZzGfiJ/z9Ih+ONC79B3GmEBgCHAJ0Azob4xpZoxpaYz5+phbNQ/nE/EK17RP4vGLG/PVL1v5xzcr3Y5TeSU0gLu+h86DYe4weO8C2LXG7VQirgry5Itba6cbY5KPuTsNyLDWrgMwxnwKXGGtfQno48k8It7svh4N2J6Ty9vT11EjJow7zk1xO1LlFBQCvV+ElG7w5b3OBXQuewXa9Hc7mYgr3DhGXxsovVoms/i+MhljEowxbwFtjTF/OsHzBhpj0o0x6Tt37iy/tCIVxBjDc5c356Jm1fnb18uZuGSb25Eqt8a9YdBPznH8LwfBmHsg74DbqUQqnNcvxrPWZltrB1lrGxSP+o/3vGHW2g7W2g5Vq1atyIgi5SYwwPBa/7a0qxvHw5/9wpx12W5HqtxiasNt46H7k7BkFLzdzVmwJ+JH3Cj6LUDp61EmFd/V6/wAACAASURBVN8nIkBYcCDv3tqBOnHhDBiRzuod+92OVLkFBELPP8Gt4yD/ELx7Acx527lkrogfcKPo5wENjTEpxpgQ4AZgnAs5RLxWXJUQPrwzjbDgQG57fy7bcg67HanySzkPBv0M9XvCpCfgs5vh0G63U4l4nKdPr/sEmAU0NsZkGmPustYWAPcD3wIrgFHW2mXl9H59jTHDcnJyyuPlRFyVFBfBB3d0ZH9uAbe/P4+cw9pQ56xVSYAbP4OLX4TV38Jb58Gm2W6nEvEobYEr4uV+WrOL2z+YS4fkOD68M43QoEC3I/mGLQtg9J2wd5Mztd/1UWeaX6QS0ha4IpVY14aJ/KtfK2av280fPl+sDXXKS+12cM90aH4l/PgCfHQV7N/udiqRcqeiF6kErmqbxJOXNGH8oq28NGmF23F8R1g0XPMeXP4GbJ4LQ8+FNZPdTiVSrlT0IpXEPd3qc/s5ybwzYz3vzljndhzfYQy0uwUGToXIavC/a+D7Z6BQayLEN6joRSoJYwx/6dOMS1rU4IUJKxi/aKvbkXxLtSbOFfHa3wE/vwrv94Y9G9xOJXLWfKrotepefF1ggOE/17chLTmex0YtYtZabahTroLDoe9/od9w2LXaWZW/dIzbqUTOik8VvbV2vLV2YExMjNtRRDwmLDiQd27tQL2ECAZ+lM7K7fvcjuR7ml8Fg2ZAYkMYfQd82Bcy57udSuSM+FTRi/iLmIhght+ZRkRIILe/P4+te7WhTrmLS4Y7v4XeL8OO5fDu+fDpTZClqwtK5aKiF6mkaseGM/yONA7mFXD7B3O1oY4nBAZD53vhoV+gx1OwbhoM7QJj74U9G91OJ3JKVPQilVjTmtG8fWt71u86yMAR6eTmF7odyTeFRkGPP8JDi6DzfbD0C3i9PUx8Ag5kuZ1O5IRU9CKV3DkNEvm/fq2Zs343d304j827D7kdyXdVSYCL/w4PLnCubz/vXXi1jbPhTq4WAYt38qktcI0xfYG+qampA9asWeN2HJEKNWreZp4bvwxr4dELG3HHuckEBeqzvEftyoApL8CysRAeB10fgbSBzup9kQp0oi1wfaroS2ive/FXW/Ye5tmvljJ5RRbNa0Xz0tUtaZUU63Ys37f1F/jxeciYDFG1oPsT0PZm5xi/SAVQ0Yv4EWst3yzdzrPjlrHrQB63nZPMYxc1JjI0yO1ovm/DTzD5r5A5F+LrQ88/Q/OrIUAzK+JZKnoRP7QvN59/fbOKj+dspEZ0GH+7ogUXNqvudizfZy2s/gZ+eB6ylkGNltDrWUi9wNluV8QDdPU6ET8UHRbM81e2YPSgc4gOC2bAiHQGfTSf7Tm5bkfzbcZA40ucDXeufgfy9sP/roUPLoVNs91OJ35II3oRP5BfWMSw6et47Yc1BAcG8ETvxtzUqR6BARphelzBEVjwIUz/FxzYAQ0vhl5/cUb6IuVEU/ciAsDG7IP8eexSfsrYRZs6sbx0dUua1ox2O5Z/OHIQ5rwNP/8XcvdBjz855+aLlAO/KXqdXidyctZavvxlC89/vYJ9h/O5+7z6PNSrIeEhgW5H8w+H98CkJ2Hxp9Dzaej+uNuJxAf4TdGX0Ihe5OT2HDzCixNX8Pn8TOrGR/DClS3o1qiq27H8Q1ERfHUfLPoELvgrdH3Y7URSyWkxnoj8TlyVEP7VrzWfDOhMUIDh1vfn8tCnC9l1IM/taL4vIACuGAItroXJz8KsIW4nEh+mohfxc10aJDDxofN4sFdDJi7ZRq9XpjFq3mZ8cbbPqwQEwlVvQ9PL4dunYO47bicSH6WiFxHCggN59MJGTHzwPBpVj+SJLxZzw7DZrN15wO1ovi0wCK59HxpfBhP/AOkfuJ1IfJCKXkR+1bB6FJ8N7MJLV7dkxbZ9XPLfGbz2wxqKijS695jAYOj3gXPa3dcPw8KP3U4kPkZFLyK/ERBg6J9Wl8mPdeei5tX59/ereWbcUk3le1JQKFw3AhqcD1/dD4s+czuR+BBtfi0iZaoWFcbr/dtSOy6ct6etIyQwkL/0aYrRNq6eERwGN4yEkdfBl4OckX6Lq91OJT7Ap4q+1Hn0bkcR8QnGGJ7s3YQjBUW8//N6QoIC+GPvxip7TwkOh/6fwsfXwhd3O2XftK/bqaSS86mpe2vteGvtwJiYGLejiPgMYwzP9GnGzZ3r8ta0tfxnsjaj8qiQKnDTKKjdHj6/A1ZNcjuRVHI+VfQi4hnGGP52eQuu71CH135Yw5ApGW5H8m2hUXDzaGc//FG3wprJbieSSkxFLyKnJCDA8OLVLbm6bW3+9e0q3pm+zu1Ivi0sBm4ZA1WbwKc3wtopbieSSkpFLyKnLDDA8M9rW3FZq5r8feIKhv+83u1Ivi08Dm79ChJS4ZP+sH6G24mkElLRi8hpCQoM4L/Xt+Hi5tV5bvxyRs7Z5HYk3xYR75R9XD0YeT1snOV2IqlkVPQictqCAwN4vX87zm9SjafGLuHz9M1uR/JtkVXh1nEQXQv+1w82z3M7kVQiKnoROSMhQQG8eVM7zmuYyBNfLOarX7a4Hcm3RVWH28Y7pf/xNbBlgduJpJJQ0YvIGQsLDmTYLR3onJLAo6MWMWHxNrcj+bbomk7Zh8fCR1fBtsVuJ5JKQEUvImclPCSQd2/rQNs6sTz06UK+W7bd7Ui+LSbJKfuQSBhxBexY7nYi8XI+VfTGmL7GmGE5OTluRxHxK1VCg/jgjo60qB3D4JELmLIyy+1Ivi2uHtw+3tkjf8TlsHOV24nEi/lU0WtnPBH3RIUF8+GdaTSuEcU9H89nxpqdbkfybfH1nZG9CYAP+8IubWIkZfOpohcRd8WEB/PRnZ2on1iFASPSmb0u2+1Ivi2xobMav6jQKfvd2sRIfk9FLyLlKq5KCB/f3Yk6cRHcOXwe6Rt2ux3Jt1VrAreNg4Jc59S7wny3E4mXUdGLSLlLjAzlfwM6USM6jNs/mMcvm/e6Hcm3VW8OV70F2Rmw8CO304iXUdGLiEdUiwpj5IDOxFcJ4db35rB0ixbJelTDi6BOZ5j2T8g/7HYa8SIqehHxmBoxYYwc0ImosGBufm8OK7fvczuS7zIGej0D+7fBvHfdTiNeREUvIh6VFBfBJwM6ExYUyE3vzCEja7/bkXxX8rnQoBfM+Dfk6kOVOFT0IuJxdRMiGDmgEwEBhhvfmcP6XQfdjuS7ev0FDu+G2W+6nUS8hIpeRCpE/aqRjLy7E4VFlhvfmc2q7RrZe0StttD0cpj5BhzU6Y2ioheRCtSwehQf392JvIIiLnttBi9PWsmhIwVux/I9Pf8M+Qfh5/+4nUS8wBkVvTEm1hjz5/IOIyK+r2nNaL5/pBtXt6vNW9PWcsEr0/h22XastW5H8x3VmkCr62HuO7Bvq9tpxGUnLHpjTB1jzDBjzNfGmLuNMVWMMa8Aq4FqFRNRRHxNQmQo/7y2NaMHdSE6PJh7PprPncPnsSn7kNvRfEePJ50d86b/y+0k4rKTjehHAFuB14HmQDpQC2hlrX3Iw9lOmy5qI1K5dEiO5+sHuvL0ZU2Zu343F/5nGq/9sIa8gkK3o1V+ccnQ/jZYMEJb4/o5c6LpMmPMImtt61I/ZwJ1rbVFFRHuTHXo0MGmp6e7HUNETsP2nFyen7CcCYu3kZJYhb9d0ZzzGlZ1O1bltn87vNoGml0OVw9zO414kDFmvrW2Q1mPnfQYvTEmzhgTb4yJB7KBmFI/i4iUixoxYQy5sR0j7kwD4Jb35jJ45AK25+S6nKwSi6oBnQbC4lG6br0fO9mIfgNQBJgyHrbW2voeynVWNKIXqdzyCgoZNm0db0zJICjA8MiFjbj9nGSCAnWi0Gk7tBtebQ0p3eCG/7mdRjzkjEf01tpka219a21KGTevLHkRqfxCgwJ5oFdDvn+kO2kp8bwwYQV9Xv9JV8I7ExHxcM4DsPJr2DLf7TTigpOtur+51PfnHvPY/Z4KJSICzo5679/ekbdubs++w/lc+9Ysnhi9iN0Hj7gdrXLpfC9EJMAPz7udRFxwsnmwR0t9//oxj91ZzllERH7HGEPvFjWY/Fh3BnVvwJgFWzj/lamMnLOJoiKde39KQqPgvMdg3RRYP93tNFLBTlb05jjfl/WziIjHRIQE8eQlTZj00Hk0rh7FU2OXcPXQmbr87anqcBdE13ZG9dqcyK+crOjtcb4v62cREY9rWD2KTwd25j/XtyZzzyEuf+Mnnhu3jH25+W5H827BYdD9CcicC6u/dTuNVKCTrbo/BGTgjN4bFH9P8c/1rbVVPJ7wDGjVvYh/yDmczyvfreKj2RtJjAzlxatacmGz6m7H8l6F+fBGRwipAvfMgACdxeArzuY8+qZAX6BPqe9Lfm5WniFFRE5XTHgwf7uiBeMGd6VqZCgPfLKAzD3aRve4AoOdC97sWArLxridRirIyU6v23jsDTgIbCr+XkTEdS2TYnjntg4YDH8br41hTqjFNVCtOUz5uzPCF593stPrOhtjphpjxhhj2hpjlgJLgR3GmN4VE1FE5ORqx4bzQK9Uvlu+gykrs9yO470CAuD8p539738Z6XYaqQAnm7p/A3gR+AT4EbjbWlsD6Aa85OFsIiKn5e6u9WlQtQrPjltGbr4ujHNcjS+B2h1g2j8gX1sM+7qTFX2QtfY7a+3nwHZr7WwAa+1Kz0cTETk9IUEBPH9FCzbtPsTQqWvdjuO9jIFez8C+LZD+vttpxMNOVvSlr1J3+JjHdHqdiHidc1IT6du6FkOnrWVj9kG343iv+t0hpTvMeAXy9lfc+1rrnN6nS+dWmJMVfWtjzD5jzH6gVfH3JT+3rIB8IiKn7enLmhISGMCz45ZxolOI/V6vZ+DQLpj9VsW836Hd8PltMPI6GHk9FORVzPv6uZOtug+01kZba6OstUHF35f8HFxRIUVETkf16DAevqAhU1ft5NtlO9yO472SOkDjy2Dma04Je9L66fBWV1g5AdreDLtWO7MJ4nHaLUFEfNLt5yTTpEYUfxu/jENHCtyO473O/7MzdT/zNc+8fsER+P5Z+PByCA6HuyfDFUOg5XUw49+QtcIz7yu/8qmiN8b0NcYMy8nR3tci/i4oMIDnr2zB1pxcXv8x4+S/4K+qN4eW1zrT9/vLefZj1xp470L4+b/Q/ja4ZzrUaus81vsl52I74x+CoqITv46cFZ8qemvteGvtwJiYGLejiIgX6JgczzXtknh3xjoysg64Hcd79fgTFB6BGf9XPq9nLcwfDm93g70b4fqPoe+rzta7JaokwsUvwuY5kP5e+byvlMmnil5E5Fh/urQJ4cGBPPPVUi3MO56EBtDuFkj/APac5aanh3bDZzc7I/U6aXDvLGjat+zntr4B6veEyX+FnC1n975yXCp6EfFpiZGhPH5xY2auzWb84m1ux/Fe3Z4AE+BsonOm1k6Boec4p89d9ALcPBaiax7/+cZAn/9AUQFMfFyXz/UQFb2I+LwbO9WjZe0YXvh6Oft1OduyxdSGtAGw6BPYuer0frcgD757Gj660jnuPuBHOOeBU7s6XnwK9PwTrJoAK8adWXY5IRW9iPi8wADD81e2YOeBPP47eY3bcbxX10cgOMK54M2p2rkK3r0AZr4OHe6CgdOgZqvTe9/Og6FGK5j4BBzee3q/KyelohcRv9CmTiw3dKzL8JkbWLl9n9txvFOVROgyGJZ/BVsXnvi51sK89+Dt7s5Wuv0/hT7/hpCI03/fwCC4/DU4mAWTnzuj6HJ8KnoR8RtPXNyY6LAg/vKlFuYdV5fBEB4HP75w/Occ3AWf3ggTHoV6XeDemc6Fcs5GrbbQ+T6Y/wFsnHl2ryW/oaIXEb8RVyWEJy9pwrwNe/higVZ5lyksxpnCz5gMG37+/eMZPzgL7jImQ++X4aYvIKpG+bx3z6cgtq6zYl/b45YbFb2I+JV+7evQrm4sL01cQc4hLcwrU8cBEFkDfnz+6Er4/Fz45in4+GoIj4cBU6Dzvae24O5UhVSBPv/V9rjlTEUvIn4loHhh3p5DR/i/705zdbm/CImA7o/DplnOyD1rBbzbC2YPgbSBMHAK1GjhmfdO7QWtrtf2uOVIRS8ifqd5rRhu7ZLMx3M2siRTW2aXqe2txdPoD8OwHnBgB9z4OVz6L2fPek+6+EVtj1uOVPQi4pcevagRCVVCefqrpRQVaWHe7wSFQM+nYV8mpHRzFtw1uqhi3rtKorMXvrbHLRcqehHxS9Fhwfz5siYs2ryXT+dtdjuOd2p9PQyeBzeOgshqFfvera7X9rjlREUvIn7ryja16ZQSzz+/Xcnug0fcjuOdqjZytqqtaNoet9yo6EXEbxnjLMw7kFvAPyatdDuOHCs+xTnlTtvjnhUVvYj4tUbVo7izawqfpW9m/sY9bseRY3W+D2q2dkb12h73jKjoRcTvPdSrITWiw/jLl0spKNQqb68SGAR9X4ODO2Hys26nqZRU9CLi96qEBvGXPs1Yvm0fH88+y+uxS/mr1aZ4e9zhZe/WJyekohcRAS5tWYPzGibyynerydqf63YcOVbp7XHz9d/ndKjoRURwFub99fLm5BUU8dJELczzOiXb42av0fa4p0lFLyJSrH7VSAZ2q8/YhVuYvS7b7ThyrJLtcX/6j7bHPQ0qehGRUgb3TKV2bDjPfLWUfC3M8z4l2+OOe1Db454iFb2ISCnhIYE8d3lzVu84wAc/r3c7jhyrZHvczLnaHvcUqehFRI5xYbPq9GpSjf9OXsO2nMNux5FjaXvc06KiFxEpw3OXN6ewyPLC1zoW7HV+sz3uH7Q97kmo6EVEylAnPoLBPVOZsGQbQ6eudTuOHOvX7XEnwvKv3E7j1by+6I0xVxpj3jHGfGaMqaBrJIqIwL09GnB561r845uV/Pu7VViNHL1Lyfa4k56Aw9q++Hg8WvTGmPeNMVnGmKXH3N/bGLPKGJNhjHnyRK9hrf3SWjsAGARc78m8IiKlBQcG8J/r23BdhyRe+zGDv09YobL3Jr9uj7sLvtf2uMcT5OHXHw68AYwoucMYEwgMAS4EMoF5xphxQCDw0jG/f6e1Nqv4+6eLf09EpMIEBhhevroVESFBvPvTeg7nF/L8FS0ICHDh0q3ye7XaQJf7YObr0Oo6SO7qdiKv49Git9ZON8YkH3N3GpBhrV0HYIz5FLjCWvsS0OfY1zDGGOBlYJK1doEn84qIlCUgwPBs32aEBQfy1rS1HM4v5J/XtCIo0OuPfvqHHk/B8nHw9SNw3xwI0H+X0tz416gNbC71c2bxfcfzAHABcK0xZtDxnmSMGWiMSTfGpO/cubN8koqIFDPG8MfejXnswkaMWbCFhz79hSMF2rDFK4REQK9nYNdqWD/V7TRex9NT92fNWvsa8NopPG8YMAygQ4cOOogmIuXOGMMDvRoSHhLICxNWcDi/kDdvakdYcKDb0aRJHwiPgwUjoMH5bqfxKm6M6LcAdUr9nFR8n4hIpXD3efV54coW/Lgyi7s+nMehIwVuR5LgMGjdH1Z87SzOk1+5UfTzgIbGmBRjTAhwAzDOhRwiImfs5s71eKVfa2atzebW9+ayLzff7UjS9hYoyodFn7qdxKt4+vS6T4BZQGNjTKYx5i5rbQFwP/AtsAIYZa1d5skcIiKecE37JF7v345fNu/lpnfmsOfgEbcj+bfqzSCpozN9r9Mgf+XRorfW9rfW1rTWBltrk6y17xXfP9Fa28ha28Ba+/fyej9jTF9jzLCcnJzyekkRkRO6rFVN3r6lPat27OeGYbPJ2p/rdiT/1u422LUKNs9xO4nX8KlzEKy14621A2NiYtyOIiJ+pFfT6rx/W0c27T7EDW/P1oVw3NT8KgiJdEb1AvhY0YuIuKVrw0RG3JVG1v48+r01i03Zh9yO5J9CI6HltbB0DORqdhdU9CIi5aZjcjwjB3TiQF4B/d6eSUbWAbcj+ad2t0LBYVgy2u0kXkFFLyJSjlolxfLpwM4UFlmuf3sWK7btczuS/6nVDqq3hAUfup3EK/hU0Wsxnoh4gyY1ovnsni4EBwZww7DZ/LJ5r9uR/Isxzqh+2yLY+ovbaVznU0WvxXgi4i0aVI3k80FdiA4P4uZ35zB3/W63I/mXVv0gKAwWfuR2Etf5VNGLiHiTOvERjLqnC9WiQ7n1/TnMWKPrcFSY8DhodgUs/hyO+PfCSBW9iIgH1YwJ57OBXUhOqMJdw9OZvHyH25H8R7tbIS8Hln/ldhJXqehFRDysalQonw7sTNOaUQz6eD7jF211O5J/qHcuxDfw+0V5KnoRkQoQGxHCx3d3om3dWB76dCE/rtTI3uNKFuVtmgU7V7udxjU+VfRadS8i3iwqLJgP70yjWlQYo+dnuh3HP7S5EQKC/HpU71NFr1X3IuLtIkKCOKdBAnPX78bqwiueF1kNGl8Ciz6BAv+86JBPFb2ISGWQlhLPrgNHWLfroNtR/EO72+FQNqya4HYSV6joRUQqWFpKPIDOra8oDXpCdJLfXuhGRS8iUsFSEquQGBnKnHXZbkfxDwGB0PZmWDsF9mx0O02FU9GLiFQwYwydUuKZo+P0Faftzc7XhR+7m8MFKnoRERd0qh/PtpxcMvfo2vUVIrYOpPZyir6o0O00Fcqnil6n14lIZaHj9C5odxvs3woZk91OUqF8quh1ep2IVBaNqkUREx6soq9IjXpDlap+tyjPp4peRKSyCAgwdEyOZ+4GFX2FCQpxNtBZNQn2b3c7TYVR0YuIuKRTSjzrdx0ka1+u21H8R9tbwRbCLyPdTlJhVPQiIi4pOU4/R9P3FScxFep1dabv/eSMBxW9iIhLmteKpkpIoI7TV7R2t8Ke9bBhhttJKoSKXkTEJUGBAbRPjlfRV7Rml0NYjN8sylPRi4i4qFNKPKt27GfPQf+84IorgsOh1fWwfBwc8v0PWT5V9DqPXkQqm5Lj9PO0+r5itbsVCvNg8Si3k3icTxW9zqMXkcqmVVIMIUEBmr6vaDVaQq12znXqfXxRnk8VvYhIZRMaFEjbOrE6n94N7W6FrOWwZb7bSTxKRS8i4rJOKfEs3ZLD/tx8t6P4l5bXQnAVZ1Tvw1T0IiIuS0tJoMjC/I173I7iX0KjoMVVsOQLyNvvdhqPUdGLiLisXb1YggKMjtO7od3tkH8Qlo5xO4nHqOhFRFwWERJEy6QYFb0bkjpA1aY+PX2vohcR8QJpKfEsytxLbr5/XSvddcY4i/K2zIftS91O4xEqehERL9ApJZ78QsvCTXvdjuJ/Wt8AgSE+u1Oeil5ExAu0rxePMWj63g0R8dC0Lyz+FPIPu52m3PlU0WtnPBGprGLCg2laI5q5G7LdjuKf2t0GuTmwYrzbScqdTxW9dsYTkcosLSWe+Rv3cKSgyO0o/if5PIhL9snpe58qehGRyqxTSjy5+UUs2aJZyQoXEOAsytswA7LXup2mXKnoRUS8RMkFbnSc3iWtbwQT6HOjehW9iIiXSIgMJbVaJHPX6zi9K6JrQqOL4ZeRUOg72xGr6EVEvEhaSjzpG/ZQWOTbV1TzWu1ug4NZsPobt5OUGxW9iIgX6ZQSz/68AlZs2+d2FP+UegFE1fSp6XsVvYiIF+mYrOP0rgoMgrY3Q8ZkyMl0O025UNGLiHiRWrHh1IkPZ46O07un7c1gi2Dh/9xOUi5U9CIiXiYtOYG563djrY7TuyIuGer3hIUfQVHlv/aAil5ExMt0qh/PnkP5ZGQdcDuK/2p3K+RshnVT3E5y1lT0IiJeplPx+fRzdJzePU0ug4gEn1iUp6IXEfEydeMjqB4dqgV5bgoKhdb9YeVEOLDT7TRnxaeKXhe1ERFfYIwhLUXH6V3X7lYoyocFH7qd5Kz4VNHrojYi4ivSUuLZvi+Xzbt977KplUbVxlC/B6S/X6l3yvOpohcR8RUlx+ln6zQ7d3UaBPu2wMqv3U5yxlT0IiJeKLVqJHERwTpO77aGFzmn28152+0kZ0xFLyLihQICDGkp8Sp6twUEQtpA2DQLtv7idpozoqIXEfFSaSkJbNp9iG05Ok7vqjY3QXAVmDvM7SRnREUvIuKlOun69N4hPBba9Icln1fKU+1U9CIiXqppzWgiQ4NU9N4gbSAUHoEFw91OctpU9CIiXiowwNAhOU5F7w2qNoYG58O89yrdqXYqehERL5aWEs+arANkH8hzO4p0GgT7t8GKcW4nOS0qehERL1ZynH7eBo3qXZd6IcSlVLpT7VT0IiJerGXtWMKCA3SBG28QEACd7oHNc2DLArfTnDIVvYiIFwsJCqBdXR2n9xptboSQyEp1qp2KXkTEy6WlxLN82z725VauRWA+KSzGKfulX8CBLLfTnBIVvYiIl0tLicdamL9hj9tRBI6eajd/uNtJTomKXkTEy7WtE0dwoNFxem+R2BBSL3BOtSs44naak1LRi4h4ufCQQFolxTJXV7LzHp0GwYHtleJUOxW9iEglkJYSz+LMHA4dKajQ983NL6zQ96s0GvSChFSYPdTtJCelohcRqQQ6pcRTUGRZuGlvhb3npCXbaP3X7/h++Y4Ke89KIyAA0u6BLemQme52mhPyqaI3xvQ1xgzLyclxO4qISLlqXy+OAEOFHafP2p/LU2OXkFdQxJ/GLNbOfGVp0x9Corx+Ax2fKnpr7Xhr7cCYmBi3o4iIlKuosGCa14qpkOP01lqeGrOEg0cKGXJjO/YdLuDpL5dirfX4e1cqoVHQ9mZYNhb2b3c7zXH5VNGLiPiytJR4Fm7aS16BZ4+bj56fyeQVWTxxcWMua1WTRy9qxKSl2xm3aKtH37dSShsARQWQ/oHbSY5LRS8iUkmkpcSTV1DEkkzPHZ7csvcwfxu/nLSUeO48NwWAAefVp329OP7y5VK25+R67L0rpYQG0PAiSH8fCrzz8IaKXkSkkuiY7FzgxlPH6YuKLI9/vohCa3mlX2sCAgzgXC73lX6t2YH/XwAAC3lJREFUyS+0/PGLxZrCP1ane+BgFiz70u0kZVLRi4hUEvFVQmhUPdJjRf/R7I3MXJvN05c1o058xG8eS06swp8ubcK01Tv5ZO5mj7x/pdXgfEhsBHOGghd+CFLRi4hUIp1SEpi/YTcFhUXl+rrrdx3kpUkr6P7/7d19kFV1Hcfx93fv7rLLAgu78qCwwkWeBRYUF410TKnwAbQSklEr0zQny4pMs6wmtRlRsydHY8xqRkfFlQyFMisdJ0cFUdZdFkjkcVeEVVpAQBbYb3/cpYBgBfbe+7vn8HnN7Ax7uXvOZ37A/XDO7/zOGdKT6VUVB33P5eP7M2FQObfPq2ft+9vTuv9IM0vdFvedN3JyqZ2KXkQkQqqSZWxr2UP9+i1p2+aeVmfG7MUUJvK483OjMbODvi8vz5h5SSUJM75TXUNra+4dvQZTOR06dYNXHwid5P+o6EVEIqQqmZqnT+dja2e9uJLX1zZz28Uj6VNa1O57+3Yv5oeTR7Bg1SYeemlV2jJEXqcuMPYKqH8KtqwPnWY/KnoRkQjp3a2IAeWd0zZPv+zdLdz73L84b2QfplSecFg/c8mp/Zg4vDczn13Oio1b05IjFqquhtY9qSvwc4iKXkQkYqqSZSxcvanDp85bdrfy7cdr6Facz+0XjzzkKfsDmRk//exISgoTzJhdk/brBSKrbCAMmZRzS+1U9CIiEVOVLKd5+y7e2vhBh7bz63+8Rf36LdzxmVGUd+l0RD/bq2sRt188ipqGzdz/wtsdyhEr46+F7e9B3ZzQSf5LRS8iEjHjk3vX0x/97XBr1jVz3wtv89lT+vLpk/sc1TYuGH08UypP4Bd/f4u6Rj1jBICBZ8NxQ1MX5eXIUjsVvYhIxPTrUcwJpUVHPU//4a49fHv2Ynp17cSPJp/coSw/uehkykoKmTG7JuO35o0Es9RR/frFsG5B6DSAil5EJHLMjKpkGQtWbTqqu9Td9exy3m7axsxLRlNaXNChLN07F3Ln50azfMNW7n3urQ5tKzYqL4VOpTmz1E5FLyISQVXJcpq27mT1Ed645pWV7/PQS6u44vT+nDm4Z1qyfGJYLy49rYJZL77NojXZeYxuTissgVOugPo/webG0GlU9CIiUfS/9fSHP0//wc7dfOeJGk4s68z3zh+W1jzfv2A4x5cWM2N2Ddtbdqd125FU9RXw1pxYaqeiFxGJoJN6llBeUnhE8/R3zFtKY/MO7plaSefC/LTm6VpUwN1TK1n9/nbu/POytG47knoMgKHnw6Lfwa6wT/xT0YuIRNC+8/SH4/nlG3l0wVquOXMg49qegpduZ5xUzpUTBvCHl9fw0or3MrKPSBl/LWx/H+qqg8ZQ0YuIRFRVsoyGf++gsXlHu+9r3t7CTdVvMqR3F771ySEZzXTTpGEM7FnCjU/UsOXDXRndV85LngU9hwdfaqeiFxGJqMOdp//R3CVs2tbCPVPHUFSQyGimooIE90yt5N0tH3Lb0/UZ3VfO27vU7t1aWPtysBgqehGRiBrWpxvdivLbPX0/v3Y9f1r8DtefM4hR/UqzkmvsiT247uyTeGJRA3+r35CVfeas0dOgqHvQpXYqehGRiErkGacNKDvkBXlNW3fyg6fqGNW3lK99YlBWs91w7hCG9enKzXNq2bStJav7zimFJXDKF2DpM9C8LkgEFb2ISIRVJctY2bSNpq37P0TF3bnlj7V8sHM3P5tWSUEiux/3hfl53Pv5MWze0cKtT9Ud1Y19YuO0qwGH134bZPcqehGRCNs7T79w9f5H9XNeb+S5+g3c+KmhDO7dNUQ0hh/fjW9OHMK82vU8/WZuPaM9q3r0b1tq93vY1f6Fk5mgohcRibCRfUspLkjsN0//TvMOfjx3CVUDyvjyx5MB08G1Zw1kTEV3bn2qjg1bwq4nD+r062DHv6H2iazvWkUvIhJhBYk8Tu3fg1dWpq68d3e+W/0me9y5a+poEnmH94z5TMlP5HHPtEp27t7DzU++eeyewu8/AXqPhFd/k/Wldjlf9GY23MweMLNqM7sudB4RkVxTlSxj+YatNG9v4eFX1vDPFe9xy/nD6V9eEjoaACf17MJNk4bx/PImHl8Y5oK04PYutdtQB2teyuquM1r0ZvaQmW00s7oDXp9kZsvNbIWZ3dzeNtx9qbt/FZgGTMhkXhGRKBqfLMMdqhc18NP5yzhz8HFcNv7E0LH288UzBnDGwHJue6aedZuO7EE8sTFqKhT3yPpSu0wf0f8emLTvC2aWAO4DzgNGANPNbISZjTKzZw746tX2M1OAecD8DOcVEYmcyoruFCbyuGP+UvITxsxLRmMW9pT9gfLy/pfrxuoaWluPwVP4BcVw6pdg2TxoXpu13Wa06N39ReDABZ5VwAp3X+nuLcBjwEXuXuvuFx7wtbFtO3Pd/TzgskzmFRGJoqKCBGMquuMOP7noZI4vLQ4d6aAqyjpz64XDeWXlJh47Vk/hj7sKMFj4YNZ2GWKOvi+w759wQ9trB2VmZ5vZL83sN7RzRG9m15jZa2b2WlNTU/rSiohEwDVnDeQb5wzi4jGH/DjNCdPGVVBWUkht4+bQUcLoXgFjL4PC7C15TO9zCjPA3V8AXjiM980CZgGMGzfuGDwnJCLHsokjejNxRO/QMT6SmQVfCRDclF9ldXchjugbgYp9vu/X9pqIiIikWYiiXwgMNrOkmRUClwJzA+QQERGJvUwvr3sUeBkYamYNZnaVu+8GrgeeBZYCs919SSZziIiIHKsyOkfv7tMP8fp8MrBUzswmA5MHDcruU5pERERyVc7fGe9IuPvT7n5NaWl2nrksIiKS62JV9CIiIrI/Fb2IiEiMqehFRERiLFZFb2aTzWzW5s3H6B2XREREDhCrotfFeCIiIvuLVdGLiIjI/lT0IiIiMaaiFxGRAPTssWwx9/gNtpk1AWvSuMnjgPfSuD1J0bimn8Y0/TSmmaFxTa/+7t7zYL8Ry6JPNzN7zd3Hhc4RNxrX9NOYpp/GNDM0rtmjU/ciIiIxpqIXERGJMRX94ZkVOkBMaVzTT2OafhrTzNC4Zonm6EVERGJMR/QiIiIxpqL/CGY2ycyWm9kKM7s5dJ6oM7MKM3vezOrNbImZ3RA6U1yYWcLM3jCzZ0JniQsz625m1Wa2zMyWmtkZoTNFnZl9q+3ffp2ZPWpmRaEzxZ2Kvh1mlgDuA84DRgDTzWxE2FSRtxuY4e4jgNOBr2lM0+YGYGnoEDHzC+Av7j4MqETj2yFm1hf4BjDO3UcCCeDSsKniT0XfvipghbuvdPcW4DHgosCZIs3d17v7622/3krqg7Nv2FTRZ2b9gAuAB0NniQszKwXOAn4L4O4t7t4cNlUs5APFZpYPdAbeCZwn9lT07esLrNvn+wZUSmljZgOAscCrYZPEws+B7wKtoYPESBJoAn7XNiXyoJmVhA4VZe7eCNwNrAXWA5vd/a9hU8Wfil6CMLMuwJPAN919S+g8UWZmFwIb3X1R6Cwxkw+cAtzv7mOBbYCu0+kAM+tB6qxoEjgBKDGzy8Omij8VffsagYp9vu/X9pp0gJkVkCr5R9x9Tug8MTABmGJmq0lNL51jZg+HjRQLDUCDu+8941RNqvjl6E0EVrl7k7vvAuYAHwucKfZU9O1bCAw2s6SZFZK6aGRu4EyRZmZGas5zqbv/LHSeOHD377l7P3cfQOrv6D/cXUdJHeTu7wLrzGxo20vnAvUBI8XBWuB0M+vc9llwLrrAMePyQwfIZe6+28yuB54ldXXoQ+6+JHCsqJsAXAHUmtnittducff5ATOJHMrXgUfa/qO/ErgycJ5Ic/dXzawaeJ3UCpw30B3yMk53xhMREYkxnboXERGJMRW9iIhIjKnoRUREYkxFLyIiEmMqehERkRhT0YuIiMSYil5ERCTGVPQiIiIx9h8Hom/+rHaG3AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}