{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MainModelKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamviji/project/blob/master/MainModelKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku11kjUKaO8X"
      },
      "source": [
        "Note:To Checkin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDSPPMfZ9czi",
        "outputId": "832c2909-5b3f-4f3d-e8f8-30eed6a0a6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "!rm -rf project\n",
        "!git clone https://github.com/iamviji/project.git\n",
        "!ls\n",
        "!ls project\n",
        "!pip install pyldpc\n",
        "!pip install scikit-commpy\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'project'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 119 (delta 47), reused 16 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (119/119), 1.80 MiB | 2.45 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "ldpc_ber_18_11.png  project  sample_data\n",
            "MainModel.ipynb\t\t    MainModelOneHotMethod.ipynb\t\t  README.md\n",
            "MainModelKeras.ipynb\t    MainModelOneHotMethodSoftMax.ipynb\t  util.py\n",
            "MainModelKerasOneHot.ipynb  MainModelWithSingleBERTraining.ipynb\n",
            "Requirement already satisfied: pyldpc in /usr/local/lib/python3.6/dist-packages (0.7.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyldpc) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from pyldpc) (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyldpc) (1.18.5)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->pyldpc) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->pyldpc) (50.3.0)\n",
            "Requirement already satisfied: scikit-commpy in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from scikit-commpy) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit-commpy) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->scikit-commpy) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QOuLqpdDgx2"
      },
      "source": [
        "import pyldpc\n",
        "import commpy\n",
        "import numpy \n",
        "import time\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior ()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YClXJbbr0lc7"
      },
      "source": [
        "SNR_BEGIN = 0\n",
        "SNR_END = 10\n",
        "SNR_STEP_SIZE = 0.5\n",
        "CHANEL_SIZE = 18\n",
        "NUM_OF_INPUT_MESSAGE = 1000\n",
        "LDPC_MAX_ITER = 100\n",
        "num_parity_check = 3\n",
        "num_bits_in_parity_check = 6 \n",
        "input_message_length =  0 # Caculated by channel encoder and initialized later"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvUzIMsB43i0"
      },
      "source": [
        "def timer_update(i,current,time_tot,tic_incr=500):\n",
        "    last = current\n",
        "    current = time.time()\n",
        "    t_diff = current-last\n",
        "    print('SNR: {:04.3f} - Iter: {} - Last {} iterations took {:03.2f}s'.format(snr,i+1,tic_incr,t_diff))\n",
        "    return time_tot + t_diff\n",
        "\n",
        "def Snr2Sigma(snr):\n",
        "  sigma = 10 ** (- snr / 20)\n",
        "  return sigma\n",
        "\n",
        "def pyldpc_encode (CodingMatrix, message):\n",
        "  rng = pyldpc.utils.check_random_state(seed=None)\n",
        "  d = pyldpc.utils.binaryproduct(CodingMatrix, message)\n",
        "  encoded_message = (-1) ** d\n",
        "  return encoded_message\n",
        "\n",
        "def pyldpc_decode (ParityCheckMatrix, CodingMatrix, message, snr, maxiter):\n",
        "  decoded_msg = pyldpc.decode(ParityCheckMatrix, message, snr, maxiter)\n",
        "  out_message = pyldpc.get_message(CodingMatrix, decoded_msg)\n",
        "  return out_message\n",
        "\n",
        "awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "init = tf.global_variables_initializer ()\n",
        "sess = tf.Session ()\n",
        "sess.run(init)\n",
        "\n",
        "def AWGNChannelOutput (xx, snr , s):\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  awgn_channel_output_message = s.run ([awgn_channel_output], feed_dict={noise_std_dev:sigma, channel_input:xx})\n",
        "  return awgn_channel_output_message"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jMQG-MZ_pXu",
        "outputId": "0672e9aa-c948-467e-9459-49bc3c445b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "ParityCheckMatrix, CodingMatrix = pyldpc.make_ldpc(CHANEL_SIZE, num_parity_check, num_bits_in_parity_check, systematic=True, sparse=True)\n",
        "input_message_length = CodingMatrix.shape[1]\n",
        "print (\"input_message_size=\", input_message_length, \"channel_size=\",CHANEL_SIZE)\n",
        "print (\"input_message_size=\", CodingMatrix.shape[1], \"channel_size=\",CodingMatrix.shape[0])\n",
        "input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE,input_message_length))\n",
        "print (input_message)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_message_size= 11 channel_size= 18\n",
            "input_message_size= 11 channel_size= 18\n",
            "[[0 1 1 ... 0 1 1]\n",
            " [1 1 1 ... 0 1 0]\n",
            " [0 1 1 ... 1 1 0]\n",
            " ...\n",
            " [1 0 1 ... 1 0 0]\n",
            " [0 1 1 ... 0 1 0]\n",
            " [1 1 0 ... 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WKg2HU2adgZ"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fL8ptL4aeOY"
      },
      "source": [
        "This section tries to compare BER and Time performance of PYLDPC in following 3 cases\n",
        "1. SNR Noise function provided in encoder function of pyldpc library (pyldpc.encode)\n",
        "2. SNR Noise function provided by commpy library (commpy.channels.awgn) \n",
        "3. SNR Noise function implemented using tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma5zUqFv0TH2",
        "outputId": "65651884-2f03-4fff-a8a9-9ff75dda7aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using tensor flow based AWGN, to make sure that effect of it is same as AWGN\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_tensor  = numpy.array(())\n",
        "times_per_iter_tensor = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc_encode (CodingMatrix, input_message[i])\n",
        "    sigma = Snr2Sigma (snr)\n",
        "    awgn_channel_output_message = sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message})[0]\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      #print (\"count=\",abs(decoded_message-input_message[i]).sum())\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_tensor=numpy.append(ber_per_iter_tensor ,ber)\n",
        "  times_per_iter_tensor=numpy.append(times_per_iter_tensor, total_time)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.59s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.24s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 4.65s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 6.20s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.62\n",
            " -> Total Time: 15.68s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.30s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.66s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 3.88s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 5.29s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.56\n",
            " -> Total Time: 13.12s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.14s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 2.33s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 3.52s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 4.55s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.53\n",
            " -> Total Time: 11.53s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.76s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.61s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.38s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 3.35s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.39\n",
            " -> Total Time: 8.10s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.79s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.52s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 2.33s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.97s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.32\n",
            " -> Total Time: 7.61s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.52s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.15s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.82s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.44s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.25\n",
            " -> Total Time: 5.93s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.47s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.01s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.56s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 2.05s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.19\n",
            " -> Total Time: 5.10s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.48s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.87s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.28s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.74s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.14\n",
            " -> Total Time: 4.37s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.40s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.80s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 1.17s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.53s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.11\n",
            " -> Total Time: 3.91s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.38s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.70s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 1.04s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 1.39s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.08\n",
            " -> Total Time: 3.51s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.32s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.66s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 0.95s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 1.24s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.06\n",
            " -> Total Time: 3.17s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.28s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.58s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.89s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 1.19s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 2.94s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.27s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.54s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.82s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 1.10s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 2.73s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.28s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.56s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 0.85s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 1.13s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 2.82s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.26s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.54s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.82s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 1.08s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 2.70s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.28s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.54s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.81s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 1.07s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.70s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.28s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.54s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.81s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 1.08s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.71s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.27s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.54s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.81s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 1.08s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.69s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.27s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.53s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.79s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 1.06s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.64s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.27s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.53s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.79s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 1.07s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 2.66s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8dIFLg76c7O",
        "outputId": "81e06a39-9a2b-4287-f66e-68d33835b04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using commpy based AWGN \n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_awgn  = numpy.array(())\n",
        "times_per_iter_awgn = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc_encode (CodingMatrix, input_message[i])\n",
        "    awgn_channel_output_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_awgn=numpy.append(ber_per_iter_awgn ,ber)\n",
        "  times_per_iter_awgn=numpy.append(times_per_iter_awgn, total_time)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.30s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 2.71s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 3.99s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 5.37s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.60\n",
            " -> Total Time: 13.37s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.36s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.34s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 3.57s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 4.74s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.55\n",
            " -> Total Time: 12.00s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 0.85s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 1.78s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 2.63s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 3.51s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.45\n",
            " -> Total Time: 8.77s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.73s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.45s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.22s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 2.94s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.38\n",
            " -> Total Time: 7.35s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.53s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.16s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.73s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.41s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.30\n",
            " -> Total Time: 5.83s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.51s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.02s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.57s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.12s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.26\n",
            " -> Total Time: 5.21s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.31s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 0.67s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.03s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 1.35s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.17\n",
            " -> Total Time: 3.36s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.31s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.71s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 0.98s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.28s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.12\n",
            " -> Total Time: 3.28s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.28s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.52s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 0.81s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.06s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.10\n",
            " -> Total Time: 2.66s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.46s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 0.70s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 0.93s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.07\n",
            " -> Total Time: 2.28s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.19s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.40s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 0.60s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 0.81s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 2.01s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.39s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.55s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 0.74s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 1.88s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.17s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.34s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.51s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 0.68s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.71s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.35s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 0.52s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 0.68s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.73s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.33s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.50s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 0.67s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.66s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.32s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.48s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 0.64s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.60s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.33s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.50s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 0.65s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.64s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.15s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.31s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.46s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 0.62s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.55s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.32s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.47s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 0.63s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.58s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.31s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.46s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 0.63s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ihPKJJk7Jj9",
        "outputId": "7f075e27-b29a-4857-af12-866aa77122c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using tensor flow based AWGN, to make sure that effect of it is same as AWGN\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_pyldpc  = numpy.array(())\n",
        "times_per_iter_pyldpc = numpy.array(())\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    encoded_message = pyldpc.encode (CodingMatrix, input_message[i], snr)\n",
        "    awgn_channel_output_message = encoded_message\n",
        "    decoded_message = pyldpc_decode(ParityCheckMatrix, CodingMatrix, awgn_channel_output_message, snr, LDPC_MAX_ITER)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_pyldpc=numpy.append(ber_per_iter_pyldpc ,ber)\n",
        "  times_per_iter_pyldpc=numpy.append(times_per_iter_pyldpc, total_time)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyldpc/decoder.py:63: UserWarning: Decoding stopped before convergence. You may want\n",
            "                       to increase maxiter\n",
            "  to increase maxiter\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 1.45s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 2.86s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 4.16s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 5.54s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.62\n",
            " -> Total Time: 14.01s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 1.18s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 2.28s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 3.47s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 4.61s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.56\n",
            " -> Total Time: 11.54s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 1.00s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 1.97s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 2.88s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 3.72s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.46\n",
            " -> Total Time: 9.58s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.63s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.36s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.10s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 2.85s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.41\n",
            " -> Total Time: 6.94s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.61s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.14s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.67s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.30s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.34\n",
            " -> Total Time: 5.72s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.55s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.05s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.60s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.11s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.25\n",
            " -> Total Time: 5.32s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.42s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 0.76s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.16s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 1.57s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.20\n",
            " -> Total Time: 3.92s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.29s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 0.67s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 0.97s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 1.25s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.12\n",
            " -> Total Time: 3.18s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.23s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 0.49s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 0.75s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 1.03s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.10\n",
            " -> Total Time: 2.49s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.24s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 0.48s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 0.70s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 0.92s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.07\n",
            " -> Total Time: 2.34s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.18s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 0.40s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 0.61s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 0.79s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 1.99s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.20s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 0.37s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 0.55s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 0.77s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 1.89s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 0.33s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 0.49s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 0.65s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.63s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.15s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 0.32s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 0.48s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 0.64s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.59s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.15s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 0.31s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 0.47s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 0.66s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 1.59s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.15s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 0.33s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 0.49s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 0.64s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.61s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 0.32s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 0.47s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 0.63s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.57s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.15s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 0.31s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 0.46s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 0.62s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.53s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.16s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 0.31s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 0.47s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 0.63s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.57s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.15s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 0.31s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 0.46s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 0.62s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 1.54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR4-FOJ-BkAG",
        "outputId": "0e87aaac-e91d-4fd7-99a3-7a35e0521fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# Compare 3 AWGN(Tensorflow, CommPy, PYLDPC) Simulation on LDPC\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_pyldpc,'', label=\"pyldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"tensor\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_awgn,'', label=\"commpy-awgn\") # plot BER vs SNR\n",
        "\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "ax2.set_xlabel('$E_b/$N_0$')\n",
        "ax2.set_ylabel('Decoding Time [s]')\n",
        "ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "            xy=(1, 0.35), xycoords='axes fraction',\n",
        "            xytext=(-20, 20), textcoords='offset pixels',\n",
        "            horizontalalignment='right',\n",
        "            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggY5VwudaRwR"
      },
      "source": [
        "<B>Conclussion:</B>\n",
        "      It proved that tensorflow behaves similar to AWGN noise channel provided by pyldpc, commpy. But tensor flow based one takes adds little more time delay. This need to be offseted if we are comparing performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOeuNfeLCgfb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior ()\n",
        "decoder_input_x = tf.placeholder(\"float32\", [None, input_message_length], name=\"decoder_input_x\")\n",
        "\n",
        "snr_std = 7.0\n",
        "\n",
        "input_message_x = Input(shape=(input_message_length,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "enc_layer1 = Dense(CHANEL_SIZE, activation='tanh')(input_message_x)\n",
        "#enc_layer2 = Dense(CHANEL_SIZE, activation='sigmoid')(enc_layer1)\n",
        "enc_layer2=enc_layer1\n",
        "#encoded2 = Dense(CHANEL_SIZE, activation='sigmoid')(encoded1)\n",
        "# this model maps an input to its encoded representation\n",
        "#enc_layer2 = BatchNormalization() (enc_layer2)\n",
        "enc_layer3 =  enc_layer2 / tf.sqrt(tf.reduce_mean(tf.square(enc_layer2)))\n",
        "#enc_layer2 = tf.round(enc_layer1)\n",
        "encoder = Model(input_message_x, enc_layer3)\n",
        "\n",
        "awgn_channel = GaussianNoise(Snr2Sigma(snr_std),input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(CHANEL_SIZE,))\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "dec_layer1 = Dense(CHANEL_SIZE, activation='tanh')(encoded_input)\n",
        "dec_layer2 = Dense(input_message_length, activation='sigmoid')(dec_layer1)\n",
        "# this model maps an encoded input to its decoder representation\n",
        "decoder = Model(encoded_input, dec_layer2)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "\n",
        "decoder_output = (tf.nn.sigmoid(decoder_input_x))\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgXpqxjrnJ-F",
        "outputId": "bea7720f-93a9-49c7-94a8-b72810f5d4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "print(autoencoder.summary())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_49\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 11)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 18)           216         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Square_1 (TensorFlo multiple             0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_1 (TensorFlowO multiple             0           tf_op_layer_Square_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sqrt_1 (TensorFlowO multiple             0           tf_op_layer_Mean_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv_1 (TensorFl multiple             0           dense_3[0][0]                    \n",
            "                                                                 tf_op_layer_Sqrt_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 216\n",
            "Trainable params: 216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"functional_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 18)]              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 18)                342       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 11)                209       \n",
            "=================================================================\n",
            "Total params: 551\n",
            "Trainable params: 551\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"functional_53\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 11)]              0         \n",
            "_________________________________________________________________\n",
            "functional_49 (Functional)   (None, 18)                216       \n",
            "_________________________________________________________________\n",
            "gaussian_noise_22 (GaussianN (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "functional_51 (Functional)   (None, 11)                551       \n",
            "=================================================================\n",
            "Total params: 767\n",
            "Trainable params: 767\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBl0pWc1oF_r",
        "outputId": "b3ea25f2-2487-4f78-d0cd-dd9eb317240c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "training_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))\n",
        "test_input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (test_input_message)\n",
        "print (len(test_input_message))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 0 1 0]\n",
            " ...\n",
            " [0 1 1 ... 1 1 1]\n",
            " [1 1 0 ... 1 1 1]\n",
            " [0 0 1 ... 0 1 1]]\n",
            "10000\n",
            "[[0 1 0 ... 1 0 0]\n",
            " [0 1 0 ... 1 0 0]\n",
            " [0 1 1 ... 0 1 0]\n",
            " ...\n",
            " [1 1 1 ... 0 1 1]\n",
            " [0 0 1 ... 0 1 0]\n",
            " [1 0 1 ... 1 1 1]]\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOXLOYLu8aML",
        "outputId": "a24e3be6-1d27-485b-fcff-514bd8c5c6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "\n",
        "#def custom_losff_fucntion (act, pred):\n",
        "#  return (tf.reduce_mean(-1*(act * tf.log(pred) + (1-act)*tf.log(1-pred))))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "#autoencoder.compile(optimizer=opt, loss=custom_losff_fucntion)\n",
        "#loss='mean_squared_error'\n",
        "#for snr in (numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)):\n",
        "for snr in (numpy.arange (0, 10, SNR_STEP_SIZE)):\n",
        "  sigma = 1.0*Snr2Sigma (snr)\n",
        "  snr_std = sigma\n",
        "  print (\"Training for SNR=\", snr, \" sigma=\", sigma) \n",
        "  awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  autoencoder.fit(training_input_message, training_input_message,\n",
        "                #epochs=50, original\n",
        "                epochs=20,\n",
        "                batch_size=500,\n",
        "                shuffle=False,\n",
        "                validation_data=(test_input_message, test_input_message))\n",
        "  \n",
        "  "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for SNR= 0.0  sigma= 1.0\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 37us/sample - loss: 0.7091 - val_loss: 0.6055\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.6109 - val_loss: 0.4960\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.5232 - val_loss: 0.4132\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.4678 - val_loss: 0.3539\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.4317 - val_loss: 0.3071\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.4048 - val_loss: 0.2703\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3814 - val_loss: 0.2394\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3638 - val_loss: 0.2128\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3504 - val_loss: 0.1907\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3360 - val_loss: 0.1718\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3261 - val_loss: 0.1569\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3191 - val_loss: 0.1447\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3124 - val_loss: 0.1357\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3076 - val_loss: 0.1277\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.3024 - val_loss: 0.1209\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2977 - val_loss: 0.1156\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2990 - val_loss: 0.1107\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2929 - val_loss: 0.1065\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2884 - val_loss: 0.1026\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2870 - val_loss: 0.0990\n",
            "Training for SNR= 0.5  sigma= 0.9440608762859234\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 39us/sample - loss: 0.2642 - val_loss: 0.0912\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2597 - val_loss: 0.0848\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2576 - val_loss: 0.0797\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2531 - val_loss: 0.0752\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2504 - val_loss: 0.0714\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2512 - val_loss: 0.0686\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2456 - val_loss: 0.0660\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2471 - val_loss: 0.0636\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2427 - val_loss: 0.0614\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2421 - val_loss: 0.0592\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2393 - val_loss: 0.0575\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2394 - val_loss: 0.0559\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2370 - val_loss: 0.0548\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2351 - val_loss: 0.0531\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2372 - val_loss: 0.0521\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2342 - val_loss: 0.0506\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2316 - val_loss: 0.0494\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2343 - val_loss: 0.0481\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.2333 - val_loss: 0.0476\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2334 - val_loss: 0.0470\n",
            "Training for SNR= 1.0  sigma= 0.8912509381337456\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 39us/sample - loss: 0.2078 - val_loss: 0.0430\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2065 - val_loss: 0.0402\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2076 - val_loss: 0.0381\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2014 - val_loss: 0.0364\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2054 - val_loss: 0.0351\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2038 - val_loss: 0.0343\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.2010 - val_loss: 0.0332\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2041 - val_loss: 0.0328\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2016 - val_loss: 0.0320\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2017 - val_loss: 0.0315\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.2032 - val_loss: 0.0310\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2003 - val_loss: 0.0304\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2008 - val_loss: 0.0301\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2044 - val_loss: 0.0297\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1982 - val_loss: 0.0292\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1980 - val_loss: 0.0285\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1992 - val_loss: 0.0281\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1976 - val_loss: 0.0276\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.2000 - val_loss: 0.0273\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1969 - val_loss: 0.0269\n",
            "Training for SNR= 1.5  sigma= 0.8413951416451951\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 42us/sample - loss: 0.1764 - val_loss: 0.0248\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1727 - val_loss: 0.0231\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1729 - val_loss: 0.0221\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1744 - val_loss: 0.0213\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1729 - val_loss: 0.0208\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1724 - val_loss: 0.0201\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1711 - val_loss: 0.0199\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1729 - val_loss: 0.0193\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1723 - val_loss: 0.0190\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1711 - val_loss: 0.0186\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1691 - val_loss: 0.0184\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1721 - val_loss: 0.0180\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1711 - val_loss: 0.0181\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1710 - val_loss: 0.0178\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1694 - val_loss: 0.0175\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1706 - val_loss: 0.0174\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1707 - val_loss: 0.0171\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1711 - val_loss: 0.0171\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1689 - val_loss: 0.0168\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1704 - val_loss: 0.0167\n",
            "Training for SNR= 2.0  sigma= 0.7943282347242815\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 43us/sample - loss: 0.1454 - val_loss: 0.0154\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1486 - val_loss: 0.0142\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1452 - val_loss: 0.0134\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1446 - val_loss: 0.0131\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1436 - val_loss: 0.0127\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1449 - val_loss: 0.0124\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1446 - val_loss: 0.0121\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1432 - val_loss: 0.0118\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1439 - val_loss: 0.0116\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1433 - val_loss: 0.0114\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1441 - val_loss: 0.0112\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1438 - val_loss: 0.0113\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1441 - val_loss: 0.0112\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1445 - val_loss: 0.0111\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1425 - val_loss: 0.0109\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1433 - val_loss: 0.0107\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1431 - val_loss: 0.0107\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1413 - val_loss: 0.0106\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1425 - val_loss: 0.0105\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1451 - val_loss: 0.0105\n",
            "Training for SNR= 2.5  sigma= 0.7498942093324559\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 44us/sample - loss: 0.1220 - val_loss: 0.0096\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1209 - val_loss: 0.0090\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1190 - val_loss: 0.0083\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1217 - val_loss: 0.0082\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1212 - val_loss: 0.0080\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1198 - val_loss: 0.0077\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1201 - val_loss: 0.0075\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1205 - val_loss: 0.0074\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1191 - val_loss: 0.0073\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1207 - val_loss: 0.0072\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1199 - val_loss: 0.0071\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1176 - val_loss: 0.0069\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1189 - val_loss: 0.0068\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1187 - val_loss: 0.0068\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.1175 - val_loss: 0.0066\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1198 - val_loss: 0.0067\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1184 - val_loss: 0.0065\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1183 - val_loss: 0.0065\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1192 - val_loss: 0.0066\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1179 - val_loss: 0.0064\n",
            "Training for SNR= 3.0  sigma= 0.7079457843841379\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 47us/sample - loss: 0.0985 - val_loss: 0.0059\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0996 - val_loss: 0.0055\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0983 - val_loss: 0.0051\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0966 - val_loss: 0.0050\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0971 - val_loss: 0.0048\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0969 - val_loss: 0.0047\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.1002 - val_loss: 0.0046\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0999 - val_loss: 0.0046\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0982 - val_loss: 0.0045\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0940 - val_loss: 0.0044\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0987 - val_loss: 0.0043\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0970 - val_loss: 0.0042\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0998 - val_loss: 0.0043\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0966 - val_loss: 0.0042\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0969 - val_loss: 0.0042\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0971 - val_loss: 0.0041\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0963 - val_loss: 0.0040\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1004 - val_loss: 0.0041\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.1002 - val_loss: 0.0041\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0970 - val_loss: 0.0040\n",
            "Training for SNR= 3.5  sigma= 0.6683439175686147\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 48us/sample - loss: 0.0794 - val_loss: 0.0038\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0789 - val_loss: 0.0035\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0789 - val_loss: 0.0033\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0774 - val_loss: 0.0031\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0789 - val_loss: 0.0031\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0788 - val_loss: 0.0030\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0805 - val_loss: 0.0029\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0776 - val_loss: 0.0028\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0772 - val_loss: 0.0027\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0777 - val_loss: 0.0027\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0772 - val_loss: 0.0026\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0762 - val_loss: 0.0026\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0772 - val_loss: 0.0025\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0772 - val_loss: 0.0025\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0777 - val_loss: 0.0025\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0808 - val_loss: 0.0025\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0767 - val_loss: 0.0025\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0769 - val_loss: 0.0024\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0780 - val_loss: 0.0024\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0765 - val_loss: 0.0024\n",
            "Training for SNR= 4.0  sigma= 0.6309573444801932\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 0s 49us/sample - loss: 0.0629 - val_loss: 0.0022\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0628 - val_loss: 0.0021\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0617 - val_loss: 0.0020\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0607 - val_loss: 0.0019\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0618 - val_loss: 0.0019\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0608 - val_loss: 0.0018\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0594 - val_loss: 0.0017\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0585 - val_loss: 0.0017\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0605 - val_loss: 0.0016\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0593 - val_loss: 0.0016\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0588 - val_loss: 0.0016\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0593 - val_loss: 0.0016\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0598 - val_loss: 0.0015\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0608 - val_loss: 0.0015\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0607 - val_loss: 0.0016\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0616 - val_loss: 0.0015\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0592 - val_loss: 0.0015\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0599 - val_loss: 0.0015\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0612 - val_loss: 0.0015\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0597 - val_loss: 0.0014\n",
            "Training for SNR= 4.5  sigma= 0.5956621435290105\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0464 - val_loss: 0.0014\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0458 - val_loss: 0.0012\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0450 - val_loss: 0.0012\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0471 - val_loss: 0.0011\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0478 - val_loss: 0.0011\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0465 - val_loss: 0.0011\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0458 - val_loss: 0.0011\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0471 - val_loss: 0.0010\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0472 - val_loss: 0.0010\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0453 - val_loss: 9.5905e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0466 - val_loss: 9.7010e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0450 - val_loss: 9.3908e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0450 - val_loss: 9.2575e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0462 - val_loss: 9.1418e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0460 - val_loss: 8.9837e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0454 - val_loss: 9.0100e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0463 - val_loss: 8.7915e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0449 - val_loss: 8.6508e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0457 - val_loss: 8.6498e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0451 - val_loss: 8.5885e-04\n",
            "Training for SNR= 5.0  sigma= 0.5623413251903491\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0339 - val_loss: 7.9200e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0349 - val_loss: 7.5416e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0345 - val_loss: 7.2635e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0341 - val_loss: 6.9786e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0344 - val_loss: 6.8050e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0353 - val_loss: 6.4179e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0333 - val_loss: 6.3690e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0343 - val_loss: 6.2551e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0333 - val_loss: 6.0373e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0339 - val_loss: 5.9041e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0337 - val_loss: 5.6965e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0339 - val_loss: 5.5977e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0335 - val_loss: 5.5735e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0336 - val_loss: 5.4172e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0324 - val_loss: 5.4179e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0333 - val_loss: 5.3301e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0343 - val_loss: 5.1971e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0343 - val_loss: 5.1954e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0352 - val_loss: 5.1933e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0333 - val_loss: 5.2054e-04\n",
            "Training for SNR= 5.5  sigma= 0.5308844442309884\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 54us/sample - loss: 0.0262 - val_loss: 4.8389e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0252 - val_loss: 4.6481e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0235 - val_loss: 4.4597e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0232 - val_loss: 4.2332e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0241 - val_loss: 4.1125e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0246 - val_loss: 4.0173e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0242 - val_loss: 3.7851e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0239 - val_loss: 3.6585e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0227 - val_loss: 3.7246e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0244 - val_loss: 3.4683e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0245 - val_loss: 3.4467e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0241 - val_loss: 3.4796e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0250 - val_loss: 3.3757e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0235 - val_loss: 3.3078e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0231 - val_loss: 3.2479e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0224 - val_loss: 3.1122e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0239 - val_loss: 3.0916e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0248 - val_loss: 3.0336e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0246 - val_loss: 3.0850e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0242 - val_loss: 3.0826e-04\n",
            "Training for SNR= 6.0  sigma= 0.5011872336272722\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 57us/sample - loss: 0.0174 - val_loss: 2.9386e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0175 - val_loss: 2.8038e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0175 - val_loss: 2.6597e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0170 - val_loss: 2.5781e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0175 - val_loss: 2.5029e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0166 - val_loss: 2.4286e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0176 - val_loss: 2.3919e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0173 - val_loss: 2.3444e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0178 - val_loss: 2.3024e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0174 - val_loss: 2.2505e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0179 - val_loss: 2.1901e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0170 - val_loss: 2.2352e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0181 - val_loss: 2.1103e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0173 - val_loss: 2.1269e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0173 - val_loss: 2.0732e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0180 - val_loss: 2.0590e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0166 - val_loss: 2.0488e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0168 - val_loss: 2.0244e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0159 - val_loss: 1.9775e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0166 - val_loss: 1.9379e-04\n",
            "Training for SNR= 6.5  sigma= 0.47315125896148047\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 60us/sample - loss: 0.0128 - val_loss: 1.8697e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0118 - val_loss: 1.7848e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0113 - val_loss: 1.7116e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0106 - val_loss: 1.6861e-04\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0107 - val_loss: 1.5975e-04\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0111 - val_loss: 1.5907e-04\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 7us/sample - loss: 0.0116 - val_loss: 1.5420e-04\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0113 - val_loss: 1.4782e-04\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0115 - val_loss: 1.4213e-04\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0120 - val_loss: 1.3780e-04\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0116 - val_loss: 1.3755e-04\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0106 - val_loss: 1.3333e-04\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0110 - val_loss: 1.3313e-04\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0112 - val_loss: 1.2544e-04\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0108 - val_loss: 1.2267e-04\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0110 - val_loss: 1.2119e-04\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0113 - val_loss: 1.1892e-04\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0102 - val_loss: 1.1605e-04\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0104 - val_loss: 1.1373e-04\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0122 - val_loss: 1.1193e-04\n",
            "Training for SNR= 7.0  sigma= 0.44668359215096315\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 62us/sample - loss: 0.0079 - val_loss: 1.1201e-04\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0079 - val_loss: 1.0468e-04\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0072 - val_loss: 1.0026e-04\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0075 - val_loss: 9.9431e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0075 - val_loss: 9.6968e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0072 - val_loss: 9.4421e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0076 - val_loss: 8.9888e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0073 - val_loss: 9.0188e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0073 - val_loss: 8.4263e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0072 - val_loss: 8.2529e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0072 - val_loss: 8.1048e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0072 - val_loss: 7.9463e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0075 - val_loss: 8.0319e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0079 - val_loss: 7.7431e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0078 - val_loss: 7.6079e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0074 - val_loss: 7.5782e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0071 - val_loss: 7.5276e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0076 - val_loss: 7.2844e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0075 - val_loss: 7.1989e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0074 - val_loss: 7.1412e-05\n",
            "Training for SNR= 7.5  sigma= 0.4216965034285822\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 61us/sample - loss: 0.0055 - val_loss: 7.1543e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0044 - val_loss: 6.9595e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0044 - val_loss: 6.5498e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0043 - val_loss: 6.1665e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0040 - val_loss: 6.0613e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0042 - val_loss: 5.8482e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0046 - val_loss: 5.6947e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0044 - val_loss: 5.4623e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0048 - val_loss: 5.4318e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0044 - val_loss: 5.2958e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0042 - val_loss: 5.1514e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0043 - val_loss: 4.9780e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0047 - val_loss: 5.0417e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0048 - val_loss: 4.7850e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0045 - val_loss: 4.7661e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0042 - val_loss: 4.5858e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0041 - val_loss: 4.5590e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0042 - val_loss: 4.5528e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0048 - val_loss: 4.3649e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0040 - val_loss: 4.4204e-05\n",
            "Training for SNR= 8.0  sigma= 0.3981071705534972\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 63us/sample - loss: 0.0027 - val_loss: 4.2970e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0030 - val_loss: 4.1554e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0029 - val_loss: 4.0470e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0027 - val_loss: 4.0277e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0027 - val_loss: 3.8734e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0030 - val_loss: 3.7676e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0028 - val_loss: 3.7030e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0027 - val_loss: 3.5774e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0030 - val_loss: 3.5535e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0025 - val_loss: 3.3402e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0027 - val_loss: 3.3632e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0024 - val_loss: 3.3095e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0026 - val_loss: 3.1802e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0022 - val_loss: 3.0421e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0024 - val_loss: 2.9957e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0027 - val_loss: 2.9025e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0026 - val_loss: 2.8725e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0025 - val_loss: 2.8146e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0030 - val_loss: 2.8591e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0025 - val_loss: 2.7818e-05\n",
            "Training for SNR= 8.5  sigma= 0.3758374042884442\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 62us/sample - loss: 0.0017 - val_loss: 2.7112e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0017 - val_loss: 2.6976e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0019 - val_loss: 2.5329e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0016 - val_loss: 2.4468e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0018 - val_loss: 2.3718e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0016 - val_loss: 2.2571e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0016 - val_loss: 2.2277e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0015 - val_loss: 2.1916e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0016 - val_loss: 2.2109e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0016 - val_loss: 2.2078e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0017 - val_loss: 2.0976e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 0.0015 - val_loss: 2.0740e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0014 - val_loss: 2.0223e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0014 - val_loss: 1.9493e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0016 - val_loss: 1.9633e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0012 - val_loss: 1.9298e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0015 - val_loss: 1.9098e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0014 - val_loss: 1.8199e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0013 - val_loss: 1.7709e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 0.0015 - val_loss: 1.7480e-05\n",
            "Training for SNR= 9.0  sigma= 0.35481338923357547\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 7.4524e-04 - val_loss: 1.6553e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 5.9465e-04 - val_loss: 1.5948e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 8.4286e-04 - val_loss: 1.5372e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 9.8584e-04 - val_loss: 1.5225e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 8.1498e-04 - val_loss: 1.5043e-05\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 0.0011 - val_loss: 1.4456e-05\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 9.3852e-04 - val_loss: 1.4054e-05\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 7.7008e-04 - val_loss: 1.3849e-05\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 9.1204e-04 - val_loss: 1.3376e-05\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 8.0900e-04 - val_loss: 1.3197e-05\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 9.7078e-04 - val_loss: 1.2954e-05\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 7.7878e-04 - val_loss: 1.2566e-05\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 6.5350e-04 - val_loss: 1.2035e-05\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 9.7328e-04 - val_loss: 1.2008e-05\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 7.1629e-04 - val_loss: 1.2112e-05\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 9.0910e-04 - val_loss: 1.1960e-05\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 8us/sample - loss: 9.4609e-04 - val_loss: 1.1545e-05\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0011 - val_loss: 1.1375e-05\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 0.0010 - val_loss: 1.1053e-05\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 7.8643e-04 - val_loss: 1.1272e-05\n",
            "Training for SNR= 9.5  sigma= 0.33496543915782767\n",
            "Train on 10000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 70us/sample - loss: 4.0642e-04 - val_loss: 1.0774e-05\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 0s 12us/sample - loss: 3.6860e-04 - val_loss: 1.0647e-05\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 5.1271e-04 - val_loss: 1.0546e-05\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 7.1214e-04 - val_loss: 1.0131e-05\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 4.5740e-04 - val_loss: 9.9864e-06\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 3.1035e-04 - val_loss: 9.7906e-06\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 4.4480e-04 - val_loss: 9.4000e-06\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 5.8649e-04 - val_loss: 9.6514e-06\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 6.8780e-04 - val_loss: 9.6758e-06\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 6.1802e-04 - val_loss: 9.4922e-06\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 4.2968e-04 - val_loss: 9.0152e-06\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 5.3289e-04 - val_loss: 8.9297e-06\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 5.9096e-04 - val_loss: 8.6926e-06\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 5.0346e-04 - val_loss: 8.7509e-06\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 0s 11us/sample - loss: 4.9625e-04 - val_loss: 8.2956e-06\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 4.0308e-04 - val_loss: 8.1023e-06\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 0s 9us/sample - loss: 5.2644e-04 - val_loss: 8.1095e-06\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 4.0235e-04 - val_loss: 8.1670e-06\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 4.9097e-04 - val_loss: 7.7547e-06\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 0s 10us/sample - loss: 5.5355e-04 - val_loss: 7.7023e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p6QVY1BDnnL",
        "outputId": "71b3ff87-c315-4518-9219-3d6417c7f000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "awgn_channel = GaussianNoise(Snr2Sigma(10),input_shape=(CHANEL_SIZE,))\n",
        "autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "autoencoder.evaluate(input_message, input_message, batch_size=128)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.71153951791348e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHByzQbTUqbv",
        "outputId": "0d25b40c-6b3a-4a53-a5a2-d14e1592c7f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "train_init = tf.global_variables_initializer ()\n",
        "train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,CHANEL_SIZE])\n",
        "    #noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,CHANEL_SIZE])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 2.82s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 3.56s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 4.31s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 5.05s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.69\n",
            " -> Total Time: 15.75s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 0.76s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 1.51s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 2.26s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 3.00s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.65\n",
            " -> Total Time: 7.53s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 0.74s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 1.50s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 2.25s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 2.99s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.57\n",
            " -> Total Time: 7.48s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.74s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.49s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 2.23s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 3.00s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.54\n",
            " -> Total Time: 7.47s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.75s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.50s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 2.25s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 3.02s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.47\n",
            " -> Total Time: 7.52s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.75s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.50s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 2.23s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.98s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.40\n",
            " -> Total Time: 7.46s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.83s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.66s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 2.49s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 3.32s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.34\n",
            " -> Total Time: 8.29s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.83s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 1.65s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 2.49s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 3.32s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.27\n",
            " -> Total Time: 8.30s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.83s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 1.67s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 2.51s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 3.34s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.24\n",
            " -> Total Time: 8.35s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.78s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 1.52s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 2.37s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 3.42s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.19\n",
            " -> Total Time: 8.09s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 1.10s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 2.16s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 3.25s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 4.30s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.16\n",
            " -> Total Time: 10.80s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 1.04s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 2.09s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 3.25s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 4.26s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.09\n",
            " -> Total Time: 10.64s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.76s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 1.52s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 2.27s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 3.04s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.07\n",
            " -> Total Time: 7.60s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.74s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 1.50s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 2.26s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 3.00s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 7.50s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.75s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 1.50s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 2.26s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 3.01s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.04\n",
            " -> Total Time: 7.52s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.75s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 1.49s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 2.25s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 3.00s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 7.50s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.73s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 1.47s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 2.22s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 2.97s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 7.40s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.74s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 1.49s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 2.25s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 3.00s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 7.49s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.75s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 1.52s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 2.28s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 3.02s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 7.56s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.76s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 1.51s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 2.27s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 3.03s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 7.57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUQij3fuxRm",
        "outputId": "a022883a-0cca-404f-f70f-236280c33cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"ldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLfbkfh4NvTj",
        "outputId": "9d045642-aa49-496e-b407-fa516e4646b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "input_message = numpy.random.randint(2, size=(NUM_OF_INPUT_MESSAGE*10,input_message_length))\n",
        "print (training_input_message)\n",
        "print (len(training_input_message))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 0 1 0]\n",
            " ...\n",
            " [0 1 1 ... 1 1 1]\n",
            " [1 1 0 ... 1 1 1]\n",
            " [0 0 1 ... 0 1 1]]\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGOH9hSKVvXI",
        "outputId": "7c6fc970-9a10-42d1-df47-2e20d3b77d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Here I am using trained model\n",
        "output_display_counter = NUM_OF_INPUT_MESSAGE/4\n",
        "ber_per_iter_dl_tensor  = numpy.array(())\n",
        "times_per_iter_dl_tensor = numpy.array(())\n",
        "\n",
        "#awgn_channel_tx = GaussianNoise(0.5,input_shape=(CHANEL_SIZE,))\n",
        "\n",
        "#awgn_channel_input = tf.compat.v1.placeholder(tf.float64, [CHANEL_SIZE])\n",
        "#awgn_noise_std_dev = tf.placeholder(tf.float64)\n",
        "#awgn_noise = tf.random.normal(tf.shape(awgn_channel_input), stddev=awgn_noise_std_dev, dtype=tf.dtypes.float64)\n",
        "#awgn_channel_output = tf.add(awgn_channel_input, awgn_noise)\n",
        "\n",
        "train_init = tf.global_variables_initializer ()\n",
        "train_sess = tf.Session ()\n",
        "\n",
        "for snr in numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE):\n",
        "  total_bit_error = 0\n",
        "  total_msg_error = 0\n",
        "  total_time = 0\n",
        "  current_time = time.time()\n",
        "  sigma = Snr2Sigma (snr)\n",
        "  #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "  #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "  #opt = keras.optimizers.Adam(learning_rate=0.003)\n",
        "  #autoencoder.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  for i in range (NUM_OF_INPUT_MESSAGE):\n",
        "    input_message_xx = input_message [i:i+1]\n",
        "    #print (\"input\", input_message_xx)\n",
        "    encoded_message = encoder.predict(input_message_xx)\n",
        "    #encoded_message = numpy.around(encoded_message > 0.5).astype(int)\n",
        "    #print(\"encoded:\",encoded_message)\n",
        "    #print (\"encoded\", encoded_message)\n",
        "    #noised_message = awgn_channel.predict (encoded_message)\n",
        "    #noised_message = commpy.channels.awgn(encoded_message, snr)\n",
        "    #noised_message = train_sess.run ([awgn_channel_output], feed_dict={awgn_noise_std_dev:sigma, awgn_channel_input:encoded_message[0]})[0].reshape([1,CHANEL_SIZE])\n",
        "    noised_message = encoded_message[0] + numpy.random.normal(0, sigma, [1,CHANEL_SIZE])\n",
        "    #print (noised_message)\n",
        "    #awgn_channel = GaussianNoise(sigma,input_shape=(CHANEL_SIZE,))\n",
        "    #noised_message = awgn_channel.predict(encoded_message)\n",
        "    #noised_message = awgn_layer (encoded_message)    \n",
        "    #print(noised_message)\n",
        "    decoded_message = decoder.predict(noised_message)\n",
        "    #print (\"decoded1:\", decoded_message)\n",
        "    #decoded_message = train_sess.run ([decoder_output], feed_dict={decoder_input_x:decoded_message})\n",
        "    #print (\"decoded2:\", decoded_message)\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    decoded_message = numpy.around(decoded_message[0]).astype(int)\n",
        "    #print (\"decoded3:\", decoded_message)\n",
        "    #decoded_message = numpy.around(decoded_message > 0.5).astype(int)\n",
        "    #print (\"decoded:\", decoded_message)\n",
        "    #print (\".\")\n",
        "    #autoencoder = Model(input_message_x, decoder(awgn_channel(encoder(input_message_x))))\n",
        "    #decoded_message = autoencoder.predict(input_message_xx)\n",
        "    #print (\"output\", decoded_message)\n",
        "    if abs(decoded_message-input_message[i]).sum() != 0 :\n",
        "      total_msg_error = total_msg_error + 1\n",
        "      #print (\"Error\")\n",
        "    if (i+1) % output_display_counter == 0:\n",
        "      total_time = timer_update(i, current_time,total_time, output_display_counter)\n",
        "  ber = float(total_msg_error)/NUM_OF_INPUT_MESSAGE\n",
        "  print('SNR: {:04.3f}:\\n -> BER: {:03.2f}\\n -> Total Time: {:03.2f}s'.format(snr,ber,total_time))\n",
        "  ber_per_iter_dl_tensor=numpy.append(ber_per_iter_dl_tensor ,ber)\n",
        "  times_per_iter_dl_tensor=numpy.append(times_per_iter_dl_tensor, total_time)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNR: 0.000 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 0.000 - Iter: 500 - Last 250.0 iterations took 1.33s\n",
            "SNR: 0.000 - Iter: 750 - Last 250.0 iterations took 1.99s\n",
            "SNR: 0.000 - Iter: 1000 - Last 250.0 iterations took 2.65s\n",
            "SNR: 0.000:\n",
            " -> BER: 0.68\n",
            " -> Total Time: 6.64s\n",
            "SNR: 0.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 0.500 - Iter: 500 - Last 250.0 iterations took 1.32s\n",
            "SNR: 0.500 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 0.500 - Iter: 1000 - Last 250.0 iterations took 2.64s\n",
            "SNR: 0.500:\n",
            " -> BER: 0.67\n",
            " -> Total Time: 6.61s\n",
            "SNR: 1.000 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 1.000 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 1.000 - Iter: 750 - Last 250.0 iterations took 1.97s\n",
            "SNR: 1.000 - Iter: 1000 - Last 250.0 iterations took 2.62s\n",
            "SNR: 1.000:\n",
            " -> BER: 0.59\n",
            " -> Total Time: 6.55s\n",
            "SNR: 1.500 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 1.500 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 1.500 - Iter: 750 - Last 250.0 iterations took 1.97s\n",
            "SNR: 1.500 - Iter: 1000 - Last 250.0 iterations took 2.62s\n",
            "SNR: 1.500:\n",
            " -> BER: 0.52\n",
            " -> Total Time: 6.54s\n",
            "SNR: 2.000 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 2.000 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 2.000 - Iter: 750 - Last 250.0 iterations took 1.96s\n",
            "SNR: 2.000 - Iter: 1000 - Last 250.0 iterations took 2.62s\n",
            "SNR: 2.000:\n",
            " -> BER: 0.49\n",
            " -> Total Time: 6.55s\n",
            "SNR: 2.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 2.500 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 2.500 - Iter: 750 - Last 250.0 iterations took 1.97s\n",
            "SNR: 2.500 - Iter: 1000 - Last 250.0 iterations took 2.63s\n",
            "SNR: 2.500:\n",
            " -> BER: 0.40\n",
            " -> Total Time: 6.57s\n",
            "SNR: 3.000 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 3.000 - Iter: 500 - Last 250.0 iterations took 1.30s\n",
            "SNR: 3.000 - Iter: 750 - Last 250.0 iterations took 1.96s\n",
            "SNR: 3.000 - Iter: 1000 - Last 250.0 iterations took 2.61s\n",
            "SNR: 3.000:\n",
            " -> BER: 0.33\n",
            " -> Total Time: 6.50s\n",
            "SNR: 3.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 3.500 - Iter: 500 - Last 250.0 iterations took 1.33s\n",
            "SNR: 3.500 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 3.500 - Iter: 1000 - Last 250.0 iterations took 2.64s\n",
            "SNR: 3.500:\n",
            " -> BER: 0.28\n",
            " -> Total Time: 6.62s\n",
            "SNR: 4.000 - Iter: 250 - Last 250.0 iterations took 0.67s\n",
            "SNR: 4.000 - Iter: 500 - Last 250.0 iterations took 1.32s\n",
            "SNR: 4.000 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 4.000 - Iter: 1000 - Last 250.0 iterations took 2.63s\n",
            "SNR: 4.000:\n",
            " -> BER: 0.25\n",
            " -> Total Time: 6.59s\n",
            "SNR: 4.500 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 4.500 - Iter: 500 - Last 250.0 iterations took 1.30s\n",
            "SNR: 4.500 - Iter: 750 - Last 250.0 iterations took 1.97s\n",
            "SNR: 4.500 - Iter: 1000 - Last 250.0 iterations took 2.62s\n",
            "SNR: 4.500:\n",
            " -> BER: 0.19\n",
            " -> Total Time: 6.54s\n",
            "SNR: 5.000 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 5.000 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 5.000 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 5.000 - Iter: 1000 - Last 250.0 iterations took 2.63s\n",
            "SNR: 5.000:\n",
            " -> BER: 0.13\n",
            " -> Total Time: 6.58s\n",
            "SNR: 5.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 5.500 - Iter: 500 - Last 250.0 iterations took 1.32s\n",
            "SNR: 5.500 - Iter: 750 - Last 250.0 iterations took 1.99s\n",
            "SNR: 5.500 - Iter: 1000 - Last 250.0 iterations took 2.63s\n",
            "SNR: 5.500:\n",
            " -> BER: 0.09\n",
            " -> Total Time: 6.59s\n",
            "SNR: 6.000 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 6.000 - Iter: 500 - Last 250.0 iterations took 1.30s\n",
            "SNR: 6.000 - Iter: 750 - Last 250.0 iterations took 1.95s\n",
            "SNR: 6.000 - Iter: 1000 - Last 250.0 iterations took 2.61s\n",
            "SNR: 6.000:\n",
            " -> BER: 0.06\n",
            " -> Total Time: 6.51s\n",
            "SNR: 6.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 6.500 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 6.500 - Iter: 750 - Last 250.0 iterations took 1.97s\n",
            "SNR: 6.500 - Iter: 1000 - Last 250.0 iterations took 2.62s\n",
            "SNR: 6.500:\n",
            " -> BER: 0.05\n",
            " -> Total Time: 6.55s\n",
            "SNR: 7.000 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 7.000 - Iter: 500 - Last 250.0 iterations took 1.32s\n",
            "SNR: 7.000 - Iter: 750 - Last 250.0 iterations took 1.97s\n",
            "SNR: 7.000 - Iter: 1000 - Last 250.0 iterations took 2.63s\n",
            "SNR: 7.000:\n",
            " -> BER: 0.03\n",
            " -> Total Time: 6.59s\n",
            "SNR: 7.500 - Iter: 250 - Last 250.0 iterations took 0.64s\n",
            "SNR: 7.500 - Iter: 500 - Last 250.0 iterations took 1.29s\n",
            "SNR: 7.500 - Iter: 750 - Last 250.0 iterations took 1.95s\n",
            "SNR: 7.500 - Iter: 1000 - Last 250.0 iterations took 2.61s\n",
            "SNR: 7.500:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 6.50s\n",
            "SNR: 8.000 - Iter: 250 - Last 250.0 iterations took 0.64s\n",
            "SNR: 8.000 - Iter: 500 - Last 250.0 iterations took 1.29s\n",
            "SNR: 8.000 - Iter: 750 - Last 250.0 iterations took 1.94s\n",
            "SNR: 8.000 - Iter: 1000 - Last 250.0 iterations took 2.59s\n",
            "SNR: 8.000:\n",
            " -> BER: 0.02\n",
            " -> Total Time: 6.47s\n",
            "SNR: 8.500 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 8.500 - Iter: 500 - Last 250.0 iterations took 1.32s\n",
            "SNR: 8.500 - Iter: 750 - Last 250.0 iterations took 1.98s\n",
            "SNR: 8.500 - Iter: 1000 - Last 250.0 iterations took 2.62s\n",
            "SNR: 8.500:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 6.57s\n",
            "SNR: 9.000 - Iter: 250 - Last 250.0 iterations took 0.65s\n",
            "SNR: 9.000 - Iter: 500 - Last 250.0 iterations took 1.29s\n",
            "SNR: 9.000 - Iter: 750 - Last 250.0 iterations took 1.94s\n",
            "SNR: 9.000 - Iter: 1000 - Last 250.0 iterations took 2.60s\n",
            "SNR: 9.000:\n",
            " -> BER: 0.01\n",
            " -> Total Time: 6.48s\n",
            "SNR: 9.500 - Iter: 250 - Last 250.0 iterations took 0.66s\n",
            "SNR: 9.500 - Iter: 500 - Last 250.0 iterations took 1.31s\n",
            "SNR: 9.500 - Iter: 750 - Last 250.0 iterations took 1.96s\n",
            "SNR: 9.500 - Iter: 1000 - Last 250.0 iterations took 2.62s\n",
            "SNR: 9.500:\n",
            " -> BER: 0.00\n",
            " -> Total Time: 6.54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k01LEr1TV14X",
        "outputId": "c35b8cae-b6a0-4b07-86e2-b2c8cd6b5b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "snrs = numpy.arange (SNR_BEGIN, SNR_END, SNR_STEP_SIZE)\n",
        "fig, (ax1) = plt.subplots(1,1,figsize=(8,6))\n",
        "ax1.semilogy(snrs,ber_per_iter_tensor,'', label=\"ldpc\") # plot BER vs SNR\n",
        "ax1.semilogy(snrs,ber_per_iter_dl_tensor,'', label=\"ai-dl\") # plot BER vs SNR\n",
        "ax1.set_ylabel('BER')\n",
        "ax1.set_title('Regular LDPC ({},{},{})'.format(CHANEL_SIZE,input_message_length,CHANEL_SIZE-input_message_length))\n",
        "#ax2.plot(snrs,times_per_iter_pyldpc,'', label=\"pyldpc\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_tensor,'', label=\"tensor\") # plot decode timing for different SNRs\n",
        "#ax2.plot(snrs,times_per_iter_awgn,'', label=\"commpy-awgn\") # plot decode timing for different SNRs\n",
        "#ax2.set_xlabel('$E_b/$N_0$')\n",
        "#ax2.set_ylabel('Decoding Time [s]')\n",
        "#ax2.annotate('Total Runtime: pyldpc:{:03.2f}s awgn:{:03.2f}s tensor:{:03.2f}s'.format(numpy.sum(times_per_iter_pyldpc), \n",
        "#            numpy.sum(times_per_iter_awgn), numpy.sum(times_per_iter_tensor)),\n",
        "#            xy=(1, 0.35), xycoords='axes fraction',\n",
        "#            xytext=(-20, 20), textcoords='offset pixels',\n",
        "#            horizontalalignment='right',\n",
        "#            verticalalignment='bottom')\n",
        "plt.savefig('ldpc_ber_{}_{}.png'.format(CHANEL_SIZE,input_message_length))\n",
        "plt.legend ()\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}